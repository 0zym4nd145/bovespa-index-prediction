{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdJ4ztmx2CO"
      },
      "source": [
        " # Trabalho de Graduação para engenharia de Informação @UFABC\n",
        " Aluno: Lucas Ortega Venzel\n",
        " \n",
        " # Previsão do Índice Bovespa Utilizando Indicadores Técnicos e Algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from yfinance import download\n",
        "import pandas as pd\n",
        "from ta import trend, momentum\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
        "from pmdarima.arima import auto_arima\n",
        "from tqdm import trange\n",
        "import optuna\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, roc_auc_score, roc_curve, confusion_matrix, mean_absolute_error, f1_score, accuracy_score, mean_squared_error\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def coeff_determination(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKoGqbdyy9xG"
      },
      "source": [
        "## Importando Dados e Criando Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMXo6H2kZkUd",
        "outputId": "5eea958c-f35f-4af5-b09c-9179b2c904be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "dataSP = download(\n",
        "        tickers = '^GSPC',\n",
        "\n",
        "        start='2006-01-01',\n",
        "        interval = \"1d\",\n",
        "\n",
        "        auto_adjust = True,\n",
        "        prepost = True,\n",
        "    )\n",
        "dataUS = download(\n",
        "        tickers = 'BRL=X',\n",
        "\n",
        "        start='2006-01-01',\n",
        "        interval = \"1d\",\n",
        "\n",
        "        auto_adjust = True,\n",
        "        prepost = True,\n",
        "    )\n",
        "dataBV = download(\n",
        "        tickers = '^BVSP',\n",
        "\n",
        "        start='2006-01-01',\n",
        "        interval = \"1d\",\n",
        "\n",
        "        auto_adjust = True,\n",
        "        prepost = True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "LE40z2FMFwns",
        "outputId": "d0129c4a-e6ac-422b-8fa1-7c35e962f347"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-18</th>\n",
              "      <td>4700.720215</td>\n",
              "      <td>4708.799805</td>\n",
              "      <td>4672.779785</td>\n",
              "      <td>4704.540039</td>\n",
              "      <td>3335620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-19</th>\n",
              "      <td>4708.439941</td>\n",
              "      <td>4717.750000</td>\n",
              "      <td>4694.220215</td>\n",
              "      <td>4697.959961</td>\n",
              "      <td>3265600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-22</th>\n",
              "      <td>4712.000000</td>\n",
              "      <td>4743.830078</td>\n",
              "      <td>4682.169922</td>\n",
              "      <td>4682.939941</td>\n",
              "      <td>3206280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-23</th>\n",
              "      <td>4678.479980</td>\n",
              "      <td>4699.390137</td>\n",
              "      <td>4652.660156</td>\n",
              "      <td>4690.700195</td>\n",
              "      <td>3428780000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-24</th>\n",
              "      <td>4675.779785</td>\n",
              "      <td>4694.750000</td>\n",
              "      <td>4659.890137</td>\n",
              "      <td>4687.240234</td>\n",
              "      <td>833163715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Open         High          Low        Close      Volume\n",
              "Date                                                                      \n",
              "2021-11-18  4700.720215  4708.799805  4672.779785  4704.540039  3335620000\n",
              "2021-11-19  4708.439941  4717.750000  4694.220215  4697.959961  3265600000\n",
              "2021-11-22  4712.000000  4743.830078  4682.169922  4682.939941  3206280000\n",
              "2021-11-23  4678.479980  4699.390137  4652.660156  4690.700195  3428780000\n",
              "2021-11-24  4675.779785  4694.750000  4659.890137  4687.240234   833163715"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataSP.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-18</th>\n",
              "      <td>5.5287</td>\n",
              "      <td>5.5646</td>\n",
              "      <td>5.475345</td>\n",
              "      <td>5.5287</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-19</th>\n",
              "      <td>5.5561</td>\n",
              "      <td>5.5754</td>\n",
              "      <td>5.521700</td>\n",
              "      <td>5.5564</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-22</th>\n",
              "      <td>5.6072</td>\n",
              "      <td>5.6144</td>\n",
              "      <td>5.563300</td>\n",
              "      <td>5.6116</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-23</th>\n",
              "      <td>5.5858</td>\n",
              "      <td>5.6601</td>\n",
              "      <td>5.565159</td>\n",
              "      <td>5.5856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-24</th>\n",
              "      <td>5.6091</td>\n",
              "      <td>5.6226</td>\n",
              "      <td>5.548000</td>\n",
              "      <td>5.5972</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High       Low   Close  Volume\n",
              "Date                                                \n",
              "2021-11-18  5.5287  5.5646  5.475345  5.5287       0\n",
              "2021-11-19  5.5561  5.5754  5.521700  5.5564       0\n",
              "2021-11-22  5.6072  5.6144  5.563300  5.6116       0\n",
              "2021-11-23  5.5858  5.6601  5.565159  5.5856       0\n",
              "2021-11-24  5.6091  5.6226  5.548000  5.5972       0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataUS.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-18</th>\n",
              "      <td>102948.000000</td>\n",
              "      <td>103757.00000</td>\n",
              "      <td>102014.000000</td>\n",
              "      <td>102524.000000</td>\n",
              "      <td>10905700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-19</th>\n",
              "      <td>102426.000000</td>\n",
              "      <td>103975.00000</td>\n",
              "      <td>102143.000000</td>\n",
              "      <td>103035.000000</td>\n",
              "      <td>11101500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-22</th>\n",
              "      <td>103036.000000</td>\n",
              "      <td>104613.00000</td>\n",
              "      <td>102122.000000</td>\n",
              "      <td>102122.000000</td>\n",
              "      <td>10410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-23</th>\n",
              "      <td>102124.000000</td>\n",
              "      <td>103692.00000</td>\n",
              "      <td>101736.000000</td>\n",
              "      <td>103663.000000</td>\n",
              "      <td>13032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-24</th>\n",
              "      <td>103651.882812</td>\n",
              "      <td>105041.15625</td>\n",
              "      <td>102464.289062</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Open          High            Low          Close  \\\n",
              "Date                                                                    \n",
              "2021-11-18  102948.000000  103757.00000  102014.000000  102524.000000   \n",
              "2021-11-19  102426.000000  103975.00000  102143.000000  103035.000000   \n",
              "2021-11-22  103036.000000  104613.00000  102122.000000  102122.000000   \n",
              "2021-11-23  102124.000000  103692.00000  101736.000000  103663.000000   \n",
              "2021-11-24  103651.882812  105041.15625  102464.289062  104461.382812   \n",
              "\n",
              "              Volume  \n",
              "Date                  \n",
              "2021-11-18  10905700  \n",
              "2021-11-19  11101500  \n",
              "2021-11-22  10410000  \n",
              "2021-11-23  13032400  \n",
              "2021-11-24         0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataBV.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qAwt0TIvSKzm"
      },
      "outputs": [],
      "source": [
        "dataSP['ano'] = dataSP.index.year\n",
        "dataUS['ano'] = dataUS.index.year\n",
        "dataBV['ano'] = dataBV.index.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KQUl6YEJhZjU"
      },
      "outputs": [],
      "source": [
        "temp = dataBV['Close']\n",
        "temp.index = temp.index + pd.DateOffset(weeks=-1)\n",
        "dataBV = dataBV.join(temp.rename('1w target'))\n",
        "dataBV.loc[:, '1w target'] = dataBV['1w target'].fillna(method='ffill')\n",
        "dataBV.loc[:, '1w target'] = (dataBV['1w target'] / dataBV['Close']) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "JrE1n1GWxdom",
        "outputId": "859d6de0-9220-4168-e549-0b6d316d4ed6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date\n",
              "2006-01-02    0.054615\n",
              "2006-01-03    0.014707\n",
              "2006-01-04    0.027141\n",
              "2006-01-05    0.024130\n",
              "2006-01-06    0.011896\n",
              "                ...   \n",
              "2021-11-18    0.018897\n",
              "2021-11-19    0.013844\n",
              "2021-11-22    0.022908\n",
              "2021-11-23    0.007702\n",
              "2021-11-24    0.000000\n",
              "Name: 1w target, Length: 3915, dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataBV['1w target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp = dataBV['Close']\n",
        "temp.index = temp.index + pd.DateOffset(weeks=-1)\n",
        "dataBV = dataBV.join(temp.rename('1w absolute target'))\n",
        "dataBV.loc[:, '1w absolute target'] = dataBV['1w absolute target'].fillna(method='ffill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date\n",
              "2006-01-02     35337.000000\n",
              "2006-01-03     35049.000000\n",
              "2006-01-04     35952.000000\n",
              "2006-01-05     35779.000000\n",
              "2006-01-06     35897.000000\n",
              "                  ...      \n",
              "2021-11-18    104461.382812\n",
              "2021-11-19    104461.382812\n",
              "2021-11-22    104461.382812\n",
              "2021-11-23    104461.382812\n",
              "2021-11-24    104461.382812\n",
              "Name: 1w absolute target, Length: 3915, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataBV['1w absolute target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uNT8CHtZ_MW",
        "outputId": "019a0c4f-9c26-4634-8741-fe22e6ba9207"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
          ]
        }
      ],
      "source": [
        "dataSP['MACD'] = trend.MACD(close = dataSP['Close'], window_slow = 26, window_fast = 12, window_sign = 9, fillna = False).macd_signal()\n",
        "dataSP['RSI'] = momentum.RSIIndicator(close = dataSP['Close'], window = 14, fillna = False).rsi()\n",
        "dataSP['ADX'] = trend.ADXIndicator(high = dataSP['High'], low = dataSP['Low'], close = dataSP['Close'], window = 14, fillna = False).adx()\n",
        "dataSP['Aroon'] = trend.AroonIndicator(close = dataSP['Close'], window = 25, fillna = False).aroon_indicator()\n",
        "dataSP['CCI'] = trend.CCIIndicator(high = dataSP['High'], low = dataSP['Low'], close = dataSP['Close'], window = 20, constant = 0.015, fillna = False).cci()\n",
        "dataSP['DPO'] = trend.DPOIndicator(close = dataSP['Close'], window = 20, fillna = False).dpo()\n",
        "dataSP['MI'] = trend.MassIndex(high = dataSP['Close'], low = dataSP['Low'], window_fast = 9, window_slow = 25, fillna = False).mass_index()\n",
        "dataSP['TRIX'] = trend.TRIXIndicator(close = dataSP['Close'], window = 15, fillna = False).trix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "WvJsvMzhKJD7",
        "outputId": "59e57bdd-5e63-4442-d8c6-98d8f399fefd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ano</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ADX</th>\n",
              "      <th>Aroon</th>\n",
              "      <th>CCI</th>\n",
              "      <th>DPO</th>\n",
              "      <th>MI</th>\n",
              "      <th>TRIX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-18</th>\n",
              "      <td>4700.720215</td>\n",
              "      <td>4708.799805</td>\n",
              "      <td>4672.779785</td>\n",
              "      <td>4704.540039</td>\n",
              "      <td>3335620000</td>\n",
              "      <td>2021</td>\n",
              "      <td>57.864124</td>\n",
              "      <td>68.765198</td>\n",
              "      <td>31.778813</td>\n",
              "      <td>96.0</td>\n",
              "      <td>76.576651</td>\n",
              "      <td>17.328857</td>\n",
              "      <td>23.716047</td>\n",
              "      <td>0.194018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-19</th>\n",
              "      <td>4708.439941</td>\n",
              "      <td>4717.750000</td>\n",
              "      <td>4694.220215</td>\n",
              "      <td>4697.959961</td>\n",
              "      <td>3265600000</td>\n",
              "      <td>2021</td>\n",
              "      <td>57.081534</td>\n",
              "      <td>67.021687</td>\n",
              "      <td>31.768143</td>\n",
              "      <td>92.0</td>\n",
              "      <td>83.828588</td>\n",
              "      <td>29.166089</td>\n",
              "      <td>23.515338</td>\n",
              "      <td>0.191457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-22</th>\n",
              "      <td>4712.000000</td>\n",
              "      <td>4743.830078</td>\n",
              "      <td>4682.169922</td>\n",
              "      <td>4682.939941</td>\n",
              "      <td>3206280000</td>\n",
              "      <td>2021</td>\n",
              "      <td>55.809877</td>\n",
              "      <td>63.089475</td>\n",
              "      <td>32.276508</td>\n",
              "      <td>88.0</td>\n",
              "      <td>78.543133</td>\n",
              "      <td>40.812817</td>\n",
              "      <td>23.133289</td>\n",
              "      <td>0.187348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-23</th>\n",
              "      <td>4678.479980</td>\n",
              "      <td>4699.390137</td>\n",
              "      <td>4652.660156</td>\n",
              "      <td>4690.700195</td>\n",
              "      <td>3428780000</td>\n",
              "      <td>2021</td>\n",
              "      <td>54.294954</td>\n",
              "      <td>64.256314</td>\n",
              "      <td>31.612581</td>\n",
              "      <td>84.0</td>\n",
              "      <td>35.986874</td>\n",
              "      <td>39.187720</td>\n",
              "      <td>23.118986</td>\n",
              "      <td>0.182345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-24</th>\n",
              "      <td>4675.779785</td>\n",
              "      <td>4694.750000</td>\n",
              "      <td>4659.890137</td>\n",
              "      <td>4687.240234</td>\n",
              "      <td>833163715</td>\n",
              "      <td>2021</td>\n",
              "      <td>52.528020</td>\n",
              "      <td>63.295556</td>\n",
              "      <td>30.996077</td>\n",
              "      <td>76.0</td>\n",
              "      <td>29.158480</td>\n",
              "      <td>15.959521</td>\n",
              "      <td>23.298268</td>\n",
              "      <td>0.176452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Open         High          Low        Close      Volume  \\\n",
              "Date                                                                         \n",
              "2021-11-18  4700.720215  4708.799805  4672.779785  4704.540039  3335620000   \n",
              "2021-11-19  4708.439941  4717.750000  4694.220215  4697.959961  3265600000   \n",
              "2021-11-22  4712.000000  4743.830078  4682.169922  4682.939941  3206280000   \n",
              "2021-11-23  4678.479980  4699.390137  4652.660156  4690.700195  3428780000   \n",
              "2021-11-24  4675.779785  4694.750000  4659.890137  4687.240234   833163715   \n",
              "\n",
              "             ano       MACD        RSI        ADX  Aroon        CCI  \\\n",
              "Date                                                                  \n",
              "2021-11-18  2021  57.864124  68.765198  31.778813   96.0  76.576651   \n",
              "2021-11-19  2021  57.081534  67.021687  31.768143   92.0  83.828588   \n",
              "2021-11-22  2021  55.809877  63.089475  32.276508   88.0  78.543133   \n",
              "2021-11-23  2021  54.294954  64.256314  31.612581   84.0  35.986874   \n",
              "2021-11-24  2021  52.528020  63.295556  30.996077   76.0  29.158480   \n",
              "\n",
              "                  DPO         MI      TRIX  \n",
              "Date                                        \n",
              "2021-11-18  17.328857  23.716047  0.194018  \n",
              "2021-11-19  29.166089  23.515338  0.191457  \n",
              "2021-11-22  40.812817  23.133289  0.187348  \n",
              "2021-11-23  39.187720  23.118986  0.182345  \n",
              "2021-11-24  15.959521  23.298268  0.176452  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataSP.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uNT8CHtZ_MW",
        "outputId": "019a0c4f-9c26-4634-8741-fe22e6ba9207"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
          ]
        }
      ],
      "source": [
        "dataUS['MACD'] = trend.MACD(close = dataUS['Close'], window_slow = 26, window_fast = 12, window_sign = 9, fillna = False).macd_signal()\n",
        "dataUS['RSI'] = momentum.RSIIndicator(close = dataUS['Close'], window = 14, fillna = False).rsi()\n",
        "dataUS['ADX'] = trend.ADXIndicator(high = dataUS['High'], low = dataUS['Low'], close = dataUS['Close'], window = 14, fillna = False).adx()\n",
        "dataUS['Aroon'] = trend.AroonIndicator(close = dataUS['Close'], window = 25, fillna = False).aroon_indicator()\n",
        "dataUS['CCI'] = trend.CCIIndicator(high = dataUS['High'], low = dataUS['Low'], close = dataUS['Close'], window = 20, constant = 0.015, fillna = False).cci()\n",
        "dataUS['DPO'] = trend.DPOIndicator(close = dataUS['Close'], window = 20, fillna = False).dpo()\n",
        "dataUS['MI'] = trend.MassIndex(high = dataUS['Close'], low = dataUS['Low'], window_fast = 9, window_slow = 25, fillna = False).mass_index()\n",
        "dataUS['TRIX'] = trend.TRIXIndicator(close = dataUS['Close'], window = 15, fillna = False).trix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "WvJsvMzhKJD7",
        "outputId": "59e57bdd-5e63-4442-d8c6-98d8f399fefd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ano</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ADX</th>\n",
              "      <th>Aroon</th>\n",
              "      <th>CCI</th>\n",
              "      <th>DPO</th>\n",
              "      <th>MI</th>\n",
              "      <th>TRIX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-18</th>\n",
              "      <td>5.5287</td>\n",
              "      <td>5.5646</td>\n",
              "      <td>5.475345</td>\n",
              "      <td>5.5287</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.014436</td>\n",
              "      <td>51.534190</td>\n",
              "      <td>21.261128</td>\n",
              "      <td>-32.0</td>\n",
              "      <td>-34.423227</td>\n",
              "      <td>0.12123</td>\n",
              "      <td>25.857113</td>\n",
              "      <td>0.043791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-19</th>\n",
              "      <td>5.5561</td>\n",
              "      <td>5.5754</td>\n",
              "      <td>5.521700</td>\n",
              "      <td>5.5564</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>53.892334</td>\n",
              "      <td>20.249110</td>\n",
              "      <td>-32.0</td>\n",
              "      <td>1.422287</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>25.613004</td>\n",
              "      <td>0.034885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-22</th>\n",
              "      <td>5.6072</td>\n",
              "      <td>5.6144</td>\n",
              "      <td>5.563300</td>\n",
              "      <td>5.6116</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.011307</td>\n",
              "      <td>58.251664</td>\n",
              "      <td>19.900950</td>\n",
              "      <td>-32.0</td>\n",
              "      <td>54.409115</td>\n",
              "      <td>0.05128</td>\n",
              "      <td>25.650528</td>\n",
              "      <td>0.030710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-23</th>\n",
              "      <td>5.5858</td>\n",
              "      <td>5.6601</td>\n",
              "      <td>5.565159</td>\n",
              "      <td>5.5856</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.011555</td>\n",
              "      <td>55.585853</td>\n",
              "      <td>20.188877</td>\n",
              "      <td>-32.0</td>\n",
              "      <td>58.663904</td>\n",
              "      <td>-0.01088</td>\n",
              "      <td>25.753366</td>\n",
              "      <td>0.028899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-24</th>\n",
              "      <td>5.6091</td>\n",
              "      <td>5.6226</td>\n",
              "      <td>5.548000</td>\n",
              "      <td>5.5972</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.012467</td>\n",
              "      <td>56.541430</td>\n",
              "      <td>20.108512</td>\n",
              "      <td>-32.0</td>\n",
              "      <td>40.720398</td>\n",
              "      <td>-0.01050</td>\n",
              "      <td>25.770614</td>\n",
              "      <td>0.029102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open    High       Low   Close  Volume   ano      MACD  \\\n",
              "Date                                                                   \n",
              "2021-11-18  5.5287  5.5646  5.475345  5.5287       0  2021  0.014436   \n",
              "2021-11-19  5.5561  5.5754  5.521700  5.5564       0  2021  0.011886   \n",
              "2021-11-22  5.6072  5.6144  5.563300  5.6116       0  2021  0.011307   \n",
              "2021-11-23  5.5858  5.6601  5.565159  5.5856       0  2021  0.011555   \n",
              "2021-11-24  5.6091  5.6226  5.548000  5.5972       0  2021  0.012467   \n",
              "\n",
              "                  RSI        ADX  Aroon        CCI      DPO         MI  \\\n",
              "Date                                                                     \n",
              "2021-11-18  51.534190  21.261128  -32.0 -34.423227  0.12123  25.857113   \n",
              "2021-11-19  53.892334  20.249110  -32.0   1.422287  0.00010  25.613004   \n",
              "2021-11-22  58.251664  19.900950  -32.0  54.409115  0.05128  25.650528   \n",
              "2021-11-23  55.585853  20.188877  -32.0  58.663904 -0.01088  25.753366   \n",
              "2021-11-24  56.541430  20.108512  -32.0  40.720398 -0.01050  25.770614   \n",
              "\n",
              "                TRIX  \n",
              "Date                  \n",
              "2021-11-18  0.043791  \n",
              "2021-11-19  0.034885  \n",
              "2021-11-22  0.030710  \n",
              "2021-11-23  0.028899  \n",
              "2021-11-24  0.029102  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataUS.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uNT8CHtZ_MW",
        "outputId": "019a0c4f-9c26-4634-8741-fe22e6ba9207"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
          ]
        }
      ],
      "source": [
        "dataBV['MACD'] = trend.MACD(close = dataBV['Close'], window_slow = 26, window_fast = 12, window_sign = 9, fillna = False).macd_signal()\n",
        "dataBV['RSI'] = momentum.RSIIndicator(close = dataBV['Close'], window = 14, fillna = False).rsi()\n",
        "dataBV['ADX'] = trend.ADXIndicator(high = dataBV['High'], low = dataBV['Low'], close = dataBV['Close'], window = 14, fillna = False).adx()\n",
        "dataBV['Aroon'] = trend.AroonIndicator(close = dataBV['Close'], window = 25, fillna = False).aroon_indicator()\n",
        "dataBV['CCI'] = trend.CCIIndicator(high = dataBV['High'], low = dataBV['Low'], close = dataBV['Close'], window = 20, constant = 0.015, fillna = False).cci()\n",
        "dataBV['DPO'] = trend.DPOIndicator(close = dataBV['Close'], window = 20, fillna = False).dpo()\n",
        "dataBV['MI'] = trend.MassIndex(high = dataBV['Close'], low = dataBV['Low'], window_fast = 9, window_slow = 25, fillna = False).mass_index()\n",
        "dataBV['TRIX'] = trend.TRIXIndicator(close = dataBV['Close'], window = 15, fillna = False).trix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "WvJsvMzhKJD7",
        "outputId": "59e57bdd-5e63-4442-d8c6-98d8f399fefd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>ano</th>\n",
              "      <th>1w target</th>\n",
              "      <th>1w absolute target</th>\n",
              "      <th>MACD</th>\n",
              "      <th>RSI</th>\n",
              "      <th>ADX</th>\n",
              "      <th>Aroon</th>\n",
              "      <th>CCI</th>\n",
              "      <th>DPO</th>\n",
              "      <th>MI</th>\n",
              "      <th>TRIX</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-11-18</th>\n",
              "      <td>102948.000000</td>\n",
              "      <td>103757.00000</td>\n",
              "      <td>102014.000000</td>\n",
              "      <td>102524.000000</td>\n",
              "      <td>10905700</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.018897</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>-1984.456540</td>\n",
              "      <td>36.528517</td>\n",
              "      <td>37.740472</td>\n",
              "      <td>-84.0</td>\n",
              "      <td>-134.329684</td>\n",
              "      <td>-2478.200000</td>\n",
              "      <td>24.683949</td>\n",
              "      <td>-0.261679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-19</th>\n",
              "      <td>102426.000000</td>\n",
              "      <td>103975.00000</td>\n",
              "      <td>102143.000000</td>\n",
              "      <td>103035.000000</td>\n",
              "      <td>11101500</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.013844</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>-1989.876973</td>\n",
              "      <td>38.337778</td>\n",
              "      <td>37.581818</td>\n",
              "      <td>-84.0</td>\n",
              "      <td>-121.862309</td>\n",
              "      <td>-46.300000</td>\n",
              "      <td>24.590386</td>\n",
              "      <td>-0.263001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-22</th>\n",
              "      <td>103036.000000</td>\n",
              "      <td>104613.00000</td>\n",
              "      <td>102122.000000</td>\n",
              "      <td>102122.000000</td>\n",
              "      <td>10410000</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.022908</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>-2006.627821</td>\n",
              "      <td>36.344378</td>\n",
              "      <td>36.967428</td>\n",
              "      <td>-92.0</td>\n",
              "      <td>-121.995143</td>\n",
              "      <td>452.900000</td>\n",
              "      <td>24.253952</td>\n",
              "      <td>-0.265578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-23</th>\n",
              "      <td>102124.000000</td>\n",
              "      <td>103692.00000</td>\n",
              "      <td>101736.000000</td>\n",
              "      <td>103663.000000</td>\n",
              "      <td>13032400</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.007702</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>-2000.442981</td>\n",
              "      <td>41.841058</td>\n",
              "      <td>36.551543</td>\n",
              "      <td>-92.0</td>\n",
              "      <td>-108.176002</td>\n",
              "      <td>-1548.500000</td>\n",
              "      <td>24.319116</td>\n",
              "      <td>-0.265649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-11-24</th>\n",
              "      <td>103651.882812</td>\n",
              "      <td>105041.15625</td>\n",
              "      <td>102464.289062</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>104461.382812</td>\n",
              "      <td>-1962.909569</td>\n",
              "      <td>44.514298</td>\n",
              "      <td>35.201249</td>\n",
              "      <td>-88.0</td>\n",
              "      <td>-52.910149</td>\n",
              "      <td>-44.769141</td>\n",
              "      <td>24.463882</td>\n",
              "      <td>-0.262094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Open          High            Low          Close  \\\n",
              "Date                                                                    \n",
              "2021-11-18  102948.000000  103757.00000  102014.000000  102524.000000   \n",
              "2021-11-19  102426.000000  103975.00000  102143.000000  103035.000000   \n",
              "2021-11-22  103036.000000  104613.00000  102122.000000  102122.000000   \n",
              "2021-11-23  102124.000000  103692.00000  101736.000000  103663.000000   \n",
              "2021-11-24  103651.882812  105041.15625  102464.289062  104461.382812   \n",
              "\n",
              "              Volume   ano  1w target  1w absolute target         MACD  \\\n",
              "Date                                                                     \n",
              "2021-11-18  10905700  2021   0.018897       104461.382812 -1984.456540   \n",
              "2021-11-19  11101500  2021   0.013844       104461.382812 -1989.876973   \n",
              "2021-11-22  10410000  2021   0.022908       104461.382812 -2006.627821   \n",
              "2021-11-23  13032400  2021   0.007702       104461.382812 -2000.442981   \n",
              "2021-11-24         0  2021   0.000000       104461.382812 -1962.909569   \n",
              "\n",
              "                  RSI        ADX  Aroon         CCI          DPO         MI  \\\n",
              "Date                                                                          \n",
              "2021-11-18  36.528517  37.740472  -84.0 -134.329684 -2478.200000  24.683949   \n",
              "2021-11-19  38.337778  37.581818  -84.0 -121.862309   -46.300000  24.590386   \n",
              "2021-11-22  36.344378  36.967428  -92.0 -121.995143   452.900000  24.253952   \n",
              "2021-11-23  41.841058  36.551543  -92.0 -108.176002 -1548.500000  24.319116   \n",
              "2021-11-24  44.514298  35.201249  -88.0  -52.910149   -44.769141  24.463882   \n",
              "\n",
              "                TRIX  \n",
              "Date                  \n",
              "2021-11-18 -0.261679  \n",
              "2021-11-19 -0.263001  \n",
              "2021-11-22 -0.265578  \n",
              "2021-11-23 -0.265649  \n",
              "2021-11-24 -0.262094  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataBV.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "OKOuTE7BNnXU"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "features = ['MACD', 'RSI', 'ADX', 'Aroon', 'CCI', 'DPO', 'MI', 'TRIX']\n",
        "for i in features:\n",
        "  dataSP[i] = scaler.fit_transform(dataSP[i].values.reshape(-1, 1))\n",
        "  dataUS[i] = scaler.fit_transform(dataUS[i].values.reshape(-1, 1))\n",
        "  dataBV[i] = scaler.fit_transform(dataBV[i].values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "cG1v674r4vgx",
        "outputId": "a12de20e-5355-44a6-bae3-bec119421595"
      },
      "outputs": [],
      "source": [
        "dataSP = dataSP.add_prefix('SP_')\n",
        "dataUS = dataUS.add_prefix('US_')\n",
        "dataBV = dataBV.add_prefix('BV_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dataBV.loc[dataBV.index.year == 2019,'BV_MACD'].plot()\n",
        "# plt.figure()\n",
        "# dataBV.loc[dataBV.index.year == 2019,'BV_1w target'].plot()\n",
        "# create figure and axis objects with subplots()\n",
        "\n",
        "fig,ax = plt.subplots()\n",
        "# make a plot\n",
        "ax.plot(dataBV.loc[dataBV.index.year == 2019,'BV_MACD'].index, dataBV.loc[dataBV.index.year == 2019,'BV_TRIX'], color=\"red\")\n",
        "# set x-axis label\n",
        "ax.set_xlabel(\"Data\",fontsize=14)\n",
        "# set y-axis label\n",
        "ax.set_ylabel(\"Valor Indicador\",color=\"red\",fontsize=14)\n",
        "# twin object for two different y-axis on the sample plot\n",
        "ax2=ax.twinx()\n",
        "# make a plot with different y-axis using second axis object\n",
        "ax2.plot(dataBV.loc[dataBV.index.year == 2019,'BV_1w target'].index, dataBV.loc[dataBV.index.year == 2019,'BV_Close'],color=\"blue\")\n",
        "ax2.set_ylabel(\"Retorno IBOV\",color=\"blue\",fontsize=14)\n",
        "plt.show()\n",
        "# save the plot as a file\n",
        "# fig.savefig('two_different_y_axis_for_single_python_plot_with_twinx.jpg',\n",
        "#             format='jpeg',\n",
        "#             dpi=100,\n",
        "#             bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.merge(left=dataBV, right=dataSP, how='left', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.merge(left=data, right=dataUS, how='left', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.fillna(axis='index', method='ffill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "allFeatures = ['BV_' + x for x in features] + ['US_' + x for x in features] + ['SP_' + x for x in features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "negociation = ['Open', 'High', 'Low', 'Close']\n",
        "allData = ['BV_' + x for x in negociation] + ['US_' + x for x in negociation] + ['SP_' + x for x in negociation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Date'>"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 'MACD', 'RSI', 'ADX', 'Aroon', 'CCI', 'DPO', 'MI', 'TRIX']\n",
        "data.loc[data.index.year == 2019 , 'BV_Aroon'].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ARIMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using Technical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "eYJHlEW7pWDR",
        "outputId": "003a5c15-1c7d-4d2e-f553-9fd64279b50d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:00<?, ?it/s]/home/lvenzel/anaconda3/lib/python3.8/site-packages/pmdarima/arima/_validation.py:76: UserWarning: stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "  warnings.warn('stepwise model cannot be fit in parallel (n_jobs=%i). '\n",
            " 17%|█▋        | 1/6 [00:15<01:15, 15.01s/it]/home/lvenzel/anaconda3/lib/python3.8/site-packages/pmdarima/arima/_validation.py:76: UserWarning: stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "  warnings.warn('stepwise model cannot be fit in parallel (n_jobs=%i). '\n",
            " 33%|███▎      | 2/6 [02:07<04:48, 72.06s/it]/home/lvenzel/anaconda3/lib/python3.8/site-packages/pmdarima/arima/_validation.py:76: UserWarning: stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "  warnings.warn('stepwise model cannot be fit in parallel (n_jobs=%i). '\n",
            " 50%|█████     | 3/6 [04:06<04:41, 93.88s/it]/home/lvenzel/anaconda3/lib/python3.8/site-packages/pmdarima/arima/_validation.py:76: UserWarning: stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "  warnings.warn('stepwise model cannot be fit in parallel (n_jobs=%i). '\n",
            " 67%|██████▋   | 4/6 [05:27<02:57, 88.63s/it]/home/lvenzel/anaconda3/lib/python3.8/site-packages/pmdarima/arima/_validation.py:76: UserWarning: stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "  warnings.warn('stepwise model cannot be fit in parallel (n_jobs=%i). '\n",
            " 83%|████████▎ | 5/6 [06:52<01:27, 87.41s/it]/home/lvenzel/anaconda3/lib/python3.8/site-packages/pmdarima/arima/_validation.py:76: UserWarning: stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "  warnings.warn('stepwise model cannot be fit in parallel (n_jobs=%i). '\n",
            "100%|██████████| 6/6 [08:23<00:00, 83.95s/it]\n"
          ]
        }
      ],
      "source": [
        "predictions_arima = {}\n",
        "auto_fitted = {}\n",
        "\n",
        "for i in trange(2016,2022):\n",
        "\n",
        "  X_train = data.loc[(data.index.year >= i - 8) & (data.index.year < i - 1), allFeatures]\n",
        "  y_train = data.loc[(data.index.year >= i - 8) & (data.index.year < i - 1), 'BV_1w target']\n",
        "\n",
        "  X_valid = data.loc[data.index.year == i - 1, allFeatures]\n",
        "  y_valid = data.loc[data.index.year == i - 1, 'BV_1w target']\n",
        "\n",
        "  X_test = data.loc[data.index.year == i, allFeatures]\n",
        "  y_test = data.loc[data.index.year == i, 'BV_1w target']\n",
        "\n",
        "  auto_fitted[i] = auto_arima(y=y_train, start_p=0, start_q=0, max_p=10, max_q=10, n_jobs=-1, test='adf')\n",
        "  predictions_arima[i] = pd.DataFrame(auto_fitted[i].predict(len(X_test), X_test[allFeatures]), index=X_test.index, columns=['Predictions'])\n",
        "  predictions_arima[i]['True'] = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "w3804LuHJYNg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               SARIMAX Results                                \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                 1731\n",
            "Model:               SARIMAX(6, 0, 0)   Log Likelihood                4097.857\n",
            "Date:                Wed, 17 Nov 2021   AIC                          -8181.714\n",
            "Time:                        22:10:54   BIC                          -8143.519\n",
            "Sample:                             0   HQIC                         -8167.587\n",
            "                               - 1731                                         \n",
            "Covariance Type:                  opg                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ar.L1          0.8560      0.014     59.236      0.000       0.828       0.884\n",
            "ar.L2          0.0110      0.020      0.560      0.576      -0.028       0.050\n",
            "ar.L3         -0.0824      0.019     -4.336      0.000      -0.120      -0.045\n",
            "ar.L4          0.0247      0.021      1.157      0.247      -0.017       0.066\n",
            "ar.L5         -0.3779      0.019    -20.127      0.000      -0.415      -0.341\n",
            "ar.L6          0.2957      0.014     20.476      0.000       0.267       0.324\n",
            "sigma2         0.0005   9.27e-06     55.404      0.000       0.000       0.001\n",
            "===================================================================================\n",
            "Ljung-Box (L1) (Q):                   0.22   Jarque-Bera (JB):              2270.29\n",
            "Prob(Q):                              0.64   Prob(JB):                         0.00\n",
            "Heteroskedasticity (H):               0.32   Skew:                            -0.29\n",
            "Prob(H) (two-sided):                  0.00   Kurtosis:                         8.58\n",
            "===================================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
          ]
        }
      ],
      "source": [
        "print(auto_fitted[2016].summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  ARIMA R²: -0.03476304897471083\n",
            "  ARIMA MAE: 0.029162941738576642\n",
            "  ARIMA MSE: 0.001417540087359177\n",
            "2017\n",
            "  ARIMA R²: -0.05686759067573077\n",
            "  ARIMA MAE: 0.020215127836925664\n",
            "  ARIMA MSE: 0.0006477617152177684\n",
            "2018\n",
            "  ARIMA R²: -0.009977133990809683\n",
            "  ARIMA MAE: 0.02297214864723402\n",
            "  ARIMA MSE: 0.0008521001419671584\n",
            "2019\n",
            "  ARIMA R²: -0.028148090959849492\n",
            "  ARIMA MAE: 0.018551596575525724\n",
            "  ARIMA MSE: 0.0005162661341870973\n",
            "2020\n",
            "  ARIMA R²: -0.006732913843240151\n",
            "  ARIMA MAE: 0.03444899211786769\n",
            "  ARIMA MSE: 0.002919528352612741\n",
            "2021\n",
            "  ARIMA R²: -0.0037942981616343463\n",
            "  ARIMA MAE: 0.018143481289848176\n",
            "  ARIMA MSE: 0.0005443765921456017\n"
          ]
        }
      ],
      "source": [
        "for i in predictions_arima.keys():\n",
        "  print(i)\n",
        "  print('  ARIMA R²: {}'.format(r2_score(predictions_arima[i]['True'],predictions_arima[i]['Predictions'])))\n",
        "  print('  ARIMA MAE: {}'.format(mean_absolute_error(predictions_arima[i]['True'],predictions_arima[i]['Predictions'])))\n",
        "  print('  ARIMA MSE: {}'.format(mean_squared_error(predictions_arima[i]['True'],predictions_arima[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_arima = {}\n",
        "for i in predictions_arima.keys():\n",
        "  classification_arima[i] = predictions_arima[i].applymap(lambda x: 0 if x < 0 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  ARIMA F1: 0.5342960288808665\n",
            "  ARIMA Accu: 0.4819277108433735\n",
            "  ARIMA precision: 0.5967741935483871\n",
            "  ARIMA Recall: 0.48366013071895425\n",
            "2017\n",
            "  ARIMA F1: 0.5407407407407406\n",
            "  ARIMA Accu: 0.4979757085020243\n",
            "  ARIMA precision: 0.5934959349593496\n",
            "  ARIMA Recall: 0.4965986394557823\n",
            "2018\n",
            "  ARIMA F1: 0.5307692307692308\n",
            "  ARIMA Accu: 0.5\n",
            "  ARIMA precision: 0.5564516129032258\n",
            "  ARIMA Recall: 0.5073529411764706\n",
            "2019\n",
            "  ARIMA F1: 0.5563380281690141\n",
            "  ARIMA Accu: 0.4898785425101215\n",
            "  ARIMA precision: 0.6422764227642277\n",
            "  ARIMA Recall: 0.4906832298136646\n",
            "2020\n",
            "  ARIMA F1: 0.5543071161048688\n",
            "  ARIMA Accu: 0.5182186234817814\n",
            "  ARIMA precision: 0.6166666666666667\n",
            "  ARIMA Recall: 0.5034013605442177\n",
            "2021\n",
            "  ARIMA F1: 0.6179401993355482\n",
            "  ARIMA Accu: 0.44711538461538464\n",
            "  ARIMA precision: 0.44711538461538464\n",
            "  ARIMA Recall: 1.0\n"
          ]
        }
      ],
      "source": [
        "for i in classification_arima.keys():\n",
        "  print(i)\n",
        "  print('  ARIMA F1: {}'.format(f1_score(classification_arima[i]['True'],classification_arima[i]['Predictions'])))\n",
        "  print('  ARIMA Accu: {}'.format(accuracy_score(classification_arima[i]['True'],classification_arima[i]['Predictions'])))\n",
        "  print('  ARIMA precision: {}'.format(precision_score(classification_arima[i]['True'],classification_arima[i]['Predictions'])))\n",
        "  print('  ARIMA Recall: {}'.format(recall_score(classification_arima[i]['True'],classification_arima[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-102-0d54598ab2fe>:2: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  classification_arima[i]['week'] = classification_arima[i].index.week\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016: patrimonio final long-only: 170.2832727059861, long-short: 200.05158765443147\n",
            "2017: patrimonio final long-only: 124.43337058190613, long-short: 124.76622129036447\n",
            "2018: patrimonio final long-only: 112.62001011100442, long-short: 105.14391959092588\n",
            "2019: patrimonio final long-only: 122.45916101553493, long-short: 112.06531099341234\n",
            "2020: patrimonio final long-only: 77.02732187843421, long-short: 52.07456409123568\n",
            "2021: patrimonio final long-only: 87.86583709648168, long-short: 87.86583709648168\n"
          ]
        }
      ],
      "source": [
        "for i in classification_arima.keys():\n",
        "  classification_arima[i]['week'] = classification_arima[i].index.week\n",
        "  classification_arima[i]['True'] = predictions_arima[i]['True'] + 1\n",
        "  result = classification_arima[i].groupby('week', as_index=False).first()\n",
        "  patrimonio = 100\n",
        "  patrimonio2 = 100\n",
        "  for j in result.index:\n",
        "    if result.loc[j, 'Predictions'] == 1:\n",
        "      patrimonio *= result.loc[j, 'True']\n",
        "      patrimonio2 *= result.loc[j, 'True']\n",
        "    else:\n",
        "      patrimonio2 *= 2 - result.loc[j, 'True']\n",
        "  print('{}: patrimonio final long-only: {}, long-short: {}'.format(i, patrimonio, patrimonio2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "nGA2k3qJ96K7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[32m[I 2021-11-17 22:10:55,202]\u001b[0m A new study created in memory with name: no-name-59e27c41-0d71-428e-9c20-e0b69acd056c\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:10:56,647]\u001b[0m Trial 0 finished with value: -0.0084579985372919 and parameters: {'loss': 'lad', 'learning_rate': 1.4249170093325433e-05, 'n_estimators': 293, 'subsample': 0.34623017275126167, 'criterion': 'friedman_mse', 'min_samples_split': 30, 'min_samples_leaf': 4, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 0 with value: -0.0084579985372919.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:10:58,727]\u001b[0m Trial 1 finished with value: -0.08322081962436267 and parameters: {'loss': 'lad', 'learning_rate': 0.0064645344274017165, 'n_estimators': 447, 'subsample': 0.5034030313696921, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 8, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 0 with value: -0.0084579985372919.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:00,747]\u001b[0m Trial 2 finished with value: -0.008637475533395778 and parameters: {'loss': 'huber', 'learning_rate': 2.869517052978395e-05, 'n_estimators': 377, 'subsample': 0.24367488038352378, 'criterion': 'friedman_mse', 'min_samples_split': 32, 'min_samples_leaf': 7, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 0 with value: -0.0084579985372919.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:01,851]\u001b[0m Trial 3 finished with value: -0.30397667650907967 and parameters: {'loss': 'ls', 'learning_rate': 0.01854062742173733, 'n_estimators': 645, 'subsample': 0.15769959745513187, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 8, 'max_depth': 4, 'max_features': 'auto'}. Best is trial 0 with value: -0.0084579985372919.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:06,627]\u001b[0m Trial 4 finished with value: -2.1929644740050667 and parameters: {'loss': 'quantile', 'learning_rate': 2.2033497015687328e-05, 'n_estimators': 734, 'subsample': 0.43243848340153146, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_depth': 4, 'max_features': 'auto'}. Best is trial 0 with value: -0.0084579985372919.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:06,882]\u001b[0m Trial 5 finished with value: -0.0049418281391462315 and parameters: {'loss': 'ls', 'learning_rate': 1.6291561516572913e-06, 'n_estimators': 96, 'subsample': 0.5009881655030604, 'criterion': 'friedman_mse', 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:22,776]\u001b[0m Trial 6 finished with value: -0.030939590893630076 and parameters: {'loss': 'lad', 'learning_rate': 0.001399869494879603, 'n_estimators': 805, 'subsample': 0.6263428912535995, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:24,796]\u001b[0m Trial 7 finished with value: -0.02455953811710221 and parameters: {'loss': 'huber', 'learning_rate': 0.0012715626909651425, 'n_estimators': 334, 'subsample': 0.44518428459266124, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 5, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:27,543]\u001b[0m Trial 8 finished with value: -0.3766885065482817 and parameters: {'loss': 'huber', 'learning_rate': 0.0550006154781166, 'n_estimators': 203, 'subsample': 0.42217800820172013, 'criterion': 'friedman_mse', 'min_samples_split': 44, 'min_samples_leaf': 7, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:34,849]\u001b[0m Trial 9 finished with value: -2.232669164187612 and parameters: {'loss': 'quantile', 'learning_rate': 0.00031579456110510936, 'n_estimators': 994, 'subsample': 0.6816074971704797, 'criterion': 'friedman_mse', 'min_samples_split': 29, 'min_samples_leaf': 9, 'max_depth': 3, 'max_features': 'auto'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:35,810]\u001b[0m Trial 10 finished with value: -0.00494909327309867 and parameters: {'loss': 'ls', 'learning_rate': 1.465503288568625e-06, 'n_estimators': 157, 'subsample': 0.9109919354749207, 'criterion': 'friedman_mse', 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:35,913]\u001b[0m Trial 11 finished with value: -0.004945217993616913 and parameters: {'loss': 'ls', 'learning_rate': 1.0798934024427401e-06, 'n_estimators': 13, 'subsample': 0.9775235884545829, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:36,018]\u001b[0m Trial 12 finished with value: -0.0049479430128696045 and parameters: {'loss': 'ls', 'learning_rate': 1.0625619973844963e-06, 'n_estimators': 15, 'subsample': 0.9681278461196059, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:36,115]\u001b[0m Trial 13 finished with value: -0.004948991986407192 and parameters: {'loss': 'ls', 'learning_rate': 2.288037672112002e-06, 'n_estimators': 18, 'subsample': 0.7891402717331336, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:36,848]\u001b[0m Trial 14 finished with value: -0.004952238918593865 and parameters: {'loss': 'ls', 'learning_rate': 5.9908008624913116e-06, 'n_estimators': 171, 'subsample': 0.7729761408651789, 'criterion': 'friedman_mse', 'min_samples_split': 22, 'min_samples_leaf': 2, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:37,267]\u001b[0m Trial 15 finished with value: -0.00504693006212098 and parameters: {'loss': 'ls', 'learning_rate': 8.638864246460792e-05, 'n_estimators': 100, 'subsample': 0.6196308759845601, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:39,739]\u001b[0m Trial 16 finished with value: -0.005000718344948751 and parameters: {'loss': 'ls', 'learning_rate': 4.4746821369982056e-06, 'n_estimators': 534, 'subsample': 0.7741150281246332, 'criterion': 'friedman_mse', 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:40,131]\u001b[0m Trial 17 finished with value: -0.005793277974138089 and parameters: {'loss': 'ls', 'learning_rate': 0.0001032459336342931, 'n_estimators': 239, 'subsample': 0.32815674127755556, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 9, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:40,598]\u001b[0m Trial 18 finished with value: -0.0049503095044372 and parameters: {'loss': 'ls', 'learning_rate': 7.318614174568801e-06, 'n_estimators': 95, 'subsample': 0.8879760983036217, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 10, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:43,431]\u001b[0m Trial 19 finished with value: -2.196942178149744 and parameters: {'loss': 'quantile', 'learning_rate': 6.630715971262359e-05, 'n_estimators': 510, 'subsample': 0.5336480459391464, 'criterion': 'friedman_mse', 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:43,490]\u001b[0m Trial 20 finished with value: -0.00494865551849788 and parameters: {'loss': 'ls', 'learning_rate': 1.0224302334096925e-06, 'n_estimators': 81, 'subsample': 0.11167476751912714, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:43,679]\u001b[0m Trial 21 finished with value: -0.004943520758232012 and parameters: {'loss': 'ls', 'learning_rate': 3.163147837306969e-06, 'n_estimators': 31, 'subsample': 0.9358526223065449, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:43,827]\u001b[0m Trial 22 finished with value: -0.004952311850083824 and parameters: {'loss': 'ls', 'learning_rate': 3.3963746034566317e-06, 'n_estimators': 21, 'subsample': 0.9893022489872498, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 3, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:45,322]\u001b[0m Trial 23 finished with value: -0.00495978461022184 and parameters: {'loss': 'ls', 'learning_rate': 9.11645073576363e-06, 'n_estimators': 270, 'subsample': 0.8700412685532404, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:45,827]\u001b[0m Trial 24 finished with value: -0.0049495049980279315 and parameters: {'loss': 'ls', 'learning_rate': 2.2904728171845857e-06, 'n_estimators': 140, 'subsample': 0.6907022259807132, 'criterion': 'friedman_mse', 'min_samples_split': 19, 'min_samples_leaf': 3, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:47,862]\u001b[0m Trial 25 finished with value: -0.005265959228964334 and parameters: {'loss': 'ls', 'learning_rate': 3.502448203216606e-05, 'n_estimators': 407, 'subsample': 0.8363112904379483, 'criterion': 'friedman_mse', 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:52,038]\u001b[0m Trial 26 finished with value: -0.008411639577080132 and parameters: {'loss': 'lad', 'learning_rate': 3.701852781003533e-06, 'n_estimators': 210, 'subsample': 0.9308101688908533, 'criterion': 'friedman_mse', 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:53,669]\u001b[0m Trial 27 finished with value: -0.00929636339611184 and parameters: {'loss': 'huber', 'learning_rate': 0.00023126919891125057, 'n_estimators': 71, 'subsample': 0.5988286033427003, 'criterion': 'friedman_mse', 'min_samples_split': 25, 'min_samples_leaf': 3, 'max_depth': 11, 'max_features': 'auto'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:55,653]\u001b[0m Trial 28 finished with value: -2.1922232936272454 and parameters: {'loss': 'quantile', 'learning_rate': 1.2542243013226485e-05, 'n_estimators': 133, 'subsample': 0.7234834009662323, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:11:57,801]\u001b[0m Trial 29 finished with value: -0.008434753160895037 and parameters: {'loss': 'lad', 'learning_rate': 1.3312256672905619e-05, 'n_estimators': 294, 'subsample': 0.35035231108830384, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:00,501]\u001b[0m Trial 30 finished with value: -0.004977129872557606 and parameters: {'loss': 'ls', 'learning_rate': 2.068416082666096e-06, 'n_estimators': 591, 'subsample': 0.8178095881422329, 'criterion': 'friedman_mse', 'min_samples_split': 27, 'min_samples_leaf': 9, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:00,599]\u001b[0m Trial 31 finished with value: -0.004945755350760139 and parameters: {'loss': 'ls', 'learning_rate': 1.0110669134447136e-06, 'n_estimators': 13, 'subsample': 0.9951695354923166, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:00,697]\u001b[0m Trial 32 finished with value: -0.004949524894766633 and parameters: {'loss': 'ls', 'learning_rate': 2.495782481593141e-06, 'n_estimators': 13, 'subsample': 0.9496386917647498, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:01,117]\u001b[0m Trial 33 finished with value: -0.004945410144384876 and parameters: {'loss': 'ls', 'learning_rate': 1.070431557251409e-06, 'n_estimators': 72, 'subsample': 0.9873384815041052, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:02,078]\u001b[0m Trial 34 finished with value: -0.009671408625602673 and parameters: {'loss': 'ls', 'learning_rate': 0.0014058207845914238, 'n_estimators': 190, 'subsample': 0.8959426922196084, 'criterion': 'friedman_mse', 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:03,239]\u001b[0m Trial 35 finished with value: -0.00838332531762842 and parameters: {'loss': 'lad', 'learning_rate': 5.7855951576790395e-06, 'n_estimators': 75, 'subsample': 0.4860434588977802, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 5 with value: -0.0049418281391462315.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:04,384]\u001b[0m Trial 36 finished with value: -0.004937451150889949 and parameters: {'loss': 'ls', 'learning_rate': 2.0917033567314384e-05, 'n_estimators': 334, 'subsample': 0.8581569317242492, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 8, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:08,888]\u001b[0m Trial 37 finished with value: -0.008415654550874896 and parameters: {'loss': 'huber', 'learning_rate': 2.515597812265442e-05, 'n_estimators': 345, 'subsample': 0.5781010262458004, 'criterion': 'friedman_mse', 'min_samples_split': 35, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:12,592]\u001b[0m Trial 38 finished with value: -2.196265239390586 and parameters: {'loss': 'quantile', 'learning_rate': 4.101020648863072e-05, 'n_estimators': 472, 'subsample': 0.8397471201856417, 'criterion': 'friedman_mse', 'min_samples_split': 37, 'min_samples_leaf': 7, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:12,926]\u001b[0m Trial 39 finished with value: -0.005180961493294944 and parameters: {'loss': 'ls', 'learning_rate': 1.8206510393092026e-05, 'n_estimators': 266, 'subsample': 0.27351514690989526, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 9, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:17,398]\u001b[0m Trial 40 finished with value: -0.02961192314420713 and parameters: {'loss': 'huber', 'learning_rate': 0.0030672363749629852, 'n_estimators': 322, 'subsample': 0.7213670051409511, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 7, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:18,148]\u001b[0m Trial 41 finished with value: -0.004944277167886035 and parameters: {'loss': 'ls', 'learning_rate': 1.6236916561878198e-06, 'n_estimators': 123, 'subsample': 0.944353277120197, 'criterion': 'friedman_mse', 'min_samples_split': 28, 'min_samples_leaf': 8, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:20,372]\u001b[0m Trial 42 finished with value: -0.004962618288610443 and parameters: {'loss': 'ls', 'learning_rate': 1.918823991882387e-06, 'n_estimators': 395, 'subsample': 0.8805476613731554, 'criterion': 'friedman_mse', 'min_samples_split': 34, 'min_samples_leaf': 8, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:20,861]\u001b[0m Trial 43 finished with value: -0.004941827996537418 and parameters: {'loss': 'ls', 'learning_rate': 3.739445082570313e-06, 'n_estimators': 130, 'subsample': 0.9312406982410989, 'criterion': 'friedman_mse', 'min_samples_split': 29, 'min_samples_leaf': 8, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:21,678]\u001b[0m Trial 44 finished with value: -0.004947044403589507 and parameters: {'loss': 'ls', 'learning_rate': 8.832235176302714e-06, 'n_estimators': 221, 'subsample': 0.9314388212836489, 'criterion': 'friedman_mse', 'min_samples_split': 29, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:23,719]\u001b[0m Trial 45 finished with value: -0.0049656532395412345 and parameters: {'loss': 'ls', 'learning_rate': 4.027585896131302e-06, 'n_estimators': 719, 'subsample': 0.6489666038620765, 'criterion': 'friedman_mse', 'min_samples_split': 27, 'min_samples_leaf': 8, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:23,943]\u001b[0m Trial 46 finished with value: -0.03650945479027046 and parameters: {'loss': 'lad', 'learning_rate': 0.02143558035513453, 'n_estimators': 132, 'subsample': 0.40423003746938535, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 8, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:24,428]\u001b[0m Trial 47 finished with value: -0.004957486704953107 and parameters: {'loss': 'ls', 'learning_rate': 3.4385566481857885e-06, 'n_estimators': 157, 'subsample': 0.8458846212279499, 'criterion': 'friedman_mse', 'min_samples_split': 40, 'min_samples_leaf': 6, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:24,624]\u001b[0m Trial 48 finished with value: -0.004951942193838432 and parameters: {'loss': 'ls', 'learning_rate': 1.0735874400169819e-05, 'n_estimators': 110, 'subsample': 0.5044050018670158, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 7, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:31,272]\u001b[0m Trial 49 finished with value: -2.1925155602993667 and parameters: {'loss': 'quantile', 'learning_rate': 1.7050176449757358e-06, 'n_estimators': 240, 'subsample': 0.9290886532984498, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 9, 'max_depth': 9, 'max_features': 'auto'}. Best is trial 36 with value: -0.004937451150889949.\u001b[0m\n",
            " 17%|█▋        | 1/6 [01:37<08:06, 97.21s/it]\u001b[32m[I 2021-11-17 22:12:32,411]\u001b[0m A new study created in memory with name: no-name-c8d01fcb-2fa0-4dce-aceb-4762f875e3da\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:32,571]\u001b[0m Trial 0 finished with value: -0.03986693260325036 and parameters: {'loss': 'lad', 'learning_rate': 6.93646079644829e-06, 'n_estimators': 15, 'subsample': 0.5635627223917689, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 7, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 0 with value: -0.03986693260325036.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:45,426]\u001b[0m Trial 1 finished with value: -0.5061390315236931 and parameters: {'loss': 'quantile', 'learning_rate': 0.010068123555625202, 'n_estimators': 974, 'subsample': 0.5688207187416033, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 10, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 0 with value: -0.03986693260325036.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:46,129]\u001b[0m Trial 2 finished with value: -0.03981362682073253 and parameters: {'loss': 'huber', 'learning_rate': 8.050775459775387e-06, 'n_estimators': 131, 'subsample': 0.2343201840354017, 'criterion': 'friedman_mse', 'min_samples_split': 41, 'min_samples_leaf': 7, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:12:54,524]\u001b[0m Trial 3 finished with value: -0.04108381791537674 and parameters: {'loss': 'huber', 'learning_rate': 0.00013365385945403346, 'n_estimators': 344, 'subsample': 0.7099648994258249, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:06,984]\u001b[0m Trial 4 finished with value: -0.03986109733835841 and parameters: {'loss': 'lad', 'learning_rate': 2.068662701586432e-06, 'n_estimators': 669, 'subsample': 0.7262487641936095, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:09,185]\u001b[0m Trial 5 finished with value: -0.11146700839984636 and parameters: {'loss': 'ls', 'learning_rate': 0.004542536986510641, 'n_estimators': 685, 'subsample': 0.3358249510196267, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 6, 'max_depth': 3, 'max_features': 'auto'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:09,882]\u001b[0m Trial 6 finished with value: -0.046732037601154186 and parameters: {'loss': 'ls', 'learning_rate': 0.001044865948354905, 'n_estimators': 429, 'subsample': 0.7632753545517769, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 5, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:10,571]\u001b[0m Trial 7 finished with value: -0.7865915489286781 and parameters: {'loss': 'quantile', 'learning_rate': 0.007759152243120431, 'n_estimators': 119, 'subsample': 0.15147446812229043, 'criterion': 'friedman_mse', 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_depth': 8, 'max_features': 'auto'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:10,673]\u001b[0m Trial 8 finished with value: -0.040675228612187864 and parameters: {'loss': 'ls', 'learning_rate': 0.0017074323797097424, 'n_estimators': 33, 'subsample': 0.24763499556169893, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 8, 'max_depth': 4, 'max_features': 'auto'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:11,068]\u001b[0m Trial 9 finished with value: -0.6090144903613941 and parameters: {'loss': 'ls', 'learning_rate': 0.0633742321314766, 'n_estimators': 600, 'subsample': 0.19164247388319913, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 9, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:16,053]\u001b[0m Trial 10 finished with value: -0.04032085199846325 and parameters: {'loss': 'huber', 'learning_rate': 7.143920980358685e-05, 'n_estimators': 273, 'subsample': 0.9821032843088275, 'criterion': 'friedman_mse', 'min_samples_split': 47, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:22,731]\u001b[0m Trial 11 finished with value: -0.03983819808206812 and parameters: {'loss': 'lad', 'learning_rate': 1.2595209745620773e-06, 'n_estimators': 807, 'subsample': 0.448102880544734, 'criterion': 'friedman_mse', 'min_samples_split': 46, 'min_samples_leaf': 4, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 2 with value: -0.03981362682073253.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:30,619]\u001b[0m Trial 12 finished with value: -0.03964500277929961 and parameters: {'loss': 'huber', 'learning_rate': 1.5220878826617902e-05, 'n_estimators': 897, 'subsample': 0.39312612035699007, 'criterion': 'friedman_mse', 'min_samples_split': 48, 'min_samples_leaf': 5, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 12 with value: -0.03964500277929961.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:38,962]\u001b[0m Trial 13 finished with value: -0.039497706557666046 and parameters: {'loss': 'huber', 'learning_rate': 2.1888877233721357e-05, 'n_estimators': 992, 'subsample': 0.37503983967612753, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 7, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 13 with value: -0.039497706557666046.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:47,745]\u001b[0m Trial 14 finished with value: -0.03950202044774054 and parameters: {'loss': 'huber', 'learning_rate': 3.0617827454825085e-05, 'n_estimators': 990, 'subsample': 0.3998611976433324, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 6, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 13 with value: -0.039497706557666046.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:13:57,904]\u001b[0m Trial 15 finished with value: -0.039288999974953276 and parameters: {'loss': 'huber', 'learning_rate': 3.6896287183484106e-05, 'n_estimators': 989, 'subsample': 0.45171603724386133, 'criterion': 'friedman_mse', 'min_samples_split': 38, 'min_samples_leaf': 7, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 15 with value: -0.039288999974953276.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:04,549]\u001b[0m Trial 16 finished with value: -0.04114459811454707 and parameters: {'loss': 'huber', 'learning_rate': 0.00029419333155737557, 'n_estimators': 806, 'subsample': 0.503366020998777, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 8, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 15 with value: -0.039288999974953276.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:11,894]\u001b[0m Trial 17 finished with value: -0.040177690826989965 and parameters: {'loss': 'huber', 'learning_rate': 5.328594614563257e-05, 'n_estimators': 873, 'subsample': 0.6316421334799123, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 8, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 15 with value: -0.039288999974953276.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:16,969]\u001b[0m Trial 18 finished with value: -0.0349722961410015 and parameters: {'loss': 'huber', 'learning_rate': 0.0005107513182098041, 'n_estimators': 552, 'subsample': 0.334980358207874, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 18 with value: -0.0349722961410015.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:19,952]\u001b[0m Trial 19 finished with value: -0.7456603199104486 and parameters: {'loss': 'quantile', 'learning_rate': 0.0005004899274052054, 'n_estimators': 528, 'subsample': 0.29848773883829344, 'criterion': 'friedman_mse', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 18 with value: -0.0349722961410015.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:23,779]\u001b[0m Trial 20 finished with value: -0.04202387289876186 and parameters: {'loss': 'huber', 'learning_rate': 0.00017712916867586778, 'n_estimators': 437, 'subsample': 0.8627937384715176, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 18 with value: -0.0349722961410015.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:31,299]\u001b[0m Trial 21 finished with value: -0.03971273672532982 and parameters: {'loss': 'huber', 'learning_rate': 2.174131387349361e-05, 'n_estimators': 750, 'subsample': 0.46192513524722995, 'criterion': 'friedman_mse', 'min_samples_split': 30, 'min_samples_leaf': 7, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 18 with value: -0.0349722961410015.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:36,716]\u001b[0m Trial 22 finished with value: -0.039783810250162865 and parameters: {'loss': 'huber', 'learning_rate': 3.1461571789043296e-06, 'n_estimators': 892, 'subsample': 0.3057285772447882, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 9, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 18 with value: -0.0349722961410015.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:45,389]\u001b[0m Trial 23 finished with value: -0.03888514389332065 and parameters: {'loss': 'huber', 'learning_rate': 8.423965655703704e-05, 'n_estimators': 987, 'subsample': 0.3582233792952531, 'criterion': 'friedman_mse', 'min_samples_split': 27, 'min_samples_leaf': 6, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 18 with value: -0.0349722961410015.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:47,271]\u001b[0m Trial 24 finished with value: -0.028873338568589313 and parameters: {'loss': 'huber', 'learning_rate': 0.0007096714652636612, 'n_estimators': 567, 'subsample': 0.10581885095939991, 'criterion': 'friedman_mse', 'min_samples_split': 24, 'min_samples_leaf': 6, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 24 with value: -0.028873338568589313.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:49,158]\u001b[0m Trial 25 finished with value: -0.0257170952877237 and parameters: {'loss': 'huber', 'learning_rate': 0.0008839274252484241, 'n_estimators': 561, 'subsample': 0.10515712315315458, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 6, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:51,312]\u001b[0m Trial 26 finished with value: -0.02875740028653584 and parameters: {'loss': 'huber', 'learning_rate': 0.0018436098923210738, 'n_estimators': 559, 'subsample': 0.10761615173209732, 'criterion': 'friedman_mse', 'min_samples_split': 22, 'min_samples_leaf': 4, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:53,865]\u001b[0m Trial 27 finished with value: -0.0367293945765248 and parameters: {'loss': 'lad', 'learning_rate': 0.0026180983038505703, 'n_estimators': 615, 'subsample': 0.10709734391637891, 'criterion': 'friedman_mse', 'min_samples_split': 21, 'min_samples_leaf': 4, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:54,962]\u001b[0m Trial 28 finished with value: -1.174402731531523 and parameters: {'loss': 'quantile', 'learning_rate': 0.04813643524190997, 'n_estimators': 460, 'subsample': 0.10174359549326512, 'criterion': 'friedman_mse', 'min_samples_split': 22, 'min_samples_leaf': 4, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:14:56,248]\u001b[0m Trial 29 finished with value: -0.08665878350385259 and parameters: {'loss': 'lad', 'learning_rate': 0.020871601965245592, 'n_estimators': 338, 'subsample': 0.18582516853037784, 'criterion': 'friedman_mse', 'min_samples_split': 30, 'min_samples_leaf': 5, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:01,519]\u001b[0m Trial 30 finished with value: -0.04713232052851679 and parameters: {'loss': 'huber', 'learning_rate': 0.0013031884272432898, 'n_estimators': 669, 'subsample': 0.25207356788155244, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:06,466]\u001b[0m Trial 31 finished with value: -0.034721479846058 and parameters: {'loss': 'huber', 'learning_rate': 0.00046138077231775, 'n_estimators': 563, 'subsample': 0.16125275282337825, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:08,960]\u001b[0m Trial 32 finished with value: -0.03678309395309265 and parameters: {'loss': 'huber', 'learning_rate': 0.000734243221986917, 'n_estimators': 489, 'subsample': 0.16200231108204133, 'criterion': 'friedman_mse', 'min_samples_split': 27, 'min_samples_leaf': 2, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:12,294]\u001b[0m Trial 33 finished with value: -0.042156762516877944 and parameters: {'loss': 'huber', 'learning_rate': 0.0030039775757907264, 'n_estimators': 586, 'subsample': 0.10077849116537067, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:15,025]\u001b[0m Trial 34 finished with value: -0.03906311735738921 and parameters: {'loss': 'huber', 'learning_rate': 0.0002939906334420974, 'n_estimators': 379, 'subsample': 0.22025166718294337, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:18,901]\u001b[0m Trial 35 finished with value: -0.15252149136893034 and parameters: {'loss': 'huber', 'learning_rate': 0.013125308567969752, 'n_estimators': 721, 'subsample': 0.1464817003028467, 'criterion': 'friedman_mse', 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:23,217]\u001b[0m Trial 36 finished with value: -0.7703669733469718 and parameters: {'loss': 'quantile', 'learning_rate': 0.00016179530533109502, 'n_estimators': 518, 'subsample': 0.25836898973562994, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 6, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:28,244]\u001b[0m Trial 37 finished with value: -0.07909730862860531 and parameters: {'loss': 'huber', 'learning_rate': 0.004610578411820293, 'n_estimators': 638, 'subsample': 0.20187601845060604, 'criterion': 'friedman_mse', 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:28,456]\u001b[0m Trial 38 finished with value: -0.03632764206632633 and parameters: {'loss': 'ls', 'learning_rate': 0.0008890342668743091, 'n_estimators': 274, 'subsample': 0.15370031634219414, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:30,927]\u001b[0m Trial 39 finished with value: -0.03746510615254128 and parameters: {'loss': 'lad', 'learning_rate': 0.0020617928496070317, 'n_estimators': 550, 'subsample': 0.28045058517431815, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 4, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:34,125]\u001b[0m Trial 40 finished with value: -0.03349096516371275 and parameters: {'loss': 'huber', 'learning_rate': 0.0003841992322247861, 'n_estimators': 416, 'subsample': 0.13231504252125048, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_depth': 11, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:37,223]\u001b[0m Trial 41 finished with value: -0.034518862297556074 and parameters: {'loss': 'huber', 'learning_rate': 0.0005288397909403145, 'n_estimators': 398, 'subsample': 0.13752404297203152, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_depth': 11, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:39,396]\u001b[0m Trial 42 finished with value: -0.0472434963613102 and parameters: {'loss': 'huber', 'learning_rate': 0.005416935696462094, 'n_estimators': 397, 'subsample': 0.1297917306566965, 'criterion': 'friedman_mse', 'min_samples_split': 24, 'min_samples_leaf': 6, 'max_depth': 12, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:42,719]\u001b[0m Trial 43 finished with value: -0.03402384197024033 and parameters: {'loss': 'huber', 'learning_rate': 0.001348624995120039, 'n_estimators': 282, 'subsample': 0.21234378018147065, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:43,690]\u001b[0m Trial 44 finished with value: -0.04055082787547226 and parameters: {'loss': 'ls', 'learning_rate': 0.0011286192712185975, 'n_estimators': 237, 'subsample': 0.20253161323911303, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:45,462]\u001b[0m Trial 45 finished with value: -0.03902234400454696 and parameters: {'loss': 'huber', 'learning_rate': 0.0018536293403209607, 'n_estimators': 175, 'subsample': 0.22697572293203924, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 5, 'max_depth': 9, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:47,850]\u001b[0m Trial 46 finished with value: -0.039237301316294104 and parameters: {'loss': 'huber', 'learning_rate': 0.00021324688738750237, 'n_estimators': 340, 'subsample': 0.17581141440857562, 'criterion': 'friedman_mse', 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:55,525]\u001b[0m Trial 47 finished with value: -0.6460496452133613 and parameters: {'loss': 'quantile', 'learning_rate': 0.008619845934481264, 'n_estimators': 485, 'subsample': 0.5956506692863447, 'criterion': 'friedman_mse', 'min_samples_split': 25, 'min_samples_leaf': 6, 'max_depth': 8, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:55,976]\u001b[0m Trial 48 finished with value: -0.035689231703515345 and parameters: {'loss': 'huber', 'learning_rate': 0.003056439344625203, 'n_estimators': 81, 'subsample': 0.10169287852175071, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:15:56,835]\u001b[0m Trial 49 finished with value: -0.03990941315431806 and parameters: {'loss': 'ls', 'learning_rate': 9.973840997770243e-05, 'n_estimators': 213, 'subsample': 0.2241847315914298, 'criterion': 'friedman_mse', 'min_samples_split': 28, 'min_samples_leaf': 6, 'max_depth': 9, 'max_features': 'auto'}. Best is trial 25 with value: -0.0257170952877237.\u001b[0m\n",
            " 33%|███▎      | 2/6 [05:03<10:45, 161.35s/it]\u001b[32m[I 2021-11-17 22:15:58,664]\u001b[0m A new study created in memory with name: no-name-c104ac25-9d47-4e34-a75b-9650a3dc76c2\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:02,295]\u001b[0m Trial 0 finished with value: -0.03451947702344582 and parameters: {'loss': 'huber', 'learning_rate': 6.108533380165819e-06, 'n_estimators': 321, 'subsample': 0.9270154140705608, 'criterion': 'friedman_mse', 'min_samples_split': 44, 'min_samples_leaf': 5, 'max_depth': 9, 'max_features': 'sqrt'}. Best is trial 0 with value: -0.03451947702344582.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:03,266]\u001b[0m Trial 1 finished with value: -0.030309855004340136 and parameters: {'loss': 'ls', 'learning_rate': 0.0003339535178316224, 'n_estimators': 748, 'subsample': 0.3542201234736534, 'criterion': 'friedman_mse', 'min_samples_split': 49, 'min_samples_leaf': 10, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:03,853]\u001b[0m Trial 2 finished with value: -0.03478264332709502 and parameters: {'loss': 'ls', 'learning_rate': 0.00010229811157330218, 'n_estimators': 441, 'subsample': 0.4794144653767538, 'criterion': 'friedman_mse', 'min_samples_split': 37, 'min_samples_leaf': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:08,473]\u001b[0m Trial 3 finished with value: -0.03503649883406079 and parameters: {'loss': 'ls', 'learning_rate': 1.282911452550472e-05, 'n_estimators': 334, 'subsample': 0.8542170236184707, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:17,826]\u001b[0m Trial 4 finished with value: -0.03452386236732985 and parameters: {'loss': 'lad', 'learning_rate': 1.1695836135822593e-06, 'n_estimators': 887, 'subsample': 0.9509221216949925, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:22,592]\u001b[0m Trial 5 finished with value: -0.033907295616442346 and parameters: {'loss': 'huber', 'learning_rate': 0.00028289459687519554, 'n_estimators': 527, 'subsample': 0.49203022250792483, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 4, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:24,327]\u001b[0m Trial 6 finished with value: -0.03336470622749377 and parameters: {'loss': 'huber', 'learning_rate': 0.00016405447411394668, 'n_estimators': 539, 'subsample': 0.4968679624093342, 'criterion': 'friedman_mse', 'min_samples_split': 48, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:26,928]\u001b[0m Trial 7 finished with value: -0.733486908468709 and parameters: {'loss': 'quantile', 'learning_rate': 0.006916020326157702, 'n_estimators': 759, 'subsample': 0.41772793006704667, 'criterion': 'friedman_mse', 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:16:28,137]\u001b[0m Trial 8 finished with value: -0.06708768793046871 and parameters: {'loss': 'lad', 'learning_rate': 0.013531025122087151, 'n_estimators': 645, 'subsample': 0.9013759326518556, 'criterion': 'friedman_mse', 'min_samples_split': 38, 'min_samples_leaf': 2, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:05,258]\u001b[0m Trial 9 finished with value: -1.8690206397280003 and parameters: {'loss': 'quantile', 'learning_rate': 0.00010395222100144117, 'n_estimators': 913, 'subsample': 0.9959883907676449, 'criterion': 'friedman_mse', 'min_samples_split': 34, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:05,290]\u001b[0m Trial 10 finished with value: -0.09181881030105998 and parameters: {'loss': 'ls', 'learning_rate': 0.06975098781750946, 'n_estimators': 24, 'subsample': 0.16493644375030564, 'criterion': 'friedman_mse', 'min_samples_split': 25, 'min_samples_leaf': 10, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:06,419]\u001b[0m Trial 11 finished with value: -0.03057610899232377 and parameters: {'loss': 'huber', 'learning_rate': 0.0014296203866594119, 'n_estimators': 690, 'subsample': 0.2892142789233698, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:09,525]\u001b[0m Trial 12 finished with value: -0.06207855715253818 and parameters: {'loss': 'huber', 'learning_rate': 0.002805010077267983, 'n_estimators': 741, 'subsample': 0.2436397037978308, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 8, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:09,963]\u001b[0m Trial 13 finished with value: -0.03397571248935338 and parameters: {'loss': 'ls', 'learning_rate': 0.0018053314850861061, 'n_estimators': 807, 'subsample': 0.2947292023992511, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:12,531]\u001b[0m Trial 14 finished with value: -0.04331508327906497 and parameters: {'loss': 'ls', 'learning_rate': 0.000862645835294346, 'n_estimators': 992, 'subsample': 0.6662894033970165, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 8, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:14,308]\u001b[0m Trial 15 finished with value: -0.03398894901100924 and parameters: {'loss': 'huber', 'learning_rate': 2.4376801565341495e-05, 'n_estimators': 641, 'subsample': 0.1051723846422841, 'criterion': 'friedman_mse', 'min_samples_split': 27, 'min_samples_leaf': 9, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:17,503]\u001b[0m Trial 16 finished with value: -0.031041125632018884 and parameters: {'loss': 'lad', 'learning_rate': 0.0006272337576695236, 'n_estimators': 652, 'subsample': 0.35086771392573557, 'criterion': 'friedman_mse', 'min_samples_split': 49, 'min_samples_leaf': 6, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:17,810]\u001b[0m Trial 17 finished with value: -0.2221187875823063 and parameters: {'loss': 'ls', 'learning_rate': 0.060789979833596505, 'n_estimators': 116, 'subsample': 0.6741454733192653, 'criterion': 'friedman_mse', 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:20,995]\u001b[0m Trial 18 finished with value: -0.3522472149713325 and parameters: {'loss': 'quantile', 'learning_rate': 0.015250108032037229, 'n_estimators': 402, 'subsample': 0.6264497912207931, 'criterion': 'friedman_mse', 'min_samples_split': 28, 'min_samples_leaf': 9, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:22,660]\u001b[0m Trial 19 finished with value: -0.03369359759912416 and parameters: {'loss': 'huber', 'learning_rate': 5.043557094807408e-05, 'n_estimators': 854, 'subsample': 0.21709309120493736, 'criterion': 'friedman_mse', 'min_samples_split': 41, 'min_samples_leaf': 6, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:33,237]\u001b[0m Trial 20 finished with value: -0.12356101488395521 and parameters: {'loss': 'huber', 'learning_rate': 0.0024593976714419197, 'n_estimators': 705, 'subsample': 0.3573667281607376, 'criterion': 'friedman_mse', 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_depth': 13, 'max_features': 'auto'}. Best is trial 1 with value: -0.030309855004340136.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:36,174]\u001b[0m Trial 21 finished with value: -0.02831660617716003 and parameters: {'loss': 'lad', 'learning_rate': 0.000639009726531653, 'n_estimators': 621, 'subsample': 0.3423592056386159, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 6, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:38,986]\u001b[0m Trial 22 finished with value: -0.02925036710827822 and parameters: {'loss': 'lad', 'learning_rate': 0.0005614674056206102, 'n_estimators': 553, 'subsample': 0.34842846613995027, 'criterion': 'friedman_mse', 'min_samples_split': 46, 'min_samples_leaf': 7, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:42,197]\u001b[0m Trial 23 finished with value: -0.02907625004261183 and parameters: {'loss': 'lad', 'learning_rate': 0.0003091529457008232, 'n_estimators': 577, 'subsample': 0.3922709594125491, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 8, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:46,819]\u001b[0m Trial 24 finished with value: -0.03290226762853776 and parameters: {'loss': 'lad', 'learning_rate': 0.0004660326433550558, 'n_estimators': 572, 'subsample': 0.5961212205865225, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 8, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:49,875]\u001b[0m Trial 25 finished with value: -0.11451621765572928 and parameters: {'loss': 'lad', 'learning_rate': 0.005605818472089186, 'n_estimators': 464, 'subsample': 0.4204671902007419, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 5, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:51,405]\u001b[0m Trial 26 finished with value: -0.033922050319814545 and parameters: {'loss': 'lad', 'learning_rate': 5.0875596900333926e-05, 'n_estimators': 268, 'subsample': 0.4181561456915631, 'criterion': 'friedman_mse', 'min_samples_split': 46, 'min_samples_leaf': 7, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:17:58,248]\u001b[0m Trial 27 finished with value: -0.038992908608690424 and parameters: {'loss': 'lad', 'learning_rate': 0.0007233998220116548, 'n_estimators': 610, 'subsample': 0.741543691495799, 'criterion': 'friedman_mse', 'min_samples_split': 34, 'min_samples_leaf': 6, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:07,300]\u001b[0m Trial 28 finished with value: -0.035587829597703236 and parameters: {'loss': 'lad', 'learning_rate': 0.00019014633457542458, 'n_estimators': 494, 'subsample': 0.5571947839919648, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 5, 'max_depth': 14, 'max_features': 'auto'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:08,236]\u001b[0m Trial 29 finished with value: -0.03410508555632985 and parameters: {'loss': 'lad', 'learning_rate': 4.217592705940977e-05, 'n_estimators': 343, 'subsample': 0.18758319250946762, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 8, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:09,331]\u001b[0m Trial 30 finished with value: -0.03450365583400061 and parameters: {'loss': 'lad', 'learning_rate': 9.02225499892249e-06, 'n_estimators': 249, 'subsample': 0.29823344631548143, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 7, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:11,997]\u001b[0m Trial 31 finished with value: -0.029026716581906697 and parameters: {'loss': 'lad', 'learning_rate': 0.00030737567533914624, 'n_estimators': 574, 'subsample': 0.36319476984857535, 'criterion': 'friedman_mse', 'min_samples_split': 46, 'min_samples_leaf': 10, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 21 with value: -0.02831660617716003.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:15,028]\u001b[0m Trial 32 finished with value: -0.02750949954631743 and parameters: {'loss': 'lad', 'learning_rate': 0.00034907704919247333, 'n_estimators': 576, 'subsample': 0.37147341729604216, 'criterion': 'friedman_mse', 'min_samples_split': 40, 'min_samples_leaf': 9, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:17,430]\u001b[0m Trial 33 finished with value: -0.031811006740623204 and parameters: {'loss': 'lad', 'learning_rate': 0.00023080581704770315, 'n_estimators': 413, 'subsample': 0.45782780468281226, 'criterion': 'friedman_mse', 'min_samples_split': 41, 'min_samples_leaf': 10, 'max_depth': 9, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:20,824]\u001b[0m Trial 34 finished with value: -0.032739030955933446 and parameters: {'loss': 'lad', 'learning_rate': 9.449603924940833e-05, 'n_estimators': 599, 'subsample': 0.3787041420134734, 'criterion': 'friedman_mse', 'min_samples_split': 37, 'min_samples_leaf': 9, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:24,126]\u001b[0m Trial 35 finished with value: -0.034012438909118536 and parameters: {'loss': 'lad', 'learning_rate': 0.0011999208830667317, 'n_estimators': 485, 'subsample': 0.5410619406530107, 'criterion': 'friedman_mse', 'min_samples_split': 47, 'min_samples_leaf': 10, 'max_depth': 10, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:25,405]\u001b[0m Trial 36 finished with value: -0.03452298949420163 and parameters: {'loss': 'lad', 'learning_rate': 2.5525906600838464e-06, 'n_estimators': 381, 'subsample': 0.25600899492741713, 'criterion': 'friedman_mse', 'min_samples_split': 40, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:30,244]\u001b[0m Trial 37 finished with value: -0.03168723338608581 and parameters: {'loss': 'lad', 'learning_rate': 0.0003071805920507397, 'n_estimators': 540, 'subsample': 0.45932809831606797, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 8, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:36,320]\u001b[0m Trial 38 finished with value: -0.03052489912685208 and parameters: {'loss': 'lad', 'learning_rate': 0.00014767066259050582, 'n_estimators': 782, 'subsample': 0.3147260347993087, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 10, 'max_depth': 8, 'max_features': 'auto'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:42,312]\u001b[0m Trial 39 finished with value: -0.6118673392200147 and parameters: {'loss': 'quantile', 'learning_rate': 0.0050162710482993455, 'n_estimators': 678, 'subsample': 0.5239927523787437, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:44,411]\u001b[0m Trial 40 finished with value: -0.03421356046871127 and parameters: {'loss': 'lad', 'learning_rate': 2.4410350578577865e-05, 'n_estimators': 446, 'subsample': 0.3979841060504341, 'criterion': 'friedman_mse', 'min_samples_split': 48, 'min_samples_leaf': 5, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:47,014]\u001b[0m Trial 41 finished with value: -0.028910322682585976 and parameters: {'loss': 'lad', 'learning_rate': 0.00041407358577967703, 'n_estimators': 551, 'subsample': 0.33789525500028905, 'criterion': 'friedman_mse', 'min_samples_split': 47, 'min_samples_leaf': 8, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:49,905]\u001b[0m Trial 42 finished with value: -0.028599144602178272 and parameters: {'loss': 'lad', 'learning_rate': 0.00038567722089401186, 'n_estimators': 598, 'subsample': 0.33346909127760577, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 8, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:51,043]\u001b[0m Trial 43 finished with value: -0.03310767775435375 and parameters: {'loss': 'lad', 'learning_rate': 0.00011122899550816112, 'n_estimators': 621, 'subsample': 0.13605773001912003, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 10, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 32 with value: -0.02750949954631743.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:53,023]\u001b[0m Trial 44 finished with value: -0.027425204891957433 and parameters: {'loss': 'lad', 'learning_rate': 0.0004265951649081727, 'n_estimators': 519, 'subsample': 0.25573277770949154, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 9, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 44 with value: -0.027425204891957433.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:55,031]\u001b[0m Trial 45 finished with value: -0.033298509663725495 and parameters: {'loss': 'lad', 'learning_rate': 0.0009636209321496299, 'n_estimators': 502, 'subsample': 0.24885328656176856, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 4, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 44 with value: -0.027425204891957433.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:18:58,736]\u001b[0m Trial 46 finished with value: -1.1731766526295475 and parameters: {'loss': 'quantile', 'learning_rate': 0.0023052699468148257, 'n_estimators': 744, 'subsample': 0.18277551923931906, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 8, 'max_depth': 13, 'max_features': 'auto'}. Best is trial 44 with value: -0.027425204891957433.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:01,455]\u001b[0m Trial 47 finished with value: -0.030272446097363348 and parameters: {'loss': 'lad', 'learning_rate': 0.00041930364086208285, 'n_estimators': 529, 'subsample': 0.3251492613940832, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 9, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 44 with value: -0.027425204891957433.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:04,607]\u001b[0m Trial 48 finished with value: -0.0890573056212638 and parameters: {'loss': 'lad', 'learning_rate': 0.003527757345426767, 'n_estimators': 704, 'subsample': 0.26485771570826655, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 6, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 44 with value: -0.027425204891957433.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:05,005]\u001b[0m Trial 49 finished with value: -0.030065594187352218 and parameters: {'loss': 'ls', 'learning_rate': 0.0014033469791882227, 'n_estimators': 445, 'subsample': 0.22328017602714686, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 9, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 44 with value: -0.027425204891957433.\u001b[0m\n",
            " 50%|█████     | 3/6 [08:11<08:40, 173.65s/it]\u001b[32m[I 2021-11-17 22:19:06,942]\u001b[0m A new study created in memory with name: no-name-9a67e84c-625e-49ba-908f-8db46b08c82b\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:07,141]\u001b[0m Trial 0 finished with value: -0.003326734083729521 and parameters: {'loss': 'lad', 'learning_rate': 8.364263653157544e-06, 'n_estimators': 92, 'subsample': 0.42923217495732213, 'criterion': 'friedman_mse', 'min_samples_split': 35, 'min_samples_leaf': 6, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 0 with value: -0.003326734083729521.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:10,560]\u001b[0m Trial 1 finished with value: -1.1505046132722958 and parameters: {'loss': 'quantile', 'learning_rate': 0.06121397016218931, 'n_estimators': 447, 'subsample': 0.431226938175279, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 7, 'max_depth': 14, 'max_features': 'sqrt'}. Best is trial 0 with value: -0.003326734083729521.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:11,208]\u001b[0m Trial 2 finished with value: -0.0032179361583384303 and parameters: {'loss': 'ls', 'learning_rate': 3.1117797328303453e-06, 'n_estimators': 964, 'subsample': 0.1936566124491247, 'criterion': 'friedman_mse', 'min_samples_split': 48, 'min_samples_leaf': 4, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 2 with value: -0.0032179361583384303.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:16,203]\u001b[0m Trial 3 finished with value: -1.7193761360102657 and parameters: {'loss': 'quantile', 'learning_rate': 0.0007167952752008385, 'n_estimators': 920, 'subsample': 0.1764120978363805, 'criterion': 'friedman_mse', 'min_samples_split': 47, 'min_samples_leaf': 4, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 2 with value: -0.0032179361583384303.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:17,946]\u001b[0m Trial 4 finished with value: 0.007605313610663078 and parameters: {'loss': 'huber', 'learning_rate': 0.001276483339164933, 'n_estimators': 161, 'subsample': 0.6639369719487881, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.007605313610663078.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:18,316]\u001b[0m Trial 5 finished with value: 0.014842141741611359 and parameters: {'loss': 'ls', 'learning_rate': 0.0015988798445387238, 'n_estimators': 724, 'subsample': 0.1586836753667372, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 7, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.014842141741611359.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:23,565]\u001b[0m Trial 6 finished with value: 0.00354962179853624 and parameters: {'loss': 'lad', 'learning_rate': 0.00036255057732706013, 'n_estimators': 703, 'subsample': 0.9039506015535157, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 5 with value: 0.014842141741611359.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:26,616]\u001b[0m Trial 7 finished with value: -0.0033253049810317847 and parameters: {'loss': 'huber', 'learning_rate': 2.0028924164457053e-06, 'n_estimators': 170, 'subsample': 0.53430472998257, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 4, 'max_depth': 14, 'max_features': 'auto'}. Best is trial 5 with value: 0.014842141741611359.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:27,607]\u001b[0m Trial 8 finished with value: -0.24632046468286073 and parameters: {'loss': 'lad', 'learning_rate': 0.09076135122135483, 'n_estimators': 539, 'subsample': 0.4261121464852332, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 6, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 5 with value: 0.014842141741611359.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:34,422]\u001b[0m Trial 9 finished with value: -0.0028028715980554786 and parameters: {'loss': 'huber', 'learning_rate': 1.0433948146153436e-05, 'n_estimators': 781, 'subsample': 0.3614808196372751, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 3, 'max_depth': 13, 'max_features': 'log2'}. Best is trial 5 with value: 0.014842141741611359.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:35,836]\u001b[0m Trial 10 finished with value: -0.0013889551189341098 and parameters: {'loss': 'ls', 'learning_rate': 0.006834609110207429, 'n_estimators': 397, 'subsample': 0.7961896879890505, 'criterion': 'friedman_mse', 'min_samples_split': 24, 'min_samples_leaf': 10, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.014842141741611359.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:36,553]\u001b[0m Trial 11 finished with value: 0.019068825603886563 and parameters: {'loss': 'ls', 'learning_rate': 0.0027369743072020625, 'n_estimators': 269, 'subsample': 0.6956843856672101, 'criterion': 'friedman_mse', 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.019068825603886563.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:37,390]\u001b[0m Trial 12 finished with value: 0.02301692527157062 and parameters: {'loss': 'ls', 'learning_rate': 0.007297979808514945, 'n_estimators': 302, 'subsample': 0.686452281271012, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_depth': 9, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:38,355]\u001b[0m Trial 13 finished with value: -0.020014468325797008 and parameters: {'loss': 'ls', 'learning_rate': 0.009596805361307003, 'n_estimators': 306, 'subsample': 0.73571880121286, 'criterion': 'friedman_mse', 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:39,359]\u001b[0m Trial 14 finished with value: -0.001577927409883273 and parameters: {'loss': 'ls', 'learning_rate': 9.574883121297661e-05, 'n_estimators': 279, 'subsample': 0.9771374538357019, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:39,488]\u001b[0m Trial 15 finished with value: 0.021991946373101756 and parameters: {'loss': 'ls', 'learning_rate': 0.009480874321748435, 'n_estimators': 34, 'subsample': 0.6108443112877117, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:39,542]\u001b[0m Trial 16 finished with value: 0.013614346521984233 and parameters: {'loss': 'ls', 'learning_rate': 0.018082622501057355, 'n_estimators': 12, 'subsample': 0.584490832218334, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:51,163]\u001b[0m Trial 17 finished with value: 0.001413364842535958 and parameters: {'loss': 'ls', 'learning_rate': 6.387639248624105e-05, 'n_estimators': 594, 'subsample': 0.8366797480595369, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:51,708]\u001b[0m Trial 18 finished with value: -1.601051609045368 and parameters: {'loss': 'quantile', 'learning_rate': 0.021535099140559226, 'n_estimators': 56, 'subsample': 0.5873845495045557, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:52,034]\u001b[0m Trial 19 finished with value: 0.020207994162611875 and parameters: {'loss': 'ls', 'learning_rate': 0.004469723032484688, 'n_estimators': 181, 'subsample': 0.5390666343845052, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 8, 'max_depth': 6, 'max_features': 'sqrt'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:54,422]\u001b[0m Trial 20 finished with value: -0.19034730287790902 and parameters: {'loss': 'ls', 'learning_rate': 0.03300224202055505, 'n_estimators': 373, 'subsample': 0.3295639035087462, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 2, 'max_depth': 9, 'max_features': 'auto'}. Best is trial 12 with value: 0.02301692527157062.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:54,706]\u001b[0m Trial 21 finished with value: 0.024854116344645405 and parameters: {'loss': 'ls', 'learning_rate': 0.004796386441251689, 'n_estimators': 175, 'subsample': 0.5587678493117475, 'criterion': 'friedman_mse', 'min_samples_split': 19, 'min_samples_leaf': 8, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:54,929]\u001b[0m Trial 22 finished with value: 0.008220713741015184 and parameters: {'loss': 'ls', 'learning_rate': 0.008006528740358421, 'n_estimators': 126, 'subsample': 0.61972591531706, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 9, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:55,168]\u001b[0m Trial 23 finished with value: -0.0017262689492205663 and parameters: {'loss': 'ls', 'learning_rate': 0.0002423695441003432, 'n_estimators': 227, 'subsample': 0.7317195476026483, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 10, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:55,240]\u001b[0m Trial 24 finished with value: 0.004429235389489361 and parameters: {'loss': 'ls', 'learning_rate': 0.003390623113285145, 'n_estimators': 27, 'subsample': 0.477838316863986, 'criterion': 'friedman_mse', 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_depth': 9, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:56,210]\u001b[0m Trial 25 finished with value: -0.06612706265386081 and parameters: {'loss': 'ls', 'learning_rate': 0.015529346325580796, 'n_estimators': 369, 'subsample': 0.7887073728716439, 'criterion': 'friedman_mse', 'min_samples_split': 22, 'min_samples_leaf': 9, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:57,033]\u001b[0m Trial 26 finished with value: -1.6205919830786488 and parameters: {'loss': 'quantile', 'learning_rate': 0.0008558913964094466, 'n_estimators': 94, 'subsample': 0.6358392588021942, 'criterion': 'friedman_mse', 'min_samples_split': 29, 'min_samples_leaf': 5, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:58,320]\u001b[0m Trial 27 finished with value: -0.04646934303689498 and parameters: {'loss': 'lad', 'learning_rate': 0.0403927537568648, 'n_estimators': 220, 'subsample': 0.28071793158805436, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:19:59,774]\u001b[0m Trial 28 finished with value: 0.02051074417732468 and parameters: {'loss': 'huber', 'learning_rate': 0.0020064454707608586, 'n_estimators': 315, 'subsample': 0.4840280491086248, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:01,563]\u001b[0m Trial 29 finished with value: -0.0021670856478714917 and parameters: {'loss': 'lad', 'learning_rate': 0.00022005946152056513, 'n_estimators': 90, 'subsample': 0.8890966426740434, 'criterion': 'friedman_mse', 'min_samples_split': 37, 'min_samples_leaf': 8, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:02,047]\u001b[0m Trial 30 finished with value: -0.0029058635691943113 and parameters: {'loss': 'ls', 'learning_rate': 3.233617943986259e-05, 'n_estimators': 484, 'subsample': 0.6971619550489361, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 9, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:03,183]\u001b[0m Trial 31 finished with value: 0.021465618107249673 and parameters: {'loss': 'huber', 'learning_rate': 0.0020252342518523544, 'n_estimators': 315, 'subsample': 0.48529106353439294, 'criterion': 'friedman_mse', 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.024854116344645405.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:04,737]\u001b[0m Trial 32 finished with value: 0.030568081475826903 and parameters: {'loss': 'huber', 'learning_rate': 0.00434512249240657, 'n_estimators': 439, 'subsample': 0.48421304314570135, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:06,182]\u001b[0m Trial 33 finished with value: 0.01563137356300981 and parameters: {'loss': 'huber', 'learning_rate': 0.00514853988835572, 'n_estimators': 432, 'subsample': 0.4087091803834263, 'criterion': 'friedman_mse', 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:06,799]\u001b[0m Trial 34 finished with value: 0.021003093454192823 and parameters: {'loss': 'huber', 'learning_rate': 0.012369823528263775, 'n_estimators': 235, 'subsample': 0.5166650336758112, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:12,355]\u001b[0m Trial 35 finished with value: -1.6276129494712572 and parameters: {'loss': 'quantile', 'learning_rate': 0.0006891658744702811, 'n_estimators': 573, 'subsample': 0.5930495586247406, 'criterion': 'friedman_mse', 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:14,362]\u001b[0m Trial 36 finished with value: -0.25050405200402937 and parameters: {'loss': 'huber', 'learning_rate': 0.038144448603117574, 'n_estimators': 471, 'subsample': 0.2331654928098471, 'criterion': 'friedman_mse', 'min_samples_split': 27, 'min_samples_leaf': 7, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:14,625]\u001b[0m Trial 37 finished with value: -0.12482863475239347 and parameters: {'loss': 'ls', 'learning_rate': 0.08624463461421313, 'n_estimators': 140, 'subsample': 0.6597917411100886, 'criterion': 'friedman_mse', 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:15,146]\u001b[0m Trial 38 finished with value: -1.6115898263864783 and parameters: {'loss': 'quantile', 'learning_rate': 0.001090110313856572, 'n_estimators': 89, 'subsample': 0.3829353522707799, 'criterion': 'friedman_mse', 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_depth': 9, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:22,562]\u001b[0m Trial 39 finished with value: -0.025877797070219755 and parameters: {'loss': 'huber', 'learning_rate': 0.004780099986222175, 'n_estimators': 646, 'subsample': 0.4462186196557981, 'criterion': 'friedman_mse', 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:24,813]\u001b[0m Trial 40 finished with value: 0.01231105786876352 and parameters: {'loss': 'lad', 'learning_rate': 0.03275866070122586, 'n_estimators': 179, 'subsample': 0.5554348958946045, 'criterion': 'friedman_mse', 'min_samples_split': 21, 'min_samples_leaf': 8, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:26,176]\u001b[0m Trial 41 finished with value: 0.022554190729292656 and parameters: {'loss': 'huber', 'learning_rate': 0.002309136196361118, 'n_estimators': 338, 'subsample': 0.48823621095631853, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:27,950]\u001b[0m Trial 42 finished with value: 0.011414630800431702 and parameters: {'loss': 'huber', 'learning_rate': 0.007408180977668778, 'n_estimators': 424, 'subsample': 0.5185097743378931, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:29,017]\u001b[0m Trial 43 finished with value: 0.026321265734827515 and parameters: {'loss': 'huber', 'learning_rate': 0.002409602249013637, 'n_estimators': 345, 'subsample': 0.6331605972448542, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 5, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:30,091]\u001b[0m Trial 44 finished with value: 0.0033725070511677613 and parameters: {'loss': 'huber', 'learning_rate': 0.0005184631574883298, 'n_estimators': 331, 'subsample': 0.6836028825931002, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 5, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:30,807]\u001b[0m Trial 45 finished with value: 0.007903469513683037 and parameters: {'loss': 'huber', 'learning_rate': 0.0017980576953255116, 'n_estimators': 356, 'subsample': 0.11590054082902729, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:33,073]\u001b[0m Trial 46 finished with value: 0.0187202974544447 and parameters: {'loss': 'huber', 'learning_rate': 0.003293148270559298, 'n_estimators': 512, 'subsample': 0.4532411065611779, 'criterion': 'friedman_mse', 'min_samples_split': 25, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:34,165]\u001b[0m Trial 47 finished with value: 0.0008618385025990216 and parameters: {'loss': 'huber', 'learning_rate': 0.0003766874897690497, 'n_estimators': 276, 'subsample': 0.7546933278576926, 'criterion': 'friedman_mse', 'min_samples_split': 32, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:38,536]\u001b[0m Trial 48 finished with value: 0.028515254792682576 and parameters: {'loss': 'huber', 'learning_rate': 0.0013617156768713837, 'n_estimators': 883, 'subsample': 0.56447758573691, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:20:43,287]\u001b[0m Trial 49 finished with value: 0.021150870039365777 and parameters: {'loss': 'huber', 'learning_rate': 0.0012669608285033921, 'n_estimators': 879, 'subsample': 0.6461612458750402, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 32 with value: 0.030568081475826903.\u001b[0m\n",
            " 67%|██████▋   | 4/6 [09:49<04:47, 143.74s/it]\u001b[32m[I 2021-11-17 22:20:44,820]\u001b[0m A new study created in memory with name: no-name-8b6d46d0-1cdd-4965-8599-0b6fd31166ca\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:09,758]\u001b[0m Trial 0 finished with value: -0.09513286896601625 and parameters: {'loss': 'huber', 'learning_rate': 0.0030657257038477865, 'n_estimators': 926, 'subsample': 0.9017590003564275, 'criterion': 'friedman_mse', 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_depth': 8, 'max_features': 'auto'}. Best is trial 0 with value: -0.09513286896601625.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:12,888]\u001b[0m Trial 1 finished with value: -0.015414474469272132 and parameters: {'loss': 'lad', 'learning_rate': 1.9979623735198547e-05, 'n_estimators': 864, 'subsample': 0.1713236532686642, 'criterion': 'friedman_mse', 'min_samples_split': 28, 'min_samples_leaf': 9, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 1 with value: -0.015414474469272132.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:14,239]\u001b[0m Trial 2 finished with value: -0.015966036601189337 and parameters: {'loss': 'huber', 'learning_rate': 5.3321747074937645e-06, 'n_estimators': 237, 'subsample': 0.19206108402015754, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 5, 'max_depth': 8, 'max_features': 'auto'}. Best is trial 1 with value: -0.015414474469272132.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:16,163]\u001b[0m Trial 3 finished with value: -0.008438694298258165 and parameters: {'loss': 'huber', 'learning_rate': 0.001575176908754559, 'n_estimators': 401, 'subsample': 0.16564307360529015, 'criterion': 'friedman_mse', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 3 with value: -0.008438694298258165.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:16,199]\u001b[0m Trial 4 finished with value: 0.0018037039446255898 and parameters: {'loss': 'huber', 'learning_rate': 0.06804291020204233, 'n_estimators': 10, 'subsample': 0.9479768596519151, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:19,686]\u001b[0m Trial 5 finished with value: -0.009257258020652692 and parameters: {'loss': 'lad', 'learning_rate': 0.00021826759335082362, 'n_estimators': 436, 'subsample': 0.5943148484648132, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 6, 'max_depth': 7, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:28,277]\u001b[0m Trial 6 finished with value: -0.015094603607034518 and parameters: {'loss': 'lad', 'learning_rate': 1.9050474457580797e-05, 'n_estimators': 810, 'subsample': 0.6987160346653223, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 5, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:21:58,855]\u001b[0m Trial 7 finished with value: -0.01580272639200664 and parameters: {'loss': 'lad', 'learning_rate': 2.2412819754975467e-06, 'n_estimators': 967, 'subsample': 0.9093266092120638, 'criterion': 'friedman_mse', 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_depth': 11, 'max_features': 'auto'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:02,359]\u001b[0m Trial 8 finished with value: -0.09221646980254894 and parameters: {'loss': 'lad', 'learning_rate': 0.006140525451568304, 'n_estimators': 839, 'subsample': 0.23041660111008208, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 10, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:05,135]\u001b[0m Trial 9 finished with value: -0.015957995870178543 and parameters: {'loss': 'huber', 'learning_rate': 4.0637659635963004e-06, 'n_estimators': 544, 'subsample': 0.5437652040717853, 'criterion': 'friedman_mse', 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:05,228]\u001b[0m Trial 10 finished with value: -2.1320351551325505 and parameters: {'loss': 'quantile', 'learning_rate': 0.0828277573007775, 'n_estimators': 47, 'subsample': 0.7650586202517852, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:05,269]\u001b[0m Trial 11 finished with value: -0.1764002121969781 and parameters: {'loss': 'ls', 'learning_rate': 0.07813167207716747, 'n_estimators': 15, 'subsample': 0.3882424277773593, 'criterion': 'friedman_mse', 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:05,840]\u001b[0m Trial 12 finished with value: 0.0018021196324335964 and parameters: {'loss': 'huber', 'learning_rate': 0.004192882946603793, 'n_estimators': 305, 'subsample': 0.38422624562282426, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.0018037039446255898.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:06,228]\u001b[0m Trial 13 finished with value: 0.003939021469551163 and parameters: {'loss': 'huber', 'learning_rate': 0.015170508808785196, 'n_estimators': 212, 'subsample': 0.4014128322164223, 'criterion': 'friedman_mse', 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 13 with value: 0.003939021469551163.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:06,694]\u001b[0m Trial 14 finished with value: -1.981105648591572 and parameters: {'loss': 'quantile', 'learning_rate': 0.018546464755994963, 'n_estimators': 199, 'subsample': 0.3669187879782039, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 13 with value: 0.003939021469551163.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:06,911]\u001b[0m Trial 15 finished with value: -0.01659835526138287 and parameters: {'loss': 'ls', 'learning_rate': 0.0002942810079803359, 'n_estimators': 126, 'subsample': 0.9875942794171854, 'criterion': 'friedman_mse', 'min_samples_split': 34, 'min_samples_leaf': 7, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 13 with value: 0.003939021469551163.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:09,640]\u001b[0m Trial 16 finished with value: -0.16056435657853863 and parameters: {'loss': 'huber', 'learning_rate': 0.021502882065567365, 'n_estimators': 612, 'subsample': 0.5149425632726949, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 13 with value: 0.003939021469551163.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:10,194]\u001b[0m Trial 17 finished with value: -0.013701716404801889 and parameters: {'loss': 'huber', 'learning_rate': 0.0008596314237726313, 'n_estimators': 132, 'subsample': 0.7489079160859503, 'criterion': 'friedman_mse', 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_depth': 4, 'max_features': 'log2'}. Best is trial 13 with value: 0.003939021469551163.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:10,745]\u001b[0m Trial 18 finished with value: 0.008088477839173325 and parameters: {'loss': 'huber', 'learning_rate': 0.02308749575158258, 'n_estimators': 320, 'subsample': 0.29012721531807145, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 5, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:11,155]\u001b[0m Trial 19 finished with value: -2.063032046643588 and parameters: {'loss': 'quantile', 'learning_rate': 0.016114123592113647, 'n_estimators': 335, 'subsample': 0.2969058821691104, 'criterion': 'friedman_mse', 'min_samples_split': 26, 'min_samples_leaf': 6, 'max_depth': 2, 'max_features': 'log2'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:12,105]\u001b[0m Trial 20 finished with value: -0.013975428084465724 and parameters: {'loss': 'ls', 'learning_rate': 9.483526538527556e-05, 'n_estimators': 676, 'subsample': 0.4568992198821215, 'criterion': 'friedman_mse', 'min_samples_split': 30, 'min_samples_leaf': 5, 'max_depth': 6, 'max_features': 'log2'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:12,398]\u001b[0m Trial 21 finished with value: -0.05910589642755415 and parameters: {'loss': 'huber', 'learning_rate': 0.03904449708827596, 'n_estimators': 136, 'subsample': 0.2681243658598019, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:13,309]\u001b[0m Trial 22 finished with value: -0.012465234350448107 and parameters: {'loss': 'huber', 'learning_rate': 0.009540825252879668, 'n_estimators': 246, 'subsample': 0.637781255720613, 'criterion': 'friedman_mse', 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:13,866]\u001b[0m Trial 23 finished with value: -0.5224987215521899 and parameters: {'loss': 'huber', 'learning_rate': 0.0940323718368918, 'n_estimators': 324, 'subsample': 0.11897271818272048, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:14,020]\u001b[0m Trial 24 finished with value: -0.016429719723112246 and parameters: {'loss': 'huber', 'learning_rate': 0.030361597883170204, 'n_estimators': 77, 'subsample': 0.46180087037675654, 'criterion': 'friedman_mse', 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:15,694]\u001b[0m Trial 25 finished with value: 0.0044232338412628636 and parameters: {'loss': 'huber', 'learning_rate': 0.0025566001824874935, 'n_estimators': 444, 'subsample': 0.3184001284198438, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:17,312]\u001b[0m Trial 26 finished with value: -0.003700792547330911 and parameters: {'loss': 'huber', 'learning_rate': 0.0010622421933394305, 'n_estimators': 456, 'subsample': 0.30970789218797595, 'criterion': 'friedman_mse', 'min_samples_split': 34, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:23,641]\u001b[0m Trial 27 finished with value: -0.01732230564257975 and parameters: {'loss': 'huber', 'learning_rate': 0.0026439348385950525, 'n_estimators': 536, 'subsample': 0.4640031598250218, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 8, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:23,996]\u001b[0m Trial 28 finished with value: -0.0030502001392147537 and parameters: {'loss': 'ls', 'learning_rate': 0.009452174790929345, 'n_estimators': 371, 'subsample': 0.3907785306200461, 'criterion': 'friedman_mse', 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:28,086]\u001b[0m Trial 29 finished with value: -0.0012122664441160946 and parameters: {'loss': 'huber', 'learning_rate': 0.0025104163639207136, 'n_estimators': 731, 'subsample': 0.3271015047928947, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:30,188]\u001b[0m Trial 30 finished with value: -1.9729790286374151 and parameters: {'loss': 'quantile', 'learning_rate': 0.006934892823803754, 'n_estimators': 290, 'subsample': 0.25782971938893523, 'criterion': 'friedman_mse', 'min_samples_split': 12, 'min_samples_leaf': 8, 'max_depth': 9, 'max_features': 'auto'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:30,644]\u001b[0m Trial 31 finished with value: -0.11994064520584291 and parameters: {'loss': 'huber', 'learning_rate': 0.04802421603863448, 'n_estimators': 192, 'subsample': 0.43587673962113344, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:31,787]\u001b[0m Trial 32 finished with value: -0.008143003566330353 and parameters: {'loss': 'huber', 'learning_rate': 0.01237685676145735, 'n_estimators': 514, 'subsample': 0.8012102496534563, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:32,552]\u001b[0m Trial 33 finished with value: -0.12596413502822745 and parameters: {'loss': 'huber', 'learning_rate': 0.0353093825378004, 'n_estimators': 258, 'subsample': 0.2144788557218542, 'criterion': 'friedman_mse', 'min_samples_split': 29, 'min_samples_leaf': 5, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:33,753]\u001b[0m Trial 34 finished with value: -0.010675626645044733 and parameters: {'loss': 'huber', 'learning_rate': 0.0008780719129604338, 'n_estimators': 387, 'subsample': 0.8553357341153958, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.008088477839173325.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:35,267]\u001b[0m Trial 35 finished with value: 0.008613117475883336 and parameters: {'loss': 'huber', 'learning_rate': 0.0031254360432351152, 'n_estimators': 450, 'subsample': 0.10092954552224798, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'auto'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:37,898]\u001b[0m Trial 36 finished with value: -0.006174037738680527 and parameters: {'loss': 'huber', 'learning_rate': 0.0020905426164234877, 'n_estimators': 461, 'subsample': 0.12926650907852302, 'criterion': 'friedman_mse', 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:40,040]\u001b[0m Trial 37 finished with value: -0.01358313156412816 and parameters: {'loss': 'huber', 'learning_rate': 0.00046175631334049734, 'n_estimators': 431, 'subsample': 0.16926449268469312, 'criterion': 'friedman_mse', 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'auto'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:44,345]\u001b[0m Trial 38 finished with value: -0.04952851856818197 and parameters: {'loss': 'lad', 'learning_rate': 0.004464679570150056, 'n_estimators': 598, 'subsample': 0.1652211175839864, 'criterion': 'friedman_mse', 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_depth': 8, 'max_features': 'auto'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:46,437]\u001b[0m Trial 39 finished with value: -0.015705221598620644 and parameters: {'loss': 'huber', 'learning_rate': 2.8813561513364665e-05, 'n_estimators': 363, 'subsample': 0.3349358397664847, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 7, 'max_depth': 4, 'max_features': 'auto'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:47,144]\u001b[0m Trial 40 finished with value: -0.01583765248884994 and parameters: {'loss': 'huber', 'learning_rate': 7.963564005131098e-05, 'n_estimators': 182, 'subsample': 0.24383388374111026, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'auto'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:47,972]\u001b[0m Trial 41 finished with value: -0.0011943115897319334 and parameters: {'loss': 'huber', 'learning_rate': 0.005693343170524521, 'n_estimators': 427, 'subsample': 0.5163184280638283, 'criterion': 'friedman_mse', 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:48,768]\u001b[0m Trial 42 finished with value: -0.13663681284332307 and parameters: {'loss': 'lad', 'learning_rate': 0.059178684834456555, 'n_estimators': 493, 'subsample': 0.1054714555405376, 'criterion': 'friedman_mse', 'min_samples_split': 24, 'min_samples_leaf': 5, 'max_depth': 4, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.008613117475883336.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:49,010]\u001b[0m Trial 43 finished with value: 0.013105286409092809 and parameters: {'loss': 'huber', 'learning_rate': 0.02685460845537334, 'n_estimators': 76, 'subsample': 0.6363454518524629, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.013105286409092809.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:49,607]\u001b[0m Trial 44 finished with value: -0.009836221572723902 and parameters: {'loss': 'huber', 'learning_rate': 0.025663075324571717, 'n_estimators': 82, 'subsample': 0.6320122563893734, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'auto'}. Best is trial 43 with value: 0.013105286409092809.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:22:50,167]\u001b[0m Trial 45 finished with value: 0.005506776957445947 and parameters: {'loss': 'huber', 'learning_rate': 0.010369725244593429, 'n_estimators': 270, 'subsample': 0.5826437866899289, 'criterion': 'friedman_mse', 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.013105286409092809.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:03,287]\u001b[0m Trial 46 finished with value: -0.0077745474655601665 and parameters: {'loss': 'huber', 'learning_rate': 0.0014896532767457735, 'n_estimators': 591, 'subsample': 0.5820107264179213, 'criterion': 'friedman_mse', 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.013105286409092809.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:04,421]\u001b[0m Trial 47 finished with value: -2.118723068746813 and parameters: {'loss': 'quantile', 'learning_rate': 0.0040826566845840245, 'n_estimators': 267, 'subsample': 0.6629173456714487, 'criterion': 'friedman_mse', 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.013105286409092809.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:05,628]\u001b[0m Trial 48 finished with value: -0.06052232485302578 and parameters: {'loss': 'ls', 'learning_rate': 0.008172272087830564, 'n_estimators': 342, 'subsample': 0.6982086452085061, 'criterion': 'friedman_mse', 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.013105286409092809.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:06,257]\u001b[0m Trial 49 finished with value: 0.020258372006777714 and parameters: {'loss': 'lad', 'learning_rate': 0.013071047107576934, 'n_estimators': 413, 'subsample': 0.547528349192654, 'criterion': 'friedman_mse', 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'sqrt'}. Best is trial 49 with value: 0.020258372006777714.\u001b[0m\n",
            " 83%|████████▎ | 5/6 [12:11<02:23, 143.13s/it]\u001b[32m[I 2021-11-17 22:23:06,878]\u001b[0m A new study created in memory with name: no-name-2e3bbf64-70b6-479a-87e5-e95f0cc0472f\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:07,349]\u001b[0m Trial 0 finished with value: 0.0016411175467564432 and parameters: {'loss': 'ls', 'learning_rate': 0.00010506566686509763, 'n_estimators': 385, 'subsample': 0.6993404716686809, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_depth': 3, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.0016411175467564432.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:07,767]\u001b[0m Trial 1 finished with value: -0.00037774973417348257 and parameters: {'loss': 'huber', 'learning_rate': 2.534528022407768e-05, 'n_estimators': 154, 'subsample': 0.26779764629102965, 'criterion': 'friedman_mse', 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_depth': 2, 'max_features': 'auto'}. Best is trial 0 with value: 0.0016411175467564432.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:08,766]\u001b[0m Trial 2 finished with value: 0.0007135499956745228 and parameters: {'loss': 'ls', 'learning_rate': 0.00023899276879619103, 'n_estimators': 254, 'subsample': 0.9115337171108306, 'criterion': 'friedman_mse', 'min_samples_split': 32, 'min_samples_leaf': 9, 'max_depth': 11, 'max_features': 'log2'}. Best is trial 0 with value: 0.0016411175467564432.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:22,995]\u001b[0m Trial 3 finished with value: 0.023999862875181188 and parameters: {'loss': 'ls', 'learning_rate': 0.0006179413824732087, 'n_estimators': 893, 'subsample': 0.6202855621124633, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:27,582]\u001b[0m Trial 4 finished with value: -0.44910620894137887 and parameters: {'loss': 'quantile', 'learning_rate': 1.4867042821955802e-05, 'n_estimators': 337, 'subsample': 0.8818077152746866, 'criterion': 'friedman_mse', 'min_samples_split': 21, 'min_samples_leaf': 8, 'max_depth': 15, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:29,079]\u001b[0m Trial 5 finished with value: -1.2726604241245565 and parameters: {'loss': 'quantile', 'learning_rate': 0.015438580482077047, 'n_estimators': 694, 'subsample': 0.1549358980759437, 'criterion': 'friedman_mse', 'min_samples_split': 37, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:39,249]\u001b[0m Trial 6 finished with value: -0.0030330182993736354 and parameters: {'loss': 'lad', 'learning_rate': 0.00029410087727795546, 'n_estimators': 860, 'subsample': 0.4980479548646565, 'criterion': 'friedman_mse', 'min_samples_split': 32, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:42,950]\u001b[0m Trial 7 finished with value: -0.46562122767803116 and parameters: {'loss': 'quantile', 'learning_rate': 0.00016518563199046328, 'n_estimators': 857, 'subsample': 0.9079761680459806, 'criterion': 'friedman_mse', 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:44,037]\u001b[0m Trial 8 finished with value: -0.6809712543347834 and parameters: {'loss': 'quantile', 'learning_rate': 0.04904909663081974, 'n_estimators': 275, 'subsample': 0.6470957587108083, 'criterion': 'friedman_mse', 'min_samples_split': 38, 'min_samples_leaf': 7, 'max_depth': 5, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:46,125]\u001b[0m Trial 9 finished with value: -0.11053020288935422 and parameters: {'loss': 'lad', 'learning_rate': 0.056401262522048266, 'n_estimators': 646, 'subsample': 0.24313742156750867, 'criterion': 'friedman_mse', 'min_samples_split': 40, 'min_samples_leaf': 9, 'max_depth': 8, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:55,972]\u001b[0m Trial 10 finished with value: 6.613976237090924e-05 and parameters: {'loss': 'ls', 'learning_rate': 1.560074044035794e-06, 'n_estimators': 974, 'subsample': 0.4601878785573265, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 5, 'max_depth': 14, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:57,605]\u001b[0m Trial 11 finished with value: -0.011608438406896404 and parameters: {'loss': 'ls', 'learning_rate': 0.0017090402749194605, 'n_estimators': 545, 'subsample': 0.6798050681424476, 'criterion': 'friedman_mse', 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:57,660]\u001b[0m Trial 12 finished with value: 0.0020131374455878426 and parameters: {'loss': 'ls', 'learning_rate': 0.0027295761425009013, 'n_estimators': 12, 'subsample': 0.7209951322367092, 'criterion': 'friedman_mse', 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 11, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:57,732]\u001b[0m Trial 13 finished with value: 0.0037126132108300514 and parameters: {'loss': 'ls', 'learning_rate': 0.0029629690770938306, 'n_estimators': 16, 'subsample': 0.7625843024719475, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 2, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:23:58,738]\u001b[0m Trial 14 finished with value: 0.0016017386512984233 and parameters: {'loss': 'huber', 'learning_rate': 0.0024129079432567775, 'n_estimators': 38, 'subsample': 0.8024133276053664, 'criterion': 'friedman_mse', 'min_samples_split': 50, 'min_samples_leaf': 3, 'max_depth': 13, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:00,021]\u001b[0m Trial 15 finished with value: -0.09365724313739254 and parameters: {'loss': 'ls', 'learning_rate': 0.010430800897890906, 'n_estimators': 470, 'subsample': 0.5775346142268778, 'criterion': 'friedman_mse', 'min_samples_split': 44, 'min_samples_leaf': 4, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:06,794]\u001b[0m Trial 16 finished with value: 0.01955819978822604 and parameters: {'loss': 'ls', 'learning_rate': 0.0013916950316964706, 'n_estimators': 726, 'subsample': 0.39864935962248704, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:11,767]\u001b[0m Trial 17 finished with value: 0.0021180175150264935 and parameters: {'loss': 'ls', 'learning_rate': 0.0008867452204869012, 'n_estimators': 732, 'subsample': 0.3431389110739617, 'criterion': 'friedman_mse', 'min_samples_split': 44, 'min_samples_leaf': 7, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:23,628]\u001b[0m Trial 18 finished with value: -0.0009131171340799327 and parameters: {'loss': 'lad', 'learning_rate': 4.313998753753253e-05, 'n_estimators': 981, 'subsample': 0.37929256720468296, 'criterion': 'friedman_mse', 'min_samples_split': 28, 'min_samples_leaf': 4, 'max_depth': 10, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:36,574]\u001b[0m Trial 19 finished with value: -0.007627541079917588 and parameters: {'loss': 'huber', 'learning_rate': 0.0007736060341691648, 'n_estimators': 825, 'subsample': 0.5671770697312797, 'criterion': 'friedman_mse', 'min_samples_split': 45, 'min_samples_leaf': 4, 'max_depth': 9, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:41,605]\u001b[0m Trial 20 finished with value: 3.1887320044443612e-06 and parameters: {'loss': 'ls', 'learning_rate': 5.5017776237106406e-06, 'n_estimators': 597, 'subsample': 0.4292417008155532, 'criterion': 'friedman_mse', 'min_samples_split': 35, 'min_samples_leaf': 10, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:57,389]\u001b[0m Trial 21 finished with value: -0.1425614737765626 and parameters: {'loss': 'ls', 'learning_rate': 0.007394506023817253, 'n_estimators': 772, 'subsample': 0.812273944113671, 'criterion': 'friedman_mse', 'min_samples_split': 46, 'min_samples_leaf': 2, 'max_depth': 13, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:24:58,667]\u001b[0m Trial 22 finished with value: 0.009851770370481905 and parameters: {'loss': 'ls', 'learning_rate': 0.000792889770048412, 'n_estimators': 472, 'subsample': 0.6045161938132648, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 2, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:00,004]\u001b[0m Trial 23 finished with value: 0.007443742623860161 and parameters: {'loss': 'ls', 'learning_rate': 0.0006836487213743117, 'n_estimators': 484, 'subsample': 0.6048778010382221, 'criterion': 'friedman_mse', 'min_samples_split': 41, 'min_samples_leaf': 3, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:07,733]\u001b[0m Trial 24 finished with value: 0.004559609384589547 and parameters: {'loss': 'ls', 'learning_rate': 7.011978728272978e-05, 'n_estimators': 639, 'subsample': 0.4892014079484022, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:09,154]\u001b[0m Trial 25 finished with value: 0.003882386709506358 and parameters: {'loss': 'ls', 'learning_rate': 0.000474279236432603, 'n_estimators': 904, 'subsample': 0.3499626585354441, 'criterion': 'friedman_mse', 'min_samples_split': 28, 'min_samples_leaf': 3, 'max_depth': 12, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:31,527]\u001b[0m Trial 26 finished with value: -0.14099305175827292 and parameters: {'loss': 'ls', 'learning_rate': 0.005572091595309623, 'n_estimators': 762, 'subsample': 0.9883691927644094, 'criterion': 'friedman_mse', 'min_samples_split': 41, 'min_samples_leaf': 4, 'max_depth': 15, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:35,821]\u001b[0m Trial 27 finished with value: -0.13177458286913524 and parameters: {'loss': 'huber', 'learning_rate': 0.022363504026034004, 'n_estimators': 550, 'subsample': 0.527514583801328, 'criterion': 'friedman_mse', 'min_samples_split': 47, 'min_samples_leaf': 6, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:36,828]\u001b[0m Trial 28 finished with value: 0.00021845819172516823 and parameters: {'loss': 'lad', 'learning_rate': 0.0010336982270793436, 'n_estimators': 391, 'subsample': 0.10154860555748157, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:39,331]\u001b[0m Trial 29 finished with value: 0.005001603239583652 and parameters: {'loss': 'ls', 'learning_rate': 0.0001103125029067958, 'n_estimators': 940, 'subsample': 0.6303566587518784, 'criterion': 'friedman_mse', 'min_samples_split': 38, 'min_samples_leaf': 3, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:39,992]\u001b[0m Trial 30 finished with value: 0.0009460916865023927 and parameters: {'loss': 'ls', 'learning_rate': 0.0003688554688872938, 'n_estimators': 380, 'subsample': 0.3945033608356492, 'criterion': 'friedman_mse', 'min_samples_split': 47, 'min_samples_leaf': 6, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:41,333]\u001b[0m Trial 31 finished with value: 0.009664561336538036 and parameters: {'loss': 'ls', 'learning_rate': 0.0005835540690529465, 'n_estimators': 464, 'subsample': 0.6081267864061677, 'criterion': 'friedman_mse', 'min_samples_split': 42, 'min_samples_leaf': 3, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:42,831]\u001b[0m Trial 32 finished with value: 0.013354925663266348 and parameters: {'loss': 'ls', 'learning_rate': 0.0014131919827033814, 'n_estimators': 419, 'subsample': 0.7021986729565596, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:43,607]\u001b[0m Trial 33 finished with value: 0.007326125565813801 and parameters: {'loss': 'ls', 'learning_rate': 0.00143384176344285, 'n_estimators': 207, 'subsample': 0.7144724020766443, 'criterion': 'friedman_mse', 'min_samples_split': 36, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:44,746]\u001b[0m Trial 34 finished with value: 0.00297167934826037 and parameters: {'loss': 'ls', 'learning_rate': 0.00017507051951806771, 'n_estimators': 412, 'subsample': 0.5430662915764843, 'criterion': 'friedman_mse', 'min_samples_split': 23, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:25:46,504]\u001b[0m Trial 35 finished with value: -0.02491835020695299 and parameters: {'loss': 'huber', 'learning_rate': 0.004719149521787553, 'n_estimators': 297, 'subsample': 0.25434157137986857, 'criterion': 'friedman_mse', 'min_samples_split': 31, 'min_samples_leaf': 4, 'max_depth': 12, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:03,508]\u001b[0m Trial 36 finished with value: -0.4509815997381452 and parameters: {'loss': 'quantile', 'learning_rate': 1.8937500289367125e-05, 'n_estimators': 689, 'subsample': 0.6790906375499043, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 3, 'max_depth': 13, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:05,658]\u001b[0m Trial 37 finished with value: 0.004659553733741495 and parameters: {'loss': 'ls', 'learning_rate': 0.0002411163436268346, 'n_estimators': 558, 'subsample': 0.7474736835486215, 'criterion': 'friedman_mse', 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:16,039]\u001b[0m Trial 38 finished with value: 0.001053264895932604 and parameters: {'loss': 'ls', 'learning_rate': 0.0015050988952057596, 'n_estimators': 815, 'subsample': 0.8154033501756192, 'criterion': 'friedman_mse', 'min_samples_split': 35, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:17,925]\u001b[0m Trial 39 finished with value: -0.834619583443553 and parameters: {'loss': 'quantile', 'learning_rate': 0.024984528280005875, 'n_estimators': 429, 'subsample': 0.30438127463712644, 'criterion': 'friedman_mse', 'min_samples_split': 48, 'min_samples_leaf': 4, 'max_depth': 10, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:18,651]\u001b[0m Trial 40 finished with value: -0.006143069204881835 and parameters: {'loss': 'lad', 'learning_rate': 0.0036105901207595524, 'n_estimators': 349, 'subsample': 0.4508047725967962, 'criterion': 'friedman_mse', 'min_samples_split': 30, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:20,040]\u001b[0m Trial 41 finished with value: 0.009228792527967045 and parameters: {'loss': 'ls', 'learning_rate': 0.0004828195802345126, 'n_estimators': 457, 'subsample': 0.636353148640728, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 3, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:21,497]\u001b[0m Trial 42 finished with value: 0.006474676329043749 and parameters: {'loss': 'ls', 'learning_rate': 0.0003499784450690683, 'n_estimators': 503, 'subsample': 0.5920815605866766, 'criterion': 'friedman_mse', 'min_samples_split': 40, 'min_samples_leaf': 3, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:22,299]\u001b[0m Trial 43 finished with value: 0.0015553260124379076 and parameters: {'loss': 'ls', 'learning_rate': 0.00011583332820259494, 'n_estimators': 329, 'subsample': 0.5079064087777556, 'criterion': 'friedman_mse', 'min_samples_split': 43, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:24,218]\u001b[0m Trial 44 finished with value: 0.0034995900080027065 and parameters: {'loss': 'ls', 'learning_rate': 0.0016670384982954986, 'n_estimators': 593, 'subsample': 0.639648417414679, 'criterion': 'friedman_mse', 'min_samples_split': 37, 'min_samples_leaf': 2, 'max_depth': 15, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:24,792]\u001b[0m Trial 45 finished with value: 0.005961447894622274 and parameters: {'loss': 'ls', 'learning_rate': 0.0006961020076277353, 'n_estimators': 235, 'subsample': 0.5410319680311289, 'criterion': 'friedman_mse', 'min_samples_split': 46, 'min_samples_leaf': 3, 'max_depth': 13, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:38,355]\u001b[0m Trial 46 finished with value: -0.4538266041252308 and parameters: {'loss': 'quantile', 'learning_rate': 0.0001973326409153508, 'n_estimators': 880, 'subsample': 0.6771167545924979, 'criterion': 'friedman_mse', 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 14, 'max_features': 'log2'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:51,422]\u001b[0m Trial 47 finished with value: 0.0032648817478595493 and parameters: {'loss': 'ls', 'learning_rate': 6.234570099224929e-05, 'n_estimators': 674, 'subsample': 0.7702589661983524, 'criterion': 'friedman_mse', 'min_samples_split': 48, 'min_samples_leaf': 7, 'max_depth': 12, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:51,845]\u001b[0m Trial 48 finished with value: 0.006118217844694018 and parameters: {'loss': 'ls', 'learning_rate': 0.0022015476648334104, 'n_estimators': 132, 'subsample': 0.8754852000650741, 'criterion': 'friedman_mse', 'min_samples_split': 33, 'min_samples_leaf': 8, 'max_depth': 8, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "\u001b[32m[I 2021-11-17 22:26:53,604]\u001b[0m Trial 49 finished with value: -0.040641982863412585 and parameters: {'loss': 'lad', 'learning_rate': 0.010888834210930834, 'n_estimators': 518, 'subsample': 0.2029685164446389, 'criterion': 'friedman_mse', 'min_samples_split': 39, 'min_samples_leaf': 5, 'max_depth': 4, 'max_features': 'auto'}. Best is trial 3 with value: 0.023999862875181188.\u001b[0m\n",
            "100%|██████████| 6/6 [16:13<00:00, 162.17s/it]\n"
          ]
        }
      ],
      "source": [
        "predictions_GBR = {}\n",
        "GBR = {}\n",
        "for i in trange(2016,2022):\n",
        "  X_train = data.loc[(data.index.year >= i - 8) & (data.index.year < i - 1), allFeatures]\n",
        "  y_train = data.loc[(data.index.year >= i - 8) & (data.index.year < i - 1), 'BV_1w target']\n",
        "\n",
        "  X_valid = data.loc[data.index.year == i - 1, allFeatures]\n",
        "  y_valid = data.loc[data.index.year == i - 1, 'BV_1w target']\n",
        "\n",
        "  X_test = data.loc[data.index.year == i, allFeatures]\n",
        "  y_test = data.loc[data.index.year == i, 'BV_1w target']\n",
        "\n",
        "  def objective(trial):\n",
        "    loss = trial.suggest_categorical('loss', ['ls', 'lad', 'huber', 'quantile'])\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n",
        "    n_estimators = trial.suggest_int('n_estimators', 10, 1000)\n",
        "    subsample = trial.suggest_float('subsample', 0.1, 1)\n",
        "    criterion = trial.suggest_categorical('criterion', ['friedman_mse'])\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 50)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10)\n",
        "    max_depth = trial.suggest_int('max_depth', 2, 15)\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
        "\n",
        "\n",
        "    regressor_obj = GradientBoostingRegressor(loss=loss, learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, criterion=criterion,\n",
        "                                              min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_depth=max_depth, max_features=max_features) \n",
        "    regressor_obj.fit(X_train, y_train)\n",
        "    score = r2_score(y_valid, regressor_obj.predict(X_valid))\n",
        "    return score\n",
        "\n",
        "\n",
        "  study = optuna.create_study(direction=\"maximize\")\n",
        "  study.optimize(objective, n_trials=50)\n",
        "\n",
        "  GBR[i] = GradientBoostingRegressor(**study.best_params)\n",
        "  GBR[i].fit(X_train, y_train)\n",
        "  predictions_GBR[i] = pd.DataFrame(GBR[i].predict(X_test), index=X_test.index, columns=['Predictions'])\n",
        "  predictions_GBR[i]['True'] = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  GBR R²: -0.04943796320338367\n",
            "  GBR MAE: 0.029401930623689558\n",
            "  GBR MSE: 0.0014376435102812781\n",
            "2017\n",
            "  GBR R²: -0.019829543936647598\n",
            "  GBR MAE: 0.019776789457596092\n",
            "  GBR MSE: 0.0006250608311186689\n",
            "2018\n",
            "  GBR R²: 0.001274594831239373\n",
            "  GBR MAE: 0.022888868560964344\n",
            "  GBR MSE: 0.000842607254055172\n",
            "2019\n",
            "  GBR R²: -0.014011098184658843\n",
            "  GBR MAE: 0.01849635837719279\n",
            "  GBR MSE: 0.0005091674966724714\n",
            "2020\n",
            "  GBR R²: 0.026161120302075846\n",
            "  GBR MAE: 0.03403599062515954\n",
            "  GBR MSE: 0.0028241355587559826\n",
            "2021\n",
            "  GBR R²: -0.0513300910143053\n",
            "  GBR MAE: 0.01878277382724996\n",
            "  GBR MSE: 0.000570156149735706\n"
          ]
        }
      ],
      "source": [
        "for i in predictions_GBR.keys():\n",
        "  print(i)\n",
        "  print('  GBR R²: {}'.format(r2_score(predictions_GBR[i]['True'],predictions_GBR[i]['Predictions'])))\n",
        "  print('  GBR MAE: {}'.format(mean_absolute_error(predictions_GBR[i]['True'],predictions_GBR[i]['Predictions'])))\n",
        "  print('  GBR MSE: {}'.format(mean_squared_error(predictions_GBR[i]['True'],predictions_GBR[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_GBR = {}\n",
        "for i in predictions_GBR.keys():\n",
        "  classification_GBR[i] = predictions_GBR[i].applymap(lambda x: 0 if x < 0 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  GBRclassification_GBR F1: 0.0\n",
            "  GBRclassification_GBR Accu: 0.3855421686746988\n",
            "  GBRclassification_GBR Precision: 0.0\n",
            "  GBRclassification_GBR Recall: 0.0\n",
            "2017\n",
            "  GBRclassification_GBR F1: 0.5542168674698795\n",
            "  GBRclassification_GBR Accu: 0.5506072874493927\n",
            "  GBRclassification_GBR Precision: 0.6764705882352942\n",
            "  GBRclassification_GBR Recall: 0.46938775510204084\n",
            "2018\n",
            "  GBRclassification_GBR F1: 0.5641025641025642\n",
            "  GBRclassification_GBR Accu: 0.5122950819672131\n",
            "  GBRclassification_GBR Precision: 0.5620437956204379\n",
            "  GBRclassification_GBR Recall: 0.5661764705882353\n",
            "2019\n",
            "  GBRclassification_GBR F1: 0.5963636363636364\n",
            "  GBRclassification_GBR Accu: 0.5506072874493927\n",
            "  GBRclassification_GBR Precision: 0.7192982456140351\n",
            "  GBRclassification_GBR Recall: 0.5093167701863354\n",
            "2020\n",
            "  GBRclassification_GBR F1: 0.6382978723404255\n",
            "  GBRclassification_GBR Accu: 0.5870445344129555\n",
            "  GBRclassification_GBR Precision: 0.6666666666666666\n",
            "  GBRclassification_GBR Recall: 0.6122448979591837\n",
            "2021\n",
            "  GBRclassification_GBR F1: 0.6287878787878788\n",
            "  GBRclassification_GBR Accu: 0.5288461538461539\n",
            "  GBRclassification_GBR Precision: 0.4853801169590643\n",
            "  GBRclassification_GBR Recall: 0.8924731182795699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lvenzel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "for i in classification_GBR.keys():\n",
        "  print(i)\n",
        "  print('  GBRclassification_GBR F1: {}'.format(f1_score(classification_GBR[i]['True'],classification_GBR[i]['Predictions'])))\n",
        "  print('  GBRclassification_GBR Accu: {}'.format(accuracy_score(classification_GBR[i]['True'],classification_GBR[i]['Predictions'])))\n",
        "  print('  GBRclassification_GBR Precision: {}'.format(precision_score(classification_GBR[i]['True'],classification_GBR[i]['Predictions'])))\n",
        "  print('  GBRclassification_GBR Recall: {}'.format(recall_score(classification_GBR[i]['True'],classification_GBR[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016: patrimonio final long-only: 100, long-short: 65.04940187414854\n",
            "2017: patrimonio final long-only: 109.75235263670902, long-short: 97.49406959703715\n",
            "2018: patrimonio final long-only: 129.64925599620335, long-short: 139.83195078411205\n",
            "2019: patrimonio final long-only: 134.57891689776687, long-short: 135.7854435781594\n",
            "2020: patrimonio final long-only: 126.08868974354598, long-short: 142.06624634008762\n",
            "2021: patrimonio final long-only: 97.62595896568956, long-short: 107.96518875818715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-107-0e171d6e8f08>:2: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  classification_GBR[i]['week'] = classification_GBR[i].index.week\n"
          ]
        }
      ],
      "source": [
        "for i in classification_GBR.keys():\n",
        "  classification_GBR[i]['week'] = classification_GBR[i].index.week\n",
        "  classification_GBR[i]['True'] = predictions_GBR[i]['True'] + 1\n",
        "  result = classification_GBR[i].groupby('week', as_index=False).first()\n",
        "  patrimonio = 100\n",
        "  patrimonio2 = 100\n",
        "  for j in result.index:\n",
        "    if result.loc[j, 'Predictions'] == 1:\n",
        "      patrimonio *= result.loc[j, 'True']\n",
        "      patrimonio2 *= result.loc[j, 'True']\n",
        "    else:\n",
        "      patrimonio2 *= 2 - result.loc[j, 'True']\n",
        "  print('{}: patrimonio final long-only: {}, long-short: {}'.format(i, patrimonio, patrimonio2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIi6ab-9973r",
        "outputId": "b97f6482-620b-4d96-a644-b358ed0ceee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1007 - coeff_determination: -73.3016 - val_loss: 0.0012 - val_coeff_determination: -0.3481 - lr: 0.0100\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0380 - coeff_determination: -26.7053 - val_loss: 0.0016 - val_coeff_determination: -0.8125 - lr: 0.0100\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0245 - coeff_determination: -16.7426 - val_loss: 0.0012 - val_coeff_determination: -0.4414 - lr: 0.0100\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0180 - coeff_determination: -12.2702 - val_loss: 0.0010 - val_coeff_determination: -0.1322 - lr: 0.0100\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0125 - coeff_determination: -7.6902 - val_loss: 0.0011 - val_coeff_determination: -0.2073 - lr: 0.0100\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0086 - coeff_determination: -5.1821 - val_loss: 9.6207e-04 - val_coeff_determination: -0.0915 - lr: 0.0100\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0073 - coeff_determination: -4.0961 - val_loss: 9.7449e-04 - val_coeff_determination: -0.0786 - lr: 0.0100\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0058 - coeff_determination: -3.0572 - val_loss: 9.6011e-04 - val_coeff_determination: -0.0971 - lr: 0.0100\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0056 - coeff_determination: -2.9990 - val_loss: 0.0010 - val_coeff_determination: -0.1026 - lr: 0.0100\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - coeff_determination: -2.1130 - val_loss: 9.4923e-04 - val_coeff_determination: -0.0850 - lr: 0.0100\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0040 - coeff_determination: -1.8142 - val_loss: 9.6660e-04 - val_coeff_determination: -0.0716 - lr: 0.0100\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - coeff_determination: -1.3735 - val_loss: 9.4718e-04 - val_coeff_determination: -0.0594 - lr: 0.0100\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - coeff_determination: -1.2927 - val_loss: 9.3691e-04 - val_coeff_determination: -0.0604 - lr: 0.0100\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -1.0619 - val_loss: 9.3925e-04 - val_coeff_determination: -0.0548 - lr: 0.0100\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - coeff_determination: -0.9220 - val_loss: 9.3696e-04 - val_coeff_determination: -0.0523 - lr: 0.0100\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -0.7489 - val_loss: 9.3493e-04 - val_coeff_determination: -0.0487 - lr: 0.0100\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -0.6980 - val_loss: 9.3367e-04 - val_coeff_determination: -0.0580 - lr: 0.0100\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -0.6831 - val_loss: 9.3360e-04 - val_coeff_determination: -0.0528 - lr: 0.0100\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0023 - coeff_determination: -0.6257 - val_loss: 9.3397e-04 - val_coeff_determination: -0.0544 - lr: 0.0100\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -0.6350 - val_loss: 9.3596e-04 - val_coeff_determination: -0.0511 - lr: 0.0100\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -0.4833 - val_loss: 9.3467e-04 - val_coeff_determination: -0.0531 - lr: 0.0100\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - coeff_determination: -0.4894 - val_loss: 9.3467e-04 - val_coeff_determination: -0.0476 - lr: 0.0100\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -0.4290 - val_loss: 9.3863e-04 - val_coeff_determination: -0.0680 - lr: 0.0100\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -0.3975 - val_loss: 9.3565e-04 - val_coeff_determination: -0.0462 - lr: 0.0100\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.3136 - val_loss: 9.3534e-04 - val_coeff_determination: -0.0622 - lr: 0.0100\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -0.3643 - val_loss: 9.3147e-04 - val_coeff_determination: -0.0508 - lr: 0.0100\n",
            "Epoch 27/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - coeff_determination: -0.1639\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2711 - val_loss: 9.3386e-04 - val_coeff_determination: -0.0575 - lr: 0.0100\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.3557 - val_loss: 9.3204e-04 - val_coeff_determination: -0.0504 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2624 - val_loss: 9.3254e-04 - val_coeff_determination: -0.0507 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.3471 - val_loss: 9.3265e-04 - val_coeff_determination: -0.0495 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2866 - val_loss: 9.3323e-04 - val_coeff_determination: -0.0540 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2636 - val_loss: 9.3232e-04 - val_coeff_determination: -0.0503 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2663 - val_loss: 9.3329e-04 - val_coeff_determination: -0.0540 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2454 - val_loss: 9.3242e-04 - val_coeff_determination: -0.0492 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.3291 - val_loss: 9.3248e-04 - val_coeff_determination: -0.0507 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2259 - val_loss: 9.3271e-04 - val_coeff_determination: -0.0525 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2070 - val_loss: 9.3259e-04 - val_coeff_determination: -0.0518 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1714 - val_loss: 9.3169e-04 - val_coeff_determination: -0.0482 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1803 - val_loss: 9.3171e-04 - val_coeff_determination: -0.0502 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.2516 - val_loss: 9.3310e-04 - val_coeff_determination: -0.0545 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1943 - val_loss: 9.3396e-04 - val_coeff_determination: -0.0566 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1620 - val_loss: 9.3298e-04 - val_coeff_determination: -0.0541 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1790 - val_loss: 9.3228e-04 - val_coeff_determination: -0.0522 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1662 - val_loss: 9.3446e-04 - val_coeff_determination: -0.0574 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1432 - val_loss: 9.3347e-04 - val_coeff_determination: -0.0544 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1718 - val_loss: 9.3244e-04 - val_coeff_determination: -0.0500 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1679 - val_loss: 9.3423e-04 - val_coeff_determination: -0.0557 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1680 - val_loss: 9.3259e-04 - val_coeff_determination: -0.0502 - lr: 0.0050\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1171 - val_loss: 9.3322e-04 - val_coeff_determination: -0.0523 - lr: 0.0050\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1906 - val_loss: 9.3780e-04 - val_coeff_determination: -0.0631 - lr: 0.0050\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1612 - val_loss: 9.3487e-04 - val_coeff_determination: -0.0565 - lr: 0.0050\n",
            "Epoch 52/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - coeff_determination: -0.1215\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1530 - val_loss: 9.3446e-04 - val_coeff_determination: -0.0554 - lr: 0.0050\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1503 - val_loss: 9.3364e-04 - val_coeff_determination: -0.0535 - lr: 0.0025\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1395 - val_loss: 9.3356e-04 - val_coeff_determination: -0.0531 - lr: 0.0025\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1372 - val_loss: 9.3603e-04 - val_coeff_determination: -0.0592 - lr: 0.0025\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1041 - val_loss: 9.3627e-04 - val_coeff_determination: -0.0596 - lr: 0.0025\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1009 - val_loss: 9.3473e-04 - val_coeff_determination: -0.0564 - lr: 0.0025\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1512 - val_loss: 9.3239e-04 - val_coeff_determination: -0.0485 - lr: 0.0025\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1144 - val_loss: 9.3294e-04 - val_coeff_determination: -0.0516 - lr: 0.0025\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1344 - val_loss: 9.3363e-04 - val_coeff_determination: -0.0537 - lr: 0.0025\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1561 - val_loss: 9.3880e-04 - val_coeff_determination: -0.0650 - lr: 0.0025\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1489 - val_loss: 9.3217e-04 - val_coeff_determination: -0.0475 - lr: 0.0025\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1383 - val_loss: 9.3811e-04 - val_coeff_determination: -0.0636 - lr: 0.0025\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1225 - val_loss: 9.3367e-04 - val_coeff_determination: -0.0539 - lr: 0.0025\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1097 - val_loss: 9.3417e-04 - val_coeff_determination: -0.0552 - lr: 0.0025\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1218 - val_loss: 9.3695e-04 - val_coeff_determination: -0.0614 - lr: 0.0025\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1305 - val_loss: 9.3253e-04 - val_coeff_determination: -0.0501 - lr: 0.0025\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1158 - val_loss: 9.3549e-04 - val_coeff_determination: -0.0580 - lr: 0.0025\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0970 - val_loss: 9.3861e-04 - val_coeff_determination: -0.0644 - lr: 0.0025\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0988 - val_loss: 9.3224e-04 - val_coeff_determination: -0.0482 - lr: 0.0025\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1018 - val_loss: 9.3592e-04 - val_coeff_determination: -0.0590 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1150 - val_loss: 9.3303e-04 - val_coeff_determination: -0.0518 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0605 - val_loss: 9.3411e-04 - val_coeff_determination: -0.0547 - lr: 0.0025\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0810 - val_loss: 9.3389e-04 - val_coeff_determination: -0.0541 - lr: 0.0025\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0902 - val_loss: 9.3846e-04 - val_coeff_determination: -0.0640 - lr: 0.0025\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1267 - val_loss: 9.3517e-04 - val_coeff_determination: -0.0572 - lr: 0.0025\n",
            "Epoch 77/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0023 - coeff_determination: -0.2447\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1120 - val_loss: 9.3394e-04 - val_coeff_determination: -0.0544 - lr: 0.0025\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0919 - val_loss: 9.3378e-04 - val_coeff_determination: -0.0540 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1031 - val_loss: 9.3303e-04 - val_coeff_determination: -0.0518 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0781 - val_loss: 9.3353e-04 - val_coeff_determination: -0.0534 - lr: 0.0012\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0785 - val_loss: 9.3553e-04 - val_coeff_determination: -0.0582 - lr: 0.0012\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0870 - val_loss: 9.3447e-04 - val_coeff_determination: -0.0559 - lr: 0.0012\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0860 - val_loss: 9.3381e-04 - val_coeff_determination: -0.0543 - lr: 0.0012\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0759 - val_loss: 9.3246e-04 - val_coeff_determination: -0.0502 - lr: 0.0012\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0787 - val_loss: 9.3436e-04 - val_coeff_determination: -0.0554 - lr: 0.0012\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0528 - val_loss: 9.3737e-04 - val_coeff_determination: -0.0620 - lr: 0.0012\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1027 - val_loss: 9.3306e-04 - val_coeff_determination: -0.0522 - lr: 0.0012\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0904 - val_loss: 9.3344e-04 - val_coeff_determination: -0.0533 - lr: 0.0012\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1247 - val_loss: 9.3755e-04 - val_coeff_determination: -0.0624 - lr: 0.0012\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0563 - val_loss: 9.3597e-04 - val_coeff_determination: -0.0592 - lr: 0.0012\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0717 - val_loss: 9.3349e-04 - val_coeff_determination: -0.0537 - lr: 0.0012\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1139 - val_loss: 9.3455e-04 - val_coeff_determination: -0.0563 - lr: 0.0012\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1148 - val_loss: 9.3223e-04 - val_coeff_determination: -0.0497 - lr: 0.0012\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0888 - val_loss: 9.3579e-04 - val_coeff_determination: -0.0588 - lr: 0.0012\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0890 - val_loss: 9.3437e-04 - val_coeff_determination: -0.0557 - lr: 0.0012\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0913 - val_loss: 9.3629e-04 - val_coeff_determination: -0.0598 - lr: 0.0012\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1343 - val_loss: 9.3396e-04 - val_coeff_determination: -0.0546 - lr: 0.0012\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0765 - val_loss: 9.3497e-04 - val_coeff_determination: -0.0570 - lr: 0.0012\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1195 - val_loss: 9.3530e-04 - val_coeff_determination: -0.0577 - lr: 0.0012\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0888 - val_loss: 9.3453e-04 - val_coeff_determination: -0.0559 - lr: 0.0012\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0921 - val_loss: 9.3442e-04 - val_coeff_determination: -0.0555 - lr: 0.0012\n",
            "Epoch 102/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - coeff_determination: -0.2191\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1185 - val_loss: 9.3562e-04 - val_coeff_determination: -0.0581 - lr: 0.0012\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0568 - val_loss: 9.3517e-04 - val_coeff_determination: -0.0571 - lr: 6.2500e-04\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0915 - val_loss: 9.3466e-04 - val_coeff_determination: -0.0559 - lr: 6.2500e-04\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0701 - val_loss: 9.3566e-04 - val_coeff_determination: -0.0581 - lr: 6.2500e-04\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0818 - val_loss: 9.3469e-04 - val_coeff_determination: -0.0559 - lr: 6.2500e-04\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.1672 - val_loss: 9.3336e-04 - val_coeff_determination: -0.0525 - lr: 6.2500e-04\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0799 - val_loss: 9.3436e-04 - val_coeff_determination: -0.0550 - lr: 6.2500e-04\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1030 - val_loss: 9.3566e-04 - val_coeff_determination: -0.0580 - lr: 6.2500e-04\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0580 - val_loss: 9.3442e-04 - val_coeff_determination: -0.0551 - lr: 6.2500e-04\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1174 - val_loss: 9.3459e-04 - val_coeff_determination: -0.0555 - lr: 6.2500e-04\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0843 - val_loss: 9.3311e-04 - val_coeff_determination: -0.0515 - lr: 6.2500e-04\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0883 - val_loss: 9.3532e-04 - val_coeff_determination: -0.0571 - lr: 6.2500e-04\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0832 - val_loss: 9.3632e-04 - val_coeff_determination: -0.0592 - lr: 6.2500e-04\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0955 - val_loss: 9.3654e-04 - val_coeff_determination: -0.0597 - lr: 6.2500e-04\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1006 - val_loss: 9.3746e-04 - val_coeff_determination: -0.0616 - lr: 6.2500e-04\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0802 - val_loss: 9.3439e-04 - val_coeff_determination: -0.0549 - lr: 6.2500e-04\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0736 - val_loss: 9.3257e-04 - val_coeff_determination: -0.0495 - lr: 6.2500e-04\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0780 - val_loss: 9.3444e-04 - val_coeff_determination: -0.0550 - lr: 6.2500e-04\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0581 - val_loss: 9.3482e-04 - val_coeff_determination: -0.0560 - lr: 6.2500e-04\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0613 - val_loss: 9.3554e-04 - val_coeff_determination: -0.0576 - lr: 6.2500e-04\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0905 - val_loss: 9.3497e-04 - val_coeff_determination: -0.0564 - lr: 6.2500e-04\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0365 - val_loss: 9.3327e-04 - val_coeff_determination: -0.0521 - lr: 6.2500e-04\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0687 - val_loss: 9.3417e-04 - val_coeff_determination: -0.0545 - lr: 6.2500e-04\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0689 - val_loss: 9.3389e-04 - val_coeff_determination: -0.0538 - lr: 6.2500e-04\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0491 - val_loss: 9.3411e-04 - val_coeff_determination: -0.0544 - lr: 6.2500e-04\n",
            "Epoch 127/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0018 - coeff_determination: -0.0024\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1038 - val_loss: 9.3739e-04 - val_coeff_determination: -0.0615 - lr: 6.2500e-04\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0548 - val_loss: 9.3618e-04 - val_coeff_determination: -0.0591 - lr: 3.1250e-04\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0490 - val_loss: 9.3440e-04 - val_coeff_determination: -0.0552 - lr: 3.1250e-04\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0913 - val_loss: 9.3386e-04 - val_coeff_determination: -0.0538 - lr: 3.1250e-04\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0742 - val_loss: 9.3415e-04 - val_coeff_determination: -0.0546 - lr: 3.1250e-04\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0702 - val_loss: 9.3484e-04 - val_coeff_determination: -0.0562 - lr: 3.1250e-04\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0985 - val_loss: 9.3507e-04 - val_coeff_determination: -0.0567 - lr: 3.1250e-04\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1030 - val_loss: 9.3524e-04 - val_coeff_determination: -0.0570 - lr: 3.1250e-04\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0544 - val_loss: 9.3466e-04 - val_coeff_determination: -0.0557 - lr: 3.1250e-04\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0805 - val_loss: 9.3446e-04 - val_coeff_determination: -0.0552 - lr: 3.1250e-04\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0525 - val_loss: 9.3534e-04 - val_coeff_determination: -0.0573 - lr: 3.1250e-04\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0526 - val_loss: 9.3414e-04 - val_coeff_determination: -0.0545 - lr: 3.1250e-04\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0723 - val_loss: 9.3481e-04 - val_coeff_determination: -0.0560 - lr: 3.1250e-04\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0350 - val_loss: 9.3508e-04 - val_coeff_determination: -0.0566 - lr: 3.1250e-04\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0739 - val_loss: 9.3443e-04 - val_coeff_determination: -0.0551 - lr: 3.1250e-04\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0670 - val_loss: 9.3561e-04 - val_coeff_determination: -0.0578 - lr: 3.1250e-04\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0744 - val_loss: 9.3604e-04 - val_coeff_determination: -0.0587 - lr: 3.1250e-04\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0401 - val_loss: 9.3584e-04 - val_coeff_determination: -0.0583 - lr: 3.1250e-04\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0436 - val_loss: 9.3442e-04 - val_coeff_determination: -0.0551 - lr: 3.1250e-04\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0610 - val_loss: 9.3533e-04 - val_coeff_determination: -0.0572 - lr: 3.1250e-04\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0484 - val_loss: 9.3454e-04 - val_coeff_determination: -0.0554 - lr: 3.1250e-04\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0747 - val_loss: 9.3478e-04 - val_coeff_determination: -0.0559 - lr: 3.1250e-04\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1040 - val_loss: 9.3424e-04 - val_coeff_determination: -0.0547 - lr: 3.1250e-04\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0789 - val_loss: 9.3511e-04 - val_coeff_determination: -0.0567 - lr: 3.1250e-04\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0644 - val_loss: 9.3342e-04 - val_coeff_determination: -0.0526 - lr: 3.1250e-04\n",
            "Epoch 152/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: 0.0540\n",
            "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0495 - val_loss: 9.3392e-04 - val_coeff_determination: -0.0540 - lr: 3.1250e-04\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0714 - val_loss: 9.3341e-04 - val_coeff_determination: -0.0526 - lr: 1.5625e-04\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0619 - val_loss: 9.3311e-04 - val_coeff_determination: -0.0518 - lr: 1.5625e-04\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0631 - val_loss: 9.3338e-04 - val_coeff_determination: -0.0526 - lr: 1.5625e-04\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0918 - val_loss: 9.3389e-04 - val_coeff_determination: -0.0539 - lr: 1.5625e-04\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0906 - val_loss: 9.3454e-04 - val_coeff_determination: -0.0555 - lr: 1.5625e-04\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0691 - val_loss: 9.3445e-04 - val_coeff_determination: -0.0553 - lr: 1.5625e-04\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0459 - val_loss: 9.3475e-04 - val_coeff_determination: -0.0560 - lr: 1.5625e-04\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0723 - val_loss: 9.3542e-04 - val_coeff_determination: -0.0575 - lr: 1.5625e-04\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0627 - val_loss: 9.3625e-04 - val_coeff_determination: -0.0593 - lr: 1.5625e-04\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0575 - val_loss: 9.3535e-04 - val_coeff_determination: -0.0574 - lr: 1.5625e-04\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0836 - val_loss: 9.3495e-04 - val_coeff_determination: -0.0565 - lr: 1.5625e-04\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0876 - val_loss: 9.3453e-04 - val_coeff_determination: -0.0555 - lr: 1.5625e-04\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0791 - val_loss: 9.3445e-04 - val_coeff_determination: -0.0553 - lr: 1.5625e-04\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0795 - val_loss: 9.3497e-04 - val_coeff_determination: -0.0565 - lr: 1.5625e-04\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0883 - val_loss: 9.3463e-04 - val_coeff_determination: -0.0557 - lr: 1.5625e-04\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0333 - val_loss: 9.3457e-04 - val_coeff_determination: -0.0555 - lr: 1.5625e-04\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0718 - val_loss: 9.3480e-04 - val_coeff_determination: -0.0561 - lr: 1.5625e-04\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0665 - val_loss: 9.3473e-04 - val_coeff_determination: -0.0559 - lr: 1.5625e-04\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0469 - val_loss: 9.3510e-04 - val_coeff_determination: -0.0568 - lr: 1.5625e-04\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0903 - val_loss: 9.3429e-04 - val_coeff_determination: -0.0549 - lr: 1.5625e-04\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.1008 - val_loss: 9.3466e-04 - val_coeff_determination: -0.0558 - lr: 1.5625e-04\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0560 - val_loss: 9.3405e-04 - val_coeff_determination: -0.0543 - lr: 1.5625e-04\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0664 - val_loss: 9.3412e-04 - val_coeff_determination: -0.0545 - lr: 1.5625e-04\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0503 - val_loss: 9.3439e-04 - val_coeff_determination: -0.0552 - lr: 1.5625e-04\n",
            "Epoch 177/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.8542e-04 - coeff_determination: -0.1360\n",
            "Epoch 00177: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0878 - val_loss: 9.3506e-04 - val_coeff_determination: -0.0567 - lr: 1.5625e-04\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0819 - val_loss: 9.3488e-04 - val_coeff_determination: -0.0563 - lr: 7.8125e-05\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0676 - val_loss: 9.3499e-04 - val_coeff_determination: -0.0566 - lr: 7.8125e-05\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0688 - val_loss: 9.3490e-04 - val_coeff_determination: -0.0564 - lr: 7.8125e-05\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0562 - val_loss: 9.3492e-04 - val_coeff_determination: -0.0564 - lr: 7.8125e-05\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0897 - val_loss: 9.3463e-04 - val_coeff_determination: -0.0557 - lr: 7.8125e-05\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0531 - val_loss: 9.3450e-04 - val_coeff_determination: -0.0554 - lr: 7.8125e-05\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0419 - val_loss: 9.3444e-04 - val_coeff_determination: -0.0553 - lr: 7.8125e-05\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0353 - val_loss: 9.3449e-04 - val_coeff_determination: -0.0554 - lr: 7.8125e-05\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - coeff_determination: -0.0519 - val_loss: 9.3401e-04 - val_coeff_determination: -0.0543 - lr: 7.8125e-05\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0621 - val_loss: 9.3429e-04 - val_coeff_determination: -0.0550 - lr: 7.8125e-05\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0754 - val_loss: 9.3414e-04 - val_coeff_determination: -0.0546 - lr: 7.8125e-05\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0497 - val_loss: 9.3481e-04 - val_coeff_determination: -0.0562 - lr: 7.8125e-05\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0758 - val_loss: 9.3449e-04 - val_coeff_determination: -0.0554 - lr: 7.8125e-05\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0835 - val_loss: 9.3461e-04 - val_coeff_determination: -0.0557 - lr: 7.8125e-05\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0612 - val_loss: 9.3511e-04 - val_coeff_determination: -0.0568 - lr: 7.8125e-05\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0469 - val_loss: 9.3519e-04 - val_coeff_determination: -0.0570 - lr: 7.8125e-05\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0934 - val_loss: 9.3488e-04 - val_coeff_determination: -0.0563 - lr: 7.8125e-05\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0642 - val_loss: 9.3466e-04 - val_coeff_determination: -0.0558 - lr: 7.8125e-05\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0615 - val_loss: 9.3492e-04 - val_coeff_determination: -0.0564 - lr: 7.8125e-05\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0445 - val_loss: 9.3520e-04 - val_coeff_determination: -0.0570 - lr: 7.8125e-05\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0479 - val_loss: 9.3499e-04 - val_coeff_determination: -0.0566 - lr: 7.8125e-05\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0699 - val_loss: 9.3485e-04 - val_coeff_determination: -0.0562 - lr: 7.8125e-05\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0558 - val_loss: 9.3480e-04 - val_coeff_determination: -0.0561 - lr: 7.8125e-05\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0777 - val_loss: 9.3495e-04 - val_coeff_determination: -0.0565 - lr: 7.8125e-05\n",
            "Epoch 202/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.0488\n",
            "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0671 - val_loss: 9.3483e-04 - val_coeff_determination: -0.0562 - lr: 7.8125e-05\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0685 - val_loss: 9.3471e-04 - val_coeff_determination: -0.0559 - lr: 3.9062e-05\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0806 - val_loss: 9.3457e-04 - val_coeff_determination: -0.0556 - lr: 3.9062e-05\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0528 - val_loss: 9.3449e-04 - val_coeff_determination: -0.0554 - lr: 3.9062e-05\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0567 - val_loss: 9.3462e-04 - val_coeff_determination: -0.0557 - lr: 3.9062e-05\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0728 - val_loss: 9.3472e-04 - val_coeff_determination: -0.0560 - lr: 3.9062e-05\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0664 - val_loss: 9.3464e-04 - val_coeff_determination: -0.0558 - lr: 3.9062e-05\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0575 - val_loss: 9.3474e-04 - val_coeff_determination: -0.0560 - lr: 3.9062e-05\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0566 - val_loss: 9.3477e-04 - val_coeff_determination: -0.0561 - lr: 3.9062e-05\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0303 - val_loss: 9.3501e-04 - val_coeff_determination: -0.0566 - lr: 3.9062e-05\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0634 - val_loss: 9.3505e-04 - val_coeff_determination: -0.0567 - lr: 3.9062e-05\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0394 - val_loss: 9.3479e-04 - val_coeff_determination: -0.0561 - lr: 3.9062e-05\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0662 - val_loss: 9.3492e-04 - val_coeff_determination: -0.0564 - lr: 3.9062e-05\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0619 - val_loss: 9.3491e-04 - val_coeff_determination: -0.0564 - lr: 3.9062e-05\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0800 - val_loss: 9.3518e-04 - val_coeff_determination: -0.0570 - lr: 3.9062e-05\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0619 - val_loss: 9.3561e-04 - val_coeff_determination: -0.0580 - lr: 3.9062e-05\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0543 - val_loss: 9.3573e-04 - val_coeff_determination: -0.0582 - lr: 3.9062e-05\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0527 - val_loss: 9.3558e-04 - val_coeff_determination: -0.0579 - lr: 3.9062e-05\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0721 - val_loss: 9.3554e-04 - val_coeff_determination: -0.0578 - lr: 3.9062e-05\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0776 - val_loss: 9.3518e-04 - val_coeff_determination: -0.0570 - lr: 3.9062e-05\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0475 - val_loss: 9.3498e-04 - val_coeff_determination: -0.0566 - lr: 3.9062e-05\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0771 - val_loss: 9.3483e-04 - val_coeff_determination: -0.0563 - lr: 3.9062e-05\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.0796 - val_loss: 9.3491e-04 - val_coeff_determination: -0.0564 - lr: 3.9062e-05\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0479 - val_loss: 9.3489e-04 - val_coeff_determination: -0.0564 - lr: 3.9062e-05\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.0721 - val_loss: 9.3486e-04 - val_coeff_determination: -0.0563 - lr: 3.9062e-05\n",
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2633 - coeff_determination: -272.5698 - val_loss: 0.0413 - val_coeff_determination: -41.8413 - lr: 0.0100\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0373 - coeff_determination: -35.8730 - val_loss: 0.0022 - val_coeff_determination: -0.8730 - lr: 0.0100\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0103 - coeff_determination: -9.3777 - val_loss: 0.0022 - val_coeff_determination: -0.9884 - lr: 0.0100\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0074 - coeff_determination: -6.7244 - val_loss: 0.0024 - val_coeff_determination: -1.1272 - lr: 0.0100\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0067 - coeff_determination: -5.7029 - val_loss: 0.0017 - val_coeff_determination: -0.4291 - lr: 0.0100\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0059 - coeff_determination: -5.0389 - val_loss: 0.0016 - val_coeff_determination: -0.3313 - lr: 0.0100\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0050 - coeff_determination: -4.1134 - val_loss: 0.0017 - val_coeff_determination: -0.3697 - lr: 0.0100\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0046 - coeff_determination: -3.7428 - val_loss: 0.0017 - val_coeff_determination: -0.3498 - lr: 0.0100\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - coeff_determination: -3.3880 - val_loss: 0.0016 - val_coeff_determination: -0.3306 - lr: 0.0100\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0039 - coeff_determination: -2.9775 - val_loss: 0.0016 - val_coeff_determination: -0.2664 - lr: 0.0100\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - coeff_determination: -2.5104 - val_loss: 0.0016 - val_coeff_determination: -0.2985 - lr: 0.0100\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0032 - coeff_determination: -2.3106 - val_loss: 0.0016 - val_coeff_determination: -0.3371 - lr: 0.0100\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - coeff_determination: -2.5391 - val_loss: 0.0016 - val_coeff_determination: -0.3137 - lr: 0.0100\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -2.0952 - val_loss: 0.0016 - val_coeff_determination: -0.3387 - lr: 0.0100\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - coeff_determination: -1.9871 - val_loss: 0.0016 - val_coeff_determination: -0.3184 - lr: 0.0100\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - coeff_determination: -1.8301 - val_loss: 0.0016 - val_coeff_determination: -0.2636 - lr: 0.0100\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -1.4988 - val_loss: 0.0016 - val_coeff_determination: -0.3249 - lr: 0.0100\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.4343 - val_loss: 0.0015 - val_coeff_determination: -0.2380 - lr: 0.0100\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0023 - coeff_determination: -1.2956 - val_loss: 0.0016 - val_coeff_determination: -0.2744 - lr: 0.0100\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - coeff_determination: -1.2550 - val_loss: 0.0016 - val_coeff_determination: -0.2854 - lr: 0.0100\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.3509 - val_loss: 0.0016 - val_coeff_determination: -0.2684 - lr: 0.0100\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.0859 - val_loss: 0.0016 - val_coeff_determination: -0.2659 - lr: 0.0100\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.0253 - val_loss: 0.0016 - val_coeff_determination: -0.2489 - lr: 0.0100\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.8689 - val_loss: 0.0016 - val_coeff_determination: -0.2543 - lr: 0.0100\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.8601 - val_loss: 0.0015 - val_coeff_determination: -0.2231 - lr: 0.0100\n",
            "Epoch 26/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0021 - coeff_determination: -0.8599\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.8172 - val_loss: 0.0016 - val_coeff_determination: -0.2487 - lr: 0.0100\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.8832 - val_loss: 0.0016 - val_coeff_determination: -0.2680 - lr: 0.0050\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.9164 - val_loss: 0.0015 - val_coeff_determination: -0.2340 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7198 - val_loss: 0.0016 - val_coeff_determination: -0.2484 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.8370 - val_loss: 0.0016 - val_coeff_determination: -0.2475 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.7749 - val_loss: 0.0016 - val_coeff_determination: -0.2445 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7476 - val_loss: 0.0016 - val_coeff_determination: -0.2530 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7012 - val_loss: 0.0015 - val_coeff_determination: -0.2093 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5613 - val_loss: 0.0015 - val_coeff_determination: -0.2118 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7409 - val_loss: 0.0015 - val_coeff_determination: -0.2212 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.6953 - val_loss: 0.0016 - val_coeff_determination: -0.2367 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6079 - val_loss: 0.0015 - val_coeff_determination: -0.2140 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6555 - val_loss: 0.0016 - val_coeff_determination: -0.2406 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.5773 - val_loss: 0.0016 - val_coeff_determination: -0.2482 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5625 - val_loss: 0.0015 - val_coeff_determination: -0.2233 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.5468 - val_loss: 0.0015 - val_coeff_determination: -0.2233 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.5940 - val_loss: 0.0015 - val_coeff_determination: -0.2191 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.4932 - val_loss: 0.0015 - val_coeff_determination: -0.1985 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5018 - val_loss: 0.0015 - val_coeff_determination: -0.2097 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3563 - val_loss: 0.0015 - val_coeff_determination: -0.2048 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4232 - val_loss: 0.0015 - val_coeff_determination: -0.2054 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.4621 - val_loss: 0.0015 - val_coeff_determination: -0.2302 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4032 - val_loss: 0.0015 - val_coeff_determination: -0.1844 - lr: 0.0050\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0015 - coeff_determination: -0.5100 - val_loss: 0.0015 - val_coeff_determination: -0.2192 - lr: 0.0050\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3903 - val_loss: 0.0015 - val_coeff_determination: -0.1974 - lr: 0.0050\n",
            "Epoch 51/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.3368\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.4548 - val_loss: 0.0015 - val_coeff_determination: -0.2154 - lr: 0.0050\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3368 - val_loss: 0.0015 - val_coeff_determination: -0.1906 - lr: 0.0025\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4029 - val_loss: 0.0015 - val_coeff_determination: -0.2089 - lr: 0.0025\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3206 - val_loss: 0.0015 - val_coeff_determination: -0.2061 - lr: 0.0025\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3258 - val_loss: 0.0015 - val_coeff_determination: -0.1967 - lr: 0.0025\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3825 - val_loss: 0.0015 - val_coeff_determination: -0.2057 - lr: 0.0025\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3507 - val_loss: 0.0015 - val_coeff_determination: -0.1932 - lr: 0.0025\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3223 - val_loss: 0.0015 - val_coeff_determination: -0.2077 - lr: 0.0025\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4125 - val_loss: 0.0015 - val_coeff_determination: -0.2030 - lr: 0.0025\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - coeff_determination: -0.3029 - val_loss: 0.0015 - val_coeff_determination: -0.1954 - lr: 0.0025\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4032 - val_loss: 0.0015 - val_coeff_determination: -0.1929 - lr: 0.0025\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3444 - val_loss: 0.0015 - val_coeff_determination: -0.1880 - lr: 0.0025\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3672 - val_loss: 0.0015 - val_coeff_determination: -0.1970 - lr: 0.0025\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4449 - val_loss: 0.0015 - val_coeff_determination: -0.1954 - lr: 0.0025\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3204 - val_loss: 0.0015 - val_coeff_determination: -0.2057 - lr: 0.0025\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3137 - val_loss: 0.0015 - val_coeff_determination: -0.2042 - lr: 0.0025\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2269 - val_loss: 0.0015 - val_coeff_determination: -0.1942 - lr: 0.0025\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2967 - val_loss: 0.0015 - val_coeff_determination: -0.1838 - lr: 0.0025\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2233 - val_loss: 0.0015 - val_coeff_determination: -0.1901 - lr: 0.0025\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3110 - val_loss: 0.0015 - val_coeff_determination: -0.1876 - lr: 0.0025\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3220 - val_loss: 0.0015 - val_coeff_determination: -0.1887 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2941 - val_loss: 0.0015 - val_coeff_determination: -0.1901 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3352 - val_loss: 0.0015 - val_coeff_determination: -0.2064 - lr: 0.0025\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2618 - val_loss: 0.0015 - val_coeff_determination: -0.1954 - lr: 0.0025\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2850 - val_loss: 0.0015 - val_coeff_determination: -0.1943 - lr: 0.0025\n",
            "Epoch 76/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.1524\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2494 - val_loss: 0.0015 - val_coeff_determination: -0.1819 - lr: 0.0025\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2251 - val_loss: 0.0015 - val_coeff_determination: -0.1816 - lr: 0.0012\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3064 - val_loss: 0.0015 - val_coeff_determination: -0.1761 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2860 - val_loss: 0.0015 - val_coeff_determination: -0.1887 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3034 - val_loss: 0.0015 - val_coeff_determination: -0.1863 - lr: 0.0012\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2870 - val_loss: 0.0015 - val_coeff_determination: -0.1893 - lr: 0.0012\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2593 - val_loss: 0.0015 - val_coeff_determination: -0.1904 - lr: 0.0012\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2262 - val_loss: 0.0015 - val_coeff_determination: -0.1903 - lr: 0.0012\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3097 - val_loss: 0.0015 - val_coeff_determination: -0.1906 - lr: 0.0012\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2215 - val_loss: 0.0015 - val_coeff_determination: -0.1903 - lr: 0.0012\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1971 - val_loss: 0.0015 - val_coeff_determination: -0.1843 - lr: 0.0012\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2336 - val_loss: 0.0015 - val_coeff_determination: -0.1861 - lr: 0.0012\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2641 - val_loss: 0.0015 - val_coeff_determination: -0.1856 - lr: 0.0012\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3469 - val_loss: 0.0015 - val_coeff_determination: -0.1825 - lr: 0.0012\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2436 - val_loss: 0.0015 - val_coeff_determination: -0.1899 - lr: 0.0012\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3047 - val_loss: 0.0015 - val_coeff_determination: -0.1812 - lr: 0.0012\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2487 - val_loss: 0.0015 - val_coeff_determination: -0.1866 - lr: 0.0012\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3265 - val_loss: 0.0015 - val_coeff_determination: -0.1813 - lr: 0.0012\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2581 - val_loss: 0.0015 - val_coeff_determination: -0.1838 - lr: 0.0012\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2529 - val_loss: 0.0015 - val_coeff_determination: -0.1788 - lr: 0.0012\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2454 - val_loss: 0.0015 - val_coeff_determination: -0.1721 - lr: 0.0012\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1872 - val_loss: 0.0015 - val_coeff_determination: -0.1833 - lr: 0.0012\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - coeff_determination: -0.2587 - val_loss: 0.0015 - val_coeff_determination: -0.1796 - lr: 0.0012\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2241 - val_loss: 0.0015 - val_coeff_determination: -0.1801 - lr: 0.0012\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2015 - val_loss: 0.0015 - val_coeff_determination: -0.1823 - lr: 0.0012\n",
            "Epoch 101/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.2589\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2116 - val_loss: 0.0015 - val_coeff_determination: -0.1781 - lr: 0.0012\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2237 - val_loss: 0.0015 - val_coeff_determination: -0.1764 - lr: 6.2500e-04\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2001 - val_loss: 0.0015 - val_coeff_determination: -0.1775 - lr: 6.2500e-04\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1622 - val_loss: 0.0015 - val_coeff_determination: -0.1766 - lr: 6.2500e-04\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2044 - val_loss: 0.0015 - val_coeff_determination: -0.1811 - lr: 6.2500e-04\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2079 - val_loss: 0.0015 - val_coeff_determination: -0.1862 - lr: 6.2500e-04\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2206 - val_loss: 0.0015 - val_coeff_determination: -0.1822 - lr: 6.2500e-04\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2165 - val_loss: 0.0015 - val_coeff_determination: -0.1803 - lr: 6.2500e-04\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2163 - val_loss: 0.0015 - val_coeff_determination: -0.1823 - lr: 6.2500e-04\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2093 - val_loss: 0.0015 - val_coeff_determination: -0.1780 - lr: 6.2500e-04\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1934 - val_loss: 0.0015 - val_coeff_determination: -0.1811 - lr: 6.2500e-04\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2109 - val_loss: 0.0015 - val_coeff_determination: -0.1809 - lr: 6.2500e-04\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - coeff_determination: -0.2389 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 6.2500e-04\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2398 - val_loss: 0.0015 - val_coeff_determination: -0.1745 - lr: 6.2500e-04\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1440 - val_loss: 0.0015 - val_coeff_determination: -0.1791 - lr: 6.2500e-04\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1602 - val_loss: 0.0015 - val_coeff_determination: -0.1744 - lr: 6.2500e-04\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.1678 - val_loss: 0.0015 - val_coeff_determination: -0.1758 - lr: 6.2500e-04\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1712 - val_loss: 0.0015 - val_coeff_determination: -0.1807 - lr: 6.2500e-04\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1734 - val_loss: 0.0015 - val_coeff_determination: -0.1822 - lr: 6.2500e-04\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2178 - val_loss: 0.0015 - val_coeff_determination: -0.1877 - lr: 6.2500e-04\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1600 - val_loss: 0.0015 - val_coeff_determination: -0.1768 - lr: 6.2500e-04\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2319 - val_loss: 0.0015 - val_coeff_determination: -0.1748 - lr: 6.2500e-04\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1946 - val_loss: 0.0015 - val_coeff_determination: -0.1846 - lr: 6.2500e-04\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1315 - val_loss: 0.0015 - val_coeff_determination: -0.1800 - lr: 6.2500e-04\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2217 - val_loss: 0.0015 - val_coeff_determination: -0.1754 - lr: 6.2500e-04\n",
            "Epoch 126/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.3626\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2430 - val_loss: 0.0015 - val_coeff_determination: -0.1808 - lr: 6.2500e-04\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1870 - val_loss: 0.0015 - val_coeff_determination: -0.1855 - lr: 3.1250e-04\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1737 - val_loss: 0.0015 - val_coeff_determination: -0.1851 - lr: 3.1250e-04\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1483 - val_loss: 0.0015 - val_coeff_determination: -0.1841 - lr: 3.1250e-04\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2464 - val_loss: 0.0015 - val_coeff_determination: -0.1813 - lr: 3.1250e-04\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2282 - val_loss: 0.0015 - val_coeff_determination: -0.1801 - lr: 3.1250e-04\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.1543 - val_loss: 0.0015 - val_coeff_determination: -0.1793 - lr: 3.1250e-04\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2176 - val_loss: 0.0015 - val_coeff_determination: -0.1787 - lr: 3.1250e-04\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1720 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 3.1250e-04\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2032 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 3.1250e-04\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - coeff_determination: -0.2224 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 3.1250e-04\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1259 - val_loss: 0.0015 - val_coeff_determination: -0.1751 - lr: 3.1250e-04\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2068 - val_loss: 0.0015 - val_coeff_determination: -0.1762 - lr: 3.1250e-04\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1838 - val_loss: 0.0015 - val_coeff_determination: -0.1771 - lr: 3.1250e-04\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1876 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 3.1250e-04\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1672 - val_loss: 0.0015 - val_coeff_determination: -0.1796 - lr: 3.1250e-04\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1790 - val_loss: 0.0015 - val_coeff_determination: -0.1864 - lr: 3.1250e-04\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1319 - val_loss: 0.0015 - val_coeff_determination: -0.1841 - lr: 3.1250e-04\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1511 - val_loss: 0.0015 - val_coeff_determination: -0.1785 - lr: 3.1250e-04\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1752 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 3.1250e-04\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1700 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 3.1250e-04\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1914 - val_loss: 0.0015 - val_coeff_determination: -0.1779 - lr: 3.1250e-04\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1939 - val_loss: 0.0015 - val_coeff_determination: -0.1827 - lr: 3.1250e-04\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.2239 - val_loss: 0.0015 - val_coeff_determination: -0.1870 - lr: 3.1250e-04\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1398 - val_loss: 0.0015 - val_coeff_determination: -0.1839 - lr: 3.1250e-04\n",
            "Epoch 151/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.1328\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1837 - val_loss: 0.0015 - val_coeff_determination: -0.1810 - lr: 3.1250e-04\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2068 - val_loss: 0.0015 - val_coeff_determination: -0.1794 - lr: 1.5625e-04\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1789 - val_loss: 0.0015 - val_coeff_determination: -0.1811 - lr: 1.5625e-04\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2006 - val_loss: 0.0015 - val_coeff_determination: -0.1815 - lr: 1.5625e-04\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1820 - val_loss: 0.0015 - val_coeff_determination: -0.1799 - lr: 1.5625e-04\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2089 - val_loss: 0.0015 - val_coeff_determination: -0.1814 - lr: 1.5625e-04\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2071 - val_loss: 0.0015 - val_coeff_determination: -0.1811 - lr: 1.5625e-04\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1566 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 1.5625e-04\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1839 - val_loss: 0.0015 - val_coeff_determination: -0.1755 - lr: 1.5625e-04\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1431 - val_loss: 0.0015 - val_coeff_determination: -0.1746 - lr: 1.5625e-04\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2412 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 1.5625e-04\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1502 - val_loss: 0.0015 - val_coeff_determination: -0.1794 - lr: 1.5625e-04\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1561 - val_loss: 0.0015 - val_coeff_determination: -0.1804 - lr: 1.5625e-04\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1575 - val_loss: 0.0015 - val_coeff_determination: -0.1777 - lr: 1.5625e-04\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1893 - val_loss: 0.0015 - val_coeff_determination: -0.1782 - lr: 1.5625e-04\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1762 - val_loss: 0.0015 - val_coeff_determination: -0.1786 - lr: 1.5625e-04\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1907 - val_loss: 0.0015 - val_coeff_determination: -0.1812 - lr: 1.5625e-04\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.2517 - val_loss: 0.0015 - val_coeff_determination: -0.1800 - lr: 1.5625e-04\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1623 - val_loss: 0.0015 - val_coeff_determination: -0.1800 - lr: 1.5625e-04\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1829 - val_loss: 0.0015 - val_coeff_determination: -0.1814 - lr: 1.5625e-04\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2049 - val_loss: 0.0015 - val_coeff_determination: -0.1797 - lr: 1.5625e-04\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1541 - val_loss: 0.0015 - val_coeff_determination: -0.1800 - lr: 1.5625e-04\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2037 - val_loss: 0.0015 - val_coeff_determination: -0.1788 - lr: 1.5625e-04\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2352 - val_loss: 0.0015 - val_coeff_determination: -0.1788 - lr: 1.5625e-04\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1990 - val_loss: 0.0015 - val_coeff_determination: -0.1822 - lr: 1.5625e-04\n",
            "Epoch 176/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0956\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1884 - val_loss: 0.0015 - val_coeff_determination: -0.1820 - lr: 1.5625e-04\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1983 - val_loss: 0.0015 - val_coeff_determination: -0.1810 - lr: 7.8125e-05\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1625 - val_loss: 0.0015 - val_coeff_determination: -0.1812 - lr: 7.8125e-05\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1525 - val_loss: 0.0015 - val_coeff_determination: -0.1820 - lr: 7.8125e-05\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1590 - val_loss: 0.0015 - val_coeff_determination: -0.1817 - lr: 7.8125e-05\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2022 - val_loss: 0.0015 - val_coeff_determination: -0.1813 - lr: 7.8125e-05\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1353 - val_loss: 0.0015 - val_coeff_determination: -0.1794 - lr: 7.8125e-05\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2481 - val_loss: 0.0015 - val_coeff_determination: -0.1798 - lr: 7.8125e-05\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2059 - val_loss: 0.0015 - val_coeff_determination: -0.1803 - lr: 7.8125e-05\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2121 - val_loss: 0.0015 - val_coeff_determination: -0.1812 - lr: 7.8125e-05\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1460 - val_loss: 0.0015 - val_coeff_determination: -0.1801 - lr: 7.8125e-05\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.1760 - val_loss: 0.0015 - val_coeff_determination: -0.1801 - lr: 7.8125e-05\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - coeff_determination: -0.2006 - val_loss: 0.0015 - val_coeff_determination: -0.1795 - lr: 7.8125e-05\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1497 - val_loss: 0.0015 - val_coeff_determination: -0.1794 - lr: 7.8125e-05\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1053 - val_loss: 0.0015 - val_coeff_determination: -0.1784 - lr: 7.8125e-05\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1635 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 7.8125e-05\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1277 - val_loss: 0.0015 - val_coeff_determination: -0.1775 - lr: 7.8125e-05\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1912 - val_loss: 0.0015 - val_coeff_determination: -0.1776 - lr: 7.8125e-05\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2146 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 7.8125e-05\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1917 - val_loss: 0.0015 - val_coeff_determination: -0.1766 - lr: 7.8125e-05\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2231 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 7.8125e-05\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1847 - val_loss: 0.0015 - val_coeff_determination: -0.1785 - lr: 7.8125e-05\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1535 - val_loss: 0.0015 - val_coeff_determination: -0.1787 - lr: 7.8125e-05\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1488 - val_loss: 0.0015 - val_coeff_determination: -0.1781 - lr: 7.8125e-05\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1704 - val_loss: 0.0015 - val_coeff_determination: -0.1783 - lr: 7.8125e-05\n",
            "Epoch 201/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.2370\n",
            "Epoch 00201: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2437 - val_loss: 0.0015 - val_coeff_determination: -0.1785 - lr: 7.8125e-05\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1668 - val_loss: 0.0015 - val_coeff_determination: -0.1790 - lr: 3.9062e-05\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1466 - val_loss: 0.0015 - val_coeff_determination: -0.1798 - lr: 3.9062e-05\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1954 - val_loss: 0.0015 - val_coeff_determination: -0.1797 - lr: 3.9062e-05\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1492 - val_loss: 0.0015 - val_coeff_determination: -0.1785 - lr: 3.9062e-05\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1516 - val_loss: 0.0015 - val_coeff_determination: -0.1780 - lr: 3.9062e-05\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.1232 - val_loss: 0.0015 - val_coeff_determination: -0.1772 - lr: 3.9062e-05\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1804 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 3.9062e-05\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1733 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 3.9062e-05\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1594 - val_loss: 0.0015 - val_coeff_determination: -0.1764 - lr: 3.9062e-05\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1595 - val_loss: 0.0015 - val_coeff_determination: -0.1761 - lr: 3.9062e-05\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1760 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 3.9062e-05\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2245 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 3.9062e-05\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1268 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 3.9062e-05\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2103 - val_loss: 0.0015 - val_coeff_determination: -0.1766 - lr: 3.9062e-05\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1632 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 3.9062e-05\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1452 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 3.9062e-05\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1412 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 3.9062e-05\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1933 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 3.9062e-05\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1596 - val_loss: 0.0015 - val_coeff_determination: -0.1771 - lr: 3.9062e-05\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1628 - val_loss: 0.0015 - val_coeff_determination: -0.1767 - lr: 3.9062e-05\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1896 - val_loss: 0.0015 - val_coeff_determination: -0.1777 - lr: 3.9062e-05\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1491 - val_loss: 0.0015 - val_coeff_determination: -0.1781 - lr: 3.9062e-05\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1973 - val_loss: 0.0015 - val_coeff_determination: -0.1779 - lr: 3.9062e-05\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.1438 - val_loss: 0.0015 - val_coeff_determination: -0.1777 - lr: 3.9062e-05\n",
            "Epoch 226/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.2978\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1652 - val_loss: 0.0015 - val_coeff_determination: -0.1775 - lr: 3.9062e-05\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1821 - val_loss: 0.0015 - val_coeff_determination: -0.1767 - lr: 1.9531e-05\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1905 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 1.9531e-05\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1929 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 1.9531e-05\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1508 - val_loss: 0.0015 - val_coeff_determination: -0.1776 - lr: 1.9531e-05\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1721 - val_loss: 0.0015 - val_coeff_determination: -0.1771 - lr: 1.9531e-05\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1448 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 1.9531e-05\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1910 - val_loss: 0.0015 - val_coeff_determination: -0.1767 - lr: 1.9531e-05\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1515 - val_loss: 0.0015 - val_coeff_determination: -0.1764 - lr: 1.9531e-05\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1765 - val_loss: 0.0015 - val_coeff_determination: -0.1761 - lr: 1.9531e-05\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1491 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 1.9531e-05\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2014 - val_loss: 0.0015 - val_coeff_determination: -0.1758 - lr: 1.9531e-05\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1633 - val_loss: 0.0015 - val_coeff_determination: -0.1756 - lr: 1.9531e-05\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0012 - coeff_determination: -0.1919 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 1.9531e-05\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1713 - val_loss: 0.0015 - val_coeff_determination: -0.1758 - lr: 1.9531e-05\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1456 - val_loss: 0.0015 - val_coeff_determination: -0.1761 - lr: 1.9531e-05\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1692 - val_loss: 0.0015 - val_coeff_determination: -0.1767 - lr: 1.9531e-05\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1627 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 1.9531e-05\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1658 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 1.9531e-05\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1422 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 1.9531e-05\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2108 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 1.9531e-05\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1743 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 1.9531e-05\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1473 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 1.9531e-05\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2030 - val_loss: 0.0015 - val_coeff_determination: -0.1766 - lr: 1.9531e-05\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1481 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 1.9531e-05\n",
            "Epoch 251/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.2282\n",
            "Epoch 00251: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1668 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 1.9531e-05\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1597 - val_loss: 0.0015 - val_coeff_determination: -0.1768 - lr: 9.7656e-06\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1222 - val_loss: 0.0015 - val_coeff_determination: -0.1767 - lr: 9.7656e-06\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1877 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 9.7656e-06\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1188 - val_loss: 0.0015 - val_coeff_determination: -0.1768 - lr: 9.7656e-06\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1499 - val_loss: 0.0015 - val_coeff_determination: -0.1766 - lr: 9.7656e-06\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1115 - val_loss: 0.0015 - val_coeff_determination: -0.1767 - lr: 9.7656e-06\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2085 - val_loss: 0.0015 - val_coeff_determination: -0.1770 - lr: 9.7656e-06\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1494 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 9.7656e-06\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2065 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 9.7656e-06\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1982 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 9.7656e-06\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1518 - val_loss: 0.0015 - val_coeff_determination: -0.1773 - lr: 9.7656e-06\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1998 - val_loss: 0.0015 - val_coeff_determination: -0.1768 - lr: 9.7656e-06\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - coeff_determination: -0.1607 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 9.7656e-06\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1854 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 9.7656e-06\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1335 - val_loss: 0.0015 - val_coeff_determination: -0.1769 - lr: 9.7656e-06\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1485 - val_loss: 0.0015 - val_coeff_determination: -0.1766 - lr: 9.7656e-06\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1595 - val_loss: 0.0015 - val_coeff_determination: -0.1765 - lr: 9.7656e-06\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1295 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 9.7656e-06\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1638 - val_loss: 0.0015 - val_coeff_determination: -0.1761 - lr: 9.7656e-06\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1831 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 9.7656e-06\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1654 - val_loss: 0.0015 - val_coeff_determination: -0.1763 - lr: 9.7656e-06\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1610 - val_loss: 0.0015 - val_coeff_determination: -0.1762 - lr: 9.7656e-06\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1234 - val_loss: 0.0015 - val_coeff_determination: -0.1762 - lr: 9.7656e-06\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2084 - val_loss: 0.0015 - val_coeff_determination: -0.1760 - lr: 9.7656e-06\n",
            "Epoch 276/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0748\n",
            "Epoch 00276: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1368 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 9.7656e-06\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1288 - val_loss: 0.0015 - val_coeff_determination: -0.1758 - lr: 4.8828e-06\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1641 - val_loss: 0.0015 - val_coeff_determination: -0.1757 - lr: 4.8828e-06\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1658 - val_loss: 0.0015 - val_coeff_determination: -0.1757 - lr: 4.8828e-06\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1392 - val_loss: 0.0015 - val_coeff_determination: -0.1757 - lr: 4.8828e-06\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1552 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1282 - val_loss: 0.0015 - val_coeff_determination: -0.1760 - lr: 4.8828e-06\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1297 - val_loss: 0.0015 - val_coeff_determination: -0.1760 - lr: 4.8828e-06\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - coeff_determination: -0.1313 - val_loss: 0.0015 - val_coeff_determination: -0.1758 - lr: 4.8828e-06\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1781 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1235 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1753 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1779 - val_loss: 0.0015 - val_coeff_determination: -0.1761 - lr: 4.8828e-06\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1313 - val_loss: 0.0015 - val_coeff_determination: -0.1760 - lr: 4.8828e-06\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1463 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1582 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1751 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1385 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1384 - val_loss: 0.0015 - val_coeff_determination: -0.1759 - lr: 4.8828e-06\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1504 - val_loss: 0.0015 - val_coeff_determination: -0.1758 - lr: 4.8828e-06\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1799 - val_loss: 0.0015 - val_coeff_determination: -0.1755 - lr: 4.8828e-06\n",
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0660 - coeff_determination: -66.3511 - val_loss: 7.9511e-04 - val_coeff_determination: -0.5301 - lr: 0.0100\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0264 - coeff_determination: -25.5099 - val_loss: 9.8282e-04 - val_coeff_determination: -0.9901 - lr: 0.0100\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0115 - coeff_determination: -10.7519 - val_loss: 7.0214e-04 - val_coeff_determination: -0.2879 - lr: 0.0100\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0067 - coeff_determination: -5.7270 - val_loss: 6.6298e-04 - val_coeff_determination: -0.1818 - lr: 0.0100\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0051 - coeff_determination: -4.2301 - val_loss: 6.4813e-04 - val_coeff_determination: -0.1402 - lr: 0.0100\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - coeff_determination: -3.1078 - val_loss: 7.0326e-04 - val_coeff_determination: -0.2937 - lr: 0.0100\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0035 - coeff_determination: -2.4796 - val_loss: 6.4286e-04 - val_coeff_determination: -0.1263 - lr: 0.0100\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - coeff_determination: -1.8099 - val_loss: 6.4555e-04 - val_coeff_determination: -0.1388 - lr: 0.0100\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - coeff_determination: -1.6930 - val_loss: 6.5024e-04 - val_coeff_determination: -0.1552 - lr: 0.0100\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.4959 - val_loss: 7.0109e-04 - val_coeff_determination: -0.2859 - lr: 0.0100\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - coeff_determination: -1.2715 - val_loss: 6.2856e-04 - val_coeff_determination: -0.0851 - lr: 0.0100\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.0701 - val_loss: 6.4335e-04 - val_coeff_determination: -0.1365 - lr: 0.0100\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.8982 - val_loss: 6.7780e-04 - val_coeff_determination: -0.2270 - lr: 0.0100\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.8095 - val_loss: 6.2134e-04 - val_coeff_determination: -0.0621 - lr: 0.0100\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.6917 - val_loss: 6.3312e-04 - val_coeff_determination: -0.1083 - lr: 0.0100\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6459 - val_loss: 6.3819e-04 - val_coeff_determination: -0.1232 - lr: 0.0100\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6572 - val_loss: 6.4752e-04 - val_coeff_determination: -0.1485 - lr: 0.0100\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5152 - val_loss: 6.4285e-04 - val_coeff_determination: -0.1360 - lr: 0.0100\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4468 - val_loss: 6.3607e-04 - val_coeff_determination: -0.1174 - lr: 0.0100\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4317 - val_loss: 6.5292e-04 - val_coeff_determination: -0.1622 - lr: 0.0100\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4437 - val_loss: 6.2885e-04 - val_coeff_determination: -0.0969 - lr: 0.0100\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4091 - val_loss: 6.5841e-04 - val_coeff_determination: -0.1752 - lr: 0.0100\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2688 - val_loss: 6.7273e-04 - val_coeff_determination: -0.2103 - lr: 0.0100\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - coeff_determination: -0.2754 - val_loss: 6.4428e-04 - val_coeff_determination: -0.1383 - lr: 0.0100\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2835 - val_loss: 6.3894e-04 - val_coeff_determination: -0.1243 - lr: 0.0100\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3945 - val_loss: 6.4561e-04 - val_coeff_determination: -0.1415 - lr: 0.0100\n",
            "Epoch 27/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.3516\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2674 - val_loss: 6.6565e-04 - val_coeff_determination: -0.1915 - lr: 0.0100\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1813 - val_loss: 6.4170e-04 - val_coeff_determination: -0.1309 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2524 - val_loss: 6.4854e-04 - val_coeff_determination: -0.1486 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2305 - val_loss: 6.3781e-04 - val_coeff_determination: -0.1205 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2435 - val_loss: 6.5188e-04 - val_coeff_determination: -0.1569 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2337 - val_loss: 6.4156e-04 - val_coeff_determination: -0.1303 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2328 - val_loss: 6.4712e-04 - val_coeff_determination: -0.1446 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2464 - val_loss: 6.4240e-04 - val_coeff_determination: -0.1323 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1495 - val_loss: 6.4005e-04 - val_coeff_determination: -0.1261 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1720 - val_loss: 6.4843e-04 - val_coeff_determination: -0.1476 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1751 - val_loss: 6.2765e-04 - val_coeff_determination: -0.0927 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1992 - val_loss: 6.4681e-04 - val_coeff_determination: -0.1435 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1939 - val_loss: 6.3335e-04 - val_coeff_determination: -0.1084 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1738 - val_loss: 6.4179e-04 - val_coeff_determination: -0.1306 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1902 - val_loss: 6.3798e-04 - val_coeff_determination: -0.1207 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1556 - val_loss: 6.7321e-04 - val_coeff_determination: -0.2084 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0012 - coeff_determination: -0.1934 - val_loss: 6.3464e-04 - val_coeff_determination: -0.1118 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1645 - val_loss: 6.3159e-04 - val_coeff_determination: -0.1036 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1069 - val_loss: 6.5654e-04 - val_coeff_determination: -0.1675 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1947 - val_loss: 6.1796e-04 - val_coeff_determination: -0.0645 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1503 - val_loss: 6.3562e-04 - val_coeff_determination: -0.1143 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1567 - val_loss: 6.4324e-04 - val_coeff_determination: -0.1339 - lr: 0.0050\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1538 - val_loss: 6.4331e-04 - val_coeff_determination: -0.1342 - lr: 0.0050\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1477 - val_loss: 6.3365e-04 - val_coeff_determination: -0.1091 - lr: 0.0050\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1304 - val_loss: 6.4059e-04 - val_coeff_determination: -0.1271 - lr: 0.0050\n",
            "Epoch 52/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.9963e-04 - coeff_determination: -0.1579\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0847 - val_loss: 6.5581e-04 - val_coeff_determination: -0.1653 - lr: 0.0050\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1406 - val_loss: 6.3811e-04 - val_coeff_determination: -0.1207 - lr: 0.0025\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1328 - val_loss: 6.4132e-04 - val_coeff_determination: -0.1290 - lr: 0.0025\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1155 - val_loss: 6.4815e-04 - val_coeff_determination: -0.1463 - lr: 0.0025\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1268 - val_loss: 6.5012e-04 - val_coeff_determination: -0.1513 - lr: 0.0025\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1184 - val_loss: 6.3887e-04 - val_coeff_determination: -0.1227 - lr: 0.0025\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1933 - val_loss: 6.4834e-04 - val_coeff_determination: -0.1468 - lr: 0.0025\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1320 - val_loss: 6.3691e-04 - val_coeff_determination: -0.1176 - lr: 0.0025\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - coeff_determination: -0.1153 - val_loss: 6.4424e-04 - val_coeff_determination: -0.1364 - lr: 0.0025\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1086 - val_loss: 6.3724e-04 - val_coeff_determination: -0.1184 - lr: 0.0025\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1355 - val_loss: 6.3095e-04 - val_coeff_determination: -0.1018 - lr: 0.0025\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1488 - val_loss: 6.4392e-04 - val_coeff_determination: -0.1355 - lr: 0.0025\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0795 - val_loss: 6.4733e-04 - val_coeff_determination: -0.1441 - lr: 0.0025\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1164 - val_loss: 6.4010e-04 - val_coeff_determination: -0.1256 - lr: 0.0025\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1456 - val_loss: 6.4711e-04 - val_coeff_determination: -0.1435 - lr: 0.0025\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1449 - val_loss: 6.3546e-04 - val_coeff_determination: -0.1136 - lr: 0.0025\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1041 - val_loss: 6.4888e-04 - val_coeff_determination: -0.1478 - lr: 0.0025\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1270 - val_loss: 6.3792e-04 - val_coeff_determination: -0.1200 - lr: 0.0025\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1389 - val_loss: 6.5014e-04 - val_coeff_determination: -0.1509 - lr: 0.0025\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1187 - val_loss: 6.3001e-04 - val_coeff_determination: -0.0991 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0817 - val_loss: 6.4495e-04 - val_coeff_determination: -0.1379 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1243 - val_loss: 6.4325e-04 - val_coeff_determination: -0.1336 - lr: 0.0025\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1035 - val_loss: 6.3757e-04 - val_coeff_determination: -0.1191 - lr: 0.0025\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1085 - val_loss: 6.3474e-04 - val_coeff_determination: -0.1118 - lr: 0.0025\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0916 - val_loss: 6.4239e-04 - val_coeff_determination: -0.1315 - lr: 0.0025\n",
            "Epoch 77/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0021\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0901 - val_loss: 6.4089e-04 - val_coeff_determination: -0.1276 - lr: 0.0025\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1070 - val_loss: 6.3928e-04 - val_coeff_determination: -0.1235 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1177 - val_loss: 6.4012e-04 - val_coeff_determination: -0.1256 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0956 - val_loss: 6.4106e-04 - val_coeff_determination: -0.1281 - lr: 0.0012\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1162 - val_loss: 6.4032e-04 - val_coeff_determination: -0.1262 - lr: 0.0012\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1191 - val_loss: 6.3631e-04 - val_coeff_determination: -0.1158 - lr: 0.0012\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1177 - val_loss: 6.3133e-04 - val_coeff_determination: -0.1027 - lr: 0.0012\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1276 - val_loss: 6.4228e-04 - val_coeff_determination: -0.1311 - lr: 0.0012\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0674 - val_loss: 6.4938e-04 - val_coeff_determination: -0.1489 - lr: 0.0012\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0902 - val_loss: 6.3898e-04 - val_coeff_determination: -0.1227 - lr: 0.0012\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0923 - val_loss: 6.3285e-04 - val_coeff_determination: -0.1068 - lr: 0.0012\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0951 - val_loss: 6.4727e-04 - val_coeff_determination: -0.1437 - lr: 0.0012\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0959 - val_loss: 6.3997e-04 - val_coeff_determination: -0.1252 - lr: 0.0012\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0948 - val_loss: 6.4635e-04 - val_coeff_determination: -0.1414 - lr: 0.0012\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1083 - val_loss: 6.3292e-04 - val_coeff_determination: -0.1070 - lr: 0.0012\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0627 - val_loss: 6.4968e-04 - val_coeff_determination: -0.1497 - lr: 0.0012\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0749 - val_loss: 6.4314e-04 - val_coeff_determination: -0.1333 - lr: 0.0012\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1404 - val_loss: 6.4077e-04 - val_coeff_determination: -0.1273 - lr: 0.0012\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0434 - val_loss: 6.4355e-04 - val_coeff_determination: -0.1343 - lr: 0.0012\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0680 - val_loss: 6.4072e-04 - val_coeff_determination: -0.1272 - lr: 0.0012\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0846 - val_loss: 6.3829e-04 - val_coeff_determination: -0.1209 - lr: 0.0012\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1050 - val_loss: 6.4287e-04 - val_coeff_determination: -0.1326 - lr: 0.0012\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1066 - val_loss: 6.3760e-04 - val_coeff_determination: -0.1191 - lr: 0.0012\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0580 - val_loss: 6.4235e-04 - val_coeff_determination: -0.1312 - lr: 0.0012\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0695 - val_loss: 6.4522e-04 - val_coeff_determination: -0.1384 - lr: 0.0012\n",
            "Epoch 102/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.9337e-04 - coeff_determination: -0.0621\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0803 - val_loss: 6.3474e-04 - val_coeff_determination: -0.1117 - lr: 0.0012\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0577 - val_loss: 6.3775e-04 - val_coeff_determination: -0.1194 - lr: 6.2500e-04\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0810 - val_loss: 6.3953e-04 - val_coeff_determination: -0.1240 - lr: 6.2500e-04\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1010 - val_loss: 6.4355e-04 - val_coeff_determination: -0.1342 - lr: 6.2500e-04\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0805 - val_loss: 6.4132e-04 - val_coeff_determination: -0.1285 - lr: 6.2500e-04\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0791 - val_loss: 6.4087e-04 - val_coeff_determination: -0.1274 - lr: 6.2500e-04\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0723 - val_loss: 6.4455e-04 - val_coeff_determination: -0.1367 - lr: 6.2500e-04\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1085 - val_loss: 6.3998e-04 - val_coeff_determination: -0.1251 - lr: 6.2500e-04\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0855 - val_loss: 6.4388e-04 - val_coeff_determination: -0.1350 - lr: 6.2500e-04\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0831 - val_loss: 6.4152e-04 - val_coeff_determination: -0.1290 - lr: 6.2500e-04\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.0712 - val_loss: 6.3624e-04 - val_coeff_determination: -0.1155 - lr: 6.2500e-04\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0972 - val_loss: 6.3769e-04 - val_coeff_determination: -0.1192 - lr: 6.2500e-04\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0573 - val_loss: 6.4064e-04 - val_coeff_determination: -0.1268 - lr: 6.2500e-04\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1017 - val_loss: 6.3457e-04 - val_coeff_determination: -0.1112 - lr: 6.2500e-04\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0885 - val_loss: 6.4334e-04 - val_coeff_determination: -0.1336 - lr: 6.2500e-04\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0710 - val_loss: 6.4045e-04 - val_coeff_determination: -0.1263 - lr: 6.2500e-04\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0580 - val_loss: 6.3432e-04 - val_coeff_determination: -0.1105 - lr: 6.2500e-04\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0516 - val_loss: 6.4242e-04 - val_coeff_determination: -0.1313 - lr: 6.2500e-04\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0797 - val_loss: 6.3713e-04 - val_coeff_determination: -0.1178 - lr: 6.2500e-04\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0655 - val_loss: 6.4049e-04 - val_coeff_determination: -0.1264 - lr: 6.2500e-04\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0797 - val_loss: 6.4022e-04 - val_coeff_determination: -0.1257 - lr: 6.2500e-04\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1019 - val_loss: 6.4478e-04 - val_coeff_determination: -0.1372 - lr: 6.2500e-04\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0808 - val_loss: 6.3784e-04 - val_coeff_determination: -0.1196 - lr: 6.2500e-04\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0712 - val_loss: 6.4092e-04 - val_coeff_determination: -0.1274 - lr: 6.2500e-04\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0803 - val_loss: 6.3748e-04 - val_coeff_determination: -0.1186 - lr: 6.2500e-04\n",
            "Epoch 127/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.1550\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1119 - val_loss: 6.3317e-04 - val_coeff_determination: -0.1075 - lr: 6.2500e-04\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0526 - val_loss: 6.4432e-04 - val_coeff_determination: -0.1360 - lr: 3.1250e-04\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.0640 - val_loss: 6.4014e-04 - val_coeff_determination: -0.1254 - lr: 3.1250e-04\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0663 - val_loss: 6.3917e-04 - val_coeff_determination: -0.1229 - lr: 3.1250e-04\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0968 - val_loss: 6.4001e-04 - val_coeff_determination: -0.1251 - lr: 3.1250e-04\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0837 - val_loss: 6.4140e-04 - val_coeff_determination: -0.1286 - lr: 3.1250e-04\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0891 - val_loss: 6.4013e-04 - val_coeff_determination: -0.1254 - lr: 3.1250e-04\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0950 - val_loss: 6.4435e-04 - val_coeff_determination: -0.1361 - lr: 3.1250e-04\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0765 - val_loss: 6.4376e-04 - val_coeff_determination: -0.1346 - lr: 3.1250e-04\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0795 - val_loss: 6.3612e-04 - val_coeff_determination: -0.1151 - lr: 3.1250e-04\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0757 - val_loss: 6.3422e-04 - val_coeff_determination: -0.1102 - lr: 3.1250e-04\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0728 - val_loss: 6.4238e-04 - val_coeff_determination: -0.1311 - lr: 3.1250e-04\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0791 - val_loss: 6.4448e-04 - val_coeff_determination: -0.1364 - lr: 3.1250e-04\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0742 - val_loss: 6.4171e-04 - val_coeff_determination: -0.1294 - lr: 3.1250e-04\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0768 - val_loss: 6.3757e-04 - val_coeff_determination: -0.1189 - lr: 3.1250e-04\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0654 - val_loss: 6.3859e-04 - val_coeff_determination: -0.1215 - lr: 3.1250e-04\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0771 - val_loss: 6.4942e-04 - val_coeff_determination: -0.1488 - lr: 3.1250e-04\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0799 - val_loss: 6.4462e-04 - val_coeff_determination: -0.1368 - lr: 3.1250e-04\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1106 - val_loss: 6.4154e-04 - val_coeff_determination: -0.1290 - lr: 3.1250e-04\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0825 - val_loss: 6.3927e-04 - val_coeff_determination: -0.1233 - lr: 3.1250e-04\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0694 - val_loss: 6.3799e-04 - val_coeff_determination: -0.1200 - lr: 3.1250e-04\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0668 - val_loss: 6.4311e-04 - val_coeff_determination: -0.1330 - lr: 3.1250e-04\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0723 - val_loss: 6.4207e-04 - val_coeff_determination: -0.1304 - lr: 3.1250e-04\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1044 - val_loss: 6.4179e-04 - val_coeff_determination: -0.1296 - lr: 3.1250e-04\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0891 - val_loss: 6.3561e-04 - val_coeff_determination: -0.1138 - lr: 3.1250e-04\n",
            "Epoch 152/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.3206e-04 - coeff_determination: -0.0341\n",
            "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0807 - val_loss: 6.3742e-04 - val_coeff_determination: -0.1185 - lr: 3.1250e-04\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0830 - val_loss: 6.4095e-04 - val_coeff_determination: -0.1275 - lr: 1.5625e-04\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0800 - val_loss: 6.4134e-04 - val_coeff_determination: -0.1285 - lr: 1.5625e-04\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0704 - val_loss: 6.3770e-04 - val_coeff_determination: -0.1192 - lr: 1.5625e-04\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0730 - val_loss: 6.3795e-04 - val_coeff_determination: -0.1199 - lr: 1.5625e-04\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0914 - val_loss: 6.3726e-04 - val_coeff_determination: -0.1181 - lr: 1.5625e-04\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0894 - val_loss: 6.3798e-04 - val_coeff_determination: -0.1199 - lr: 1.5625e-04\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0575 - val_loss: 6.3927e-04 - val_coeff_determination: -0.1232 - lr: 1.5625e-04\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0895 - val_loss: 6.4253e-04 - val_coeff_determination: -0.1315 - lr: 1.5625e-04\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0726 - val_loss: 6.4063e-04 - val_coeff_determination: -0.1267 - lr: 1.5625e-04\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0472 - val_loss: 6.4087e-04 - val_coeff_determination: -0.1273 - lr: 1.5625e-04\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0677 - val_loss: 6.3815e-04 - val_coeff_determination: -0.1204 - lr: 1.5625e-04\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0828 - val_loss: 6.3933e-04 - val_coeff_determination: -0.1234 - lr: 1.5625e-04\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0729 - val_loss: 6.4005e-04 - val_coeff_determination: -0.1252 - lr: 1.5625e-04\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0634 - val_loss: 6.4140e-04 - val_coeff_determination: -0.1287 - lr: 1.5625e-04\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0642 - val_loss: 6.4204e-04 - val_coeff_determination: -0.1303 - lr: 1.5625e-04\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0857 - val_loss: 6.4221e-04 - val_coeff_determination: -0.1307 - lr: 1.5625e-04\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0762 - val_loss: 6.4536e-04 - val_coeff_determination: -0.1386 - lr: 1.5625e-04\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0766 - val_loss: 6.4507e-04 - val_coeff_determination: -0.1379 - lr: 1.5625e-04\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0910 - val_loss: 6.4474e-04 - val_coeff_determination: -0.1371 - lr: 1.5625e-04\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0834 - val_loss: 6.4441e-04 - val_coeff_determination: -0.1362 - lr: 1.5625e-04\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0629 - val_loss: 6.3971e-04 - val_coeff_determination: -0.1244 - lr: 1.5625e-04\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0692 - val_loss: 6.3619e-04 - val_coeff_determination: -0.1153 - lr: 1.5625e-04\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0589 - val_loss: 6.4064e-04 - val_coeff_determination: -0.1267 - lr: 1.5625e-04\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.0480 - val_loss: 6.3803e-04 - val_coeff_determination: -0.1201 - lr: 1.5625e-04\n",
            "Epoch 177/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.1998e-04 - coeff_determination: -0.0794\n",
            "Epoch 00177: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0904 - val_loss: 6.4091e-04 - val_coeff_determination: -0.1274 - lr: 1.5625e-04\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0446 - val_loss: 6.4199e-04 - val_coeff_determination: -0.1301 - lr: 7.8125e-05\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0491 - val_loss: 6.4182e-04 - val_coeff_determination: -0.1297 - lr: 7.8125e-05\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0662 - val_loss: 6.4235e-04 - val_coeff_determination: -0.1310 - lr: 7.8125e-05\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1008 - val_loss: 6.4194e-04 - val_coeff_determination: -0.1300 - lr: 7.8125e-05\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0745 - val_loss: 6.4188e-04 - val_coeff_determination: -0.1298 - lr: 7.8125e-05\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0989 - val_loss: 6.3827e-04 - val_coeff_determination: -0.1207 - lr: 7.8125e-05\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0853 - val_loss: 6.3902e-04 - val_coeff_determination: -0.1226 - lr: 7.8125e-05\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0678 - val_loss: 6.3987e-04 - val_coeff_determination: -0.1247 - lr: 7.8125e-05\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0810 - val_loss: 6.3895e-04 - val_coeff_determination: -0.1224 - lr: 7.8125e-05\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0542 - val_loss: 6.3875e-04 - val_coeff_determination: -0.1219 - lr: 7.8125e-05\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0010 - coeff_determination: -0.0323 - val_loss: 6.3950e-04 - val_coeff_determination: -0.1238 - lr: 7.8125e-05\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0657 - val_loss: 6.3994e-04 - val_coeff_determination: -0.1249 - lr: 7.8125e-05\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0795 - val_loss: 6.4102e-04 - val_coeff_determination: -0.1277 - lr: 7.8125e-05\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0819 - val_loss: 6.4071e-04 - val_coeff_determination: -0.1269 - lr: 7.8125e-05\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0667 - val_loss: 6.4261e-04 - val_coeff_determination: -0.1317 - lr: 7.8125e-05\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0575 - val_loss: 6.4040e-04 - val_coeff_determination: -0.1261 - lr: 7.8125e-05\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0878 - val_loss: 6.4241e-04 - val_coeff_determination: -0.1312 - lr: 7.8125e-05\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0728 - val_loss: 6.4036e-04 - val_coeff_determination: -0.1260 - lr: 7.8125e-05\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0792 - val_loss: 6.3948e-04 - val_coeff_determination: -0.1238 - lr: 7.8125e-05\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0762 - val_loss: 6.4149e-04 - val_coeff_determination: -0.1289 - lr: 7.8125e-05\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0478 - val_loss: 6.4111e-04 - val_coeff_determination: -0.1279 - lr: 7.8125e-05\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0715 - val_loss: 6.4018e-04 - val_coeff_determination: -0.1255 - lr: 7.8125e-05\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0887 - val_loss: 6.4034e-04 - val_coeff_determination: -0.1259 - lr: 7.8125e-05\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0707 - val_loss: 6.3852e-04 - val_coeff_determination: -0.1213 - lr: 7.8125e-05\n",
            "Epoch 202/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.1105\n",
            "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0603 - val_loss: 6.3937e-04 - val_coeff_determination: -0.1235 - lr: 7.8125e-05\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0745 - val_loss: 6.3995e-04 - val_coeff_determination: -0.1249 - lr: 3.9062e-05\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0950 - val_loss: 6.3910e-04 - val_coeff_determination: -0.1228 - lr: 3.9062e-05\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0613 - val_loss: 6.3947e-04 - val_coeff_determination: -0.1237 - lr: 3.9062e-05\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0655 - val_loss: 6.3962e-04 - val_coeff_determination: -0.1241 - lr: 3.9062e-05\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0702 - val_loss: 6.4006e-04 - val_coeff_determination: -0.1252 - lr: 3.9062e-05\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0479 - val_loss: 6.4101e-04 - val_coeff_determination: -0.1277 - lr: 3.9062e-05\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0582 - val_loss: 6.4053e-04 - val_coeff_determination: -0.1264 - lr: 3.9062e-05\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0702 - val_loss: 6.4119e-04 - val_coeff_determination: -0.1281 - lr: 3.9062e-05\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0646 - val_loss: 6.4165e-04 - val_coeff_determination: -0.1293 - lr: 3.9062e-05\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0793 - val_loss: 6.4154e-04 - val_coeff_determination: -0.1290 - lr: 3.9062e-05\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0921 - val_loss: 6.4306e-04 - val_coeff_determination: -0.1328 - lr: 3.9062e-05\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0475 - val_loss: 6.4232e-04 - val_coeff_determination: -0.1310 - lr: 3.9062e-05\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0773 - val_loss: 6.4234e-04 - val_coeff_determination: -0.1310 - lr: 3.9062e-05\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0578 - val_loss: 6.4104e-04 - val_coeff_determination: -0.1277 - lr: 3.9062e-05\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0567 - val_loss: 6.4012e-04 - val_coeff_determination: -0.1254 - lr: 3.9062e-05\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0641 - val_loss: 6.4037e-04 - val_coeff_determination: -0.1260 - lr: 3.9062e-05\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0700 - val_loss: 6.4085e-04 - val_coeff_determination: -0.1272 - lr: 3.9062e-05\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0729 - val_loss: 6.4003e-04 - val_coeff_determination: -0.1252 - lr: 3.9062e-05\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0485 - val_loss: 6.4000e-04 - val_coeff_determination: -0.1251 - lr: 3.9062e-05\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0556 - val_loss: 6.4054e-04 - val_coeff_determination: -0.1265 - lr: 3.9062e-05\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0648 - val_loss: 6.4103e-04 - val_coeff_determination: -0.1277 - lr: 3.9062e-05\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0453 - val_loss: 6.4017e-04 - val_coeff_determination: -0.1255 - lr: 3.9062e-05\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0760 - val_loss: 6.3961e-04 - val_coeff_determination: -0.1241 - lr: 3.9062e-05\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0010 - coeff_determination: -0.0542 - val_loss: 6.3979e-04 - val_coeff_determination: -0.1246 - lr: 3.9062e-05\n",
            "Epoch 227/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: 4.4161e-04\n",
            "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0548 - val_loss: 6.3905e-04 - val_coeff_determination: -0.1227 - lr: 3.9062e-05\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0545 - val_loss: 6.3931e-04 - val_coeff_determination: -0.1233 - lr: 1.9531e-05\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0671 - val_loss: 6.3938e-04 - val_coeff_determination: -0.1235 - lr: 1.9531e-05\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0644 - val_loss: 6.3970e-04 - val_coeff_determination: -0.1243 - lr: 1.9531e-05\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0872 - val_loss: 6.3962e-04 - val_coeff_determination: -0.1241 - lr: 1.9531e-05\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0717 - val_loss: 6.3989e-04 - val_coeff_determination: -0.1248 - lr: 1.9531e-05\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0694 - val_loss: 6.4018e-04 - val_coeff_determination: -0.1255 - lr: 1.9531e-05\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0626 - val_loss: 6.3973e-04 - val_coeff_determination: -0.1244 - lr: 1.9531e-05\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0821 - val_loss: 6.3997e-04 - val_coeff_determination: -0.1250 - lr: 1.9531e-05\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0482 - val_loss: 6.4054e-04 - val_coeff_determination: -0.1265 - lr: 1.9531e-05\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0771 - val_loss: 6.4044e-04 - val_coeff_determination: -0.1262 - lr: 1.9531e-05\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0600 - val_loss: 6.4060e-04 - val_coeff_determination: -0.1266 - lr: 1.9531e-05\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0445 - val_loss: 6.4084e-04 - val_coeff_determination: -0.1272 - lr: 1.9531e-05\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0959 - val_loss: 6.4128e-04 - val_coeff_determination: -0.1284 - lr: 1.9531e-05\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0801 - val_loss: 6.4156e-04 - val_coeff_determination: -0.1291 - lr: 1.9531e-05\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0881 - val_loss: 6.4083e-04 - val_coeff_determination: -0.1272 - lr: 1.9531e-05\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0686 - val_loss: 6.4037e-04 - val_coeff_determination: -0.1260 - lr: 1.9531e-05\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0680 - val_loss: 6.4027e-04 - val_coeff_determination: -0.1258 - lr: 1.9531e-05\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0010 - coeff_determination: -0.0533 - val_loss: 6.4029e-04 - val_coeff_determination: -0.1258 - lr: 1.9531e-05\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0589 - val_loss: 6.4062e-04 - val_coeff_determination: -0.1267 - lr: 1.9531e-05\n",
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1857 - coeff_determination: -177.2292 - val_loss: 0.0441 - val_coeff_determination: -49.8051 - lr: 0.0100\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0547 - coeff_determination: -55.8580 - val_loss: 0.0081 - val_coeff_determination: -9.1221 - lr: 0.0100\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0331 - coeff_determination: -33.5464 - val_loss: 0.0012 - val_coeff_determination: -0.3802 - lr: 0.0100\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0276 - coeff_determination: -28.7002 - val_loss: 0.0011 - val_coeff_determination: -0.4294 - lr: 0.0100\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0222 - coeff_determination: -21.8213 - val_loss: 9.5407e-04 - val_coeff_determination: -0.1141 - lr: 0.0100\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0167 - coeff_determination: -15.9904 - val_loss: 9.0757e-04 - val_coeff_determination: -0.0986 - lr: 0.0100\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0139 - coeff_determination: -13.1351 - val_loss: 8.9232e-04 - val_coeff_determination: -0.0615 - lr: 0.0100\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0111 - coeff_determination: -10.7804 - val_loss: 8.5343e-04 - val_coeff_determination: -0.0227 - lr: 0.0100\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0092 - coeff_determination: -8.4349 - val_loss: 8.6473e-04 - val_coeff_determination: -0.0277 - lr: 0.0100\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0070 - coeff_determination: -6.1854 - val_loss: 8.8035e-04 - val_coeff_determination: -0.0425 - lr: 0.0100\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0061 - coeff_determination: -5.2786 - val_loss: 8.6335e-04 - val_coeff_determination: -0.0278 - lr: 0.0100\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0053 - coeff_determination: -4.4050 - val_loss: 8.7720e-04 - val_coeff_determination: -0.0434 - lr: 0.0100\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0044 - coeff_determination: -3.4653 - val_loss: 8.7522e-04 - val_coeff_determination: -0.0429 - lr: 0.0100\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - coeff_determination: -3.1191 - val_loss: 8.7157e-04 - val_coeff_determination: -0.0406 - lr: 0.0100\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0037 - coeff_determination: -2.8725 - val_loss: 8.5675e-04 - val_coeff_determination: -0.0249 - lr: 0.0100\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - coeff_determination: -2.3808 - val_loss: 8.6546e-04 - val_coeff_determination: -0.0346 - lr: 0.0100\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -2.0737 - val_loss: 8.7209e-04 - val_coeff_determination: -0.0413 - lr: 0.0100\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -2.0973 - val_loss: 8.6777e-04 - val_coeff_determination: -0.0367 - lr: 0.0100\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - coeff_determination: -1.6515 - val_loss: 8.7330e-04 - val_coeff_determination: -0.0428 - lr: 0.0100\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -1.5385 - val_loss: 8.6646e-04 - val_coeff_determination: -0.0355 - lr: 0.0100\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -1.4930 - val_loss: 8.6258e-04 - val_coeff_determination: -0.0321 - lr: 0.0100\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.1495 - val_loss: 8.6764e-04 - val_coeff_determination: -0.0379 - lr: 0.0100\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.1743 - val_loss: 8.6566e-04 - val_coeff_determination: -0.0357 - lr: 0.0100\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.0077 - val_loss: 8.4858e-04 - val_coeff_determination: -0.0162 - lr: 0.0100\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.8987 - val_loss: 8.6981e-04 - val_coeff_determination: -0.0401 - lr: 0.0100\n",
            "Epoch 26/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0020 - coeff_determination: -1.3315\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.8836 - val_loss: 8.5369e-04 - val_coeff_determination: -0.0217 - lr: 0.0100\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0017 - coeff_determination: -0.6759 - val_loss: 8.4803e-04 - val_coeff_determination: -0.0153 - lr: 0.0050\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7168 - val_loss: 8.5065e-04 - val_coeff_determination: -0.0183 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7379 - val_loss: 8.5038e-04 - val_coeff_determination: -0.0180 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6365 - val_loss: 8.5932e-04 - val_coeff_determination: -0.0283 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6076 - val_loss: 8.5246e-04 - val_coeff_determination: -0.0206 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.5867 - val_loss: 8.5319e-04 - val_coeff_determination: -0.0214 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.6895 - val_loss: 8.5261e-04 - val_coeff_determination: -0.0208 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5419 - val_loss: 8.4999e-04 - val_coeff_determination: -0.0178 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6543 - val_loss: 8.6249e-04 - val_coeff_determination: -0.0322 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5422 - val_loss: 8.5540e-04 - val_coeff_determination: -0.0240 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5055 - val_loss: 8.6091e-04 - val_coeff_determination: -0.0303 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5059 - val_loss: 8.5467e-04 - val_coeff_determination: -0.0232 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4867 - val_loss: 8.4874e-04 - val_coeff_determination: -0.0165 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - coeff_determination: -0.5440 - val_loss: 8.5354e-04 - val_coeff_determination: -0.0221 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5496 - val_loss: 8.4880e-04 - val_coeff_determination: -0.0167 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4722 - val_loss: 8.5159e-04 - val_coeff_determination: -0.0200 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4011 - val_loss: 8.4741e-04 - val_coeff_determination: -0.0153 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4055 - val_loss: 8.4577e-04 - val_coeff_determination: -0.0133 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3834 - val_loss: 8.4936e-04 - val_coeff_determination: -0.0174 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3530 - val_loss: 8.5167e-04 - val_coeff_determination: -0.0201 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4199 - val_loss: 8.5556e-04 - val_coeff_determination: -0.0247 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.3785 - val_loss: 8.5822e-04 - val_coeff_determination: -0.0280 - lr: 0.0050\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3654 - val_loss: 8.4659e-04 - val_coeff_determination: -0.0147 - lr: 0.0050\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3558 - val_loss: 8.4606e-04 - val_coeff_determination: -0.0141 - lr: 0.0050\n",
            "Epoch 51/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.6390\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3558 - val_loss: 8.4835e-04 - val_coeff_determination: -0.0169 - lr: 0.0050\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0013 - coeff_determination: -0.3364 - val_loss: 8.4652e-04 - val_coeff_determination: -0.0147 - lr: 0.0025\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2844 - val_loss: 8.4505e-04 - val_coeff_determination: -0.0130 - lr: 0.0025\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3041 - val_loss: 8.4462e-04 - val_coeff_determination: -0.0125 - lr: 0.0025\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3394 - val_loss: 8.4536e-04 - val_coeff_determination: -0.0134 - lr: 0.0025\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3003 - val_loss: 8.5096e-04 - val_coeff_determination: -0.0200 - lr: 0.0025\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2756 - val_loss: 8.4722e-04 - val_coeff_determination: -0.0157 - lr: 0.0025\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3208 - val_loss: 8.5217e-04 - val_coeff_determination: -0.0215 - lr: 0.0025\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2109 - val_loss: 8.4637e-04 - val_coeff_determination: -0.0147 - lr: 0.0025\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2777 - val_loss: 8.4795e-04 - val_coeff_determination: -0.0166 - lr: 0.0025\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2490 - val_loss: 8.4857e-04 - val_coeff_determination: -0.0174 - lr: 0.0025\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2528 - val_loss: 8.5047e-04 - val_coeff_determination: -0.0197 - lr: 0.0025\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3087 - val_loss: 8.4914e-04 - val_coeff_determination: -0.0182 - lr: 0.0025\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.2627 - val_loss: 8.4545e-04 - val_coeff_determination: -0.0139 - lr: 0.0025\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0013 - coeff_determination: -0.3036 - val_loss: 8.5119e-04 - val_coeff_determination: -0.0207 - lr: 0.0025\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0013 - coeff_determination: -0.2974 - val_loss: 8.5356e-04 - val_coeff_determination: -0.0235 - lr: 0.0025\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2838 - val_loss: 8.4884e-04 - val_coeff_determination: -0.0179 - lr: 0.0025\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3072 - val_loss: 8.4244e-04 - val_coeff_determination: -0.0104 - lr: 0.0025\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2490 - val_loss: 8.4431e-04 - val_coeff_determination: -0.0127 - lr: 0.0025\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2566 - val_loss: 8.5155e-04 - val_coeff_determination: -0.0213 - lr: 0.0025\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.2903 - val_loss: 8.4586e-04 - val_coeff_determination: -0.0146 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1805 - val_loss: 8.4404e-04 - val_coeff_determination: -0.0125 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2349 - val_loss: 8.4482e-04 - val_coeff_determination: -0.0135 - lr: 0.0025\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2216 - val_loss: 8.5056e-04 - val_coeff_determination: -0.0203 - lr: 0.0025\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2185 - val_loss: 8.4811e-04 - val_coeff_determination: -0.0174 - lr: 0.0025\n",
            "Epoch 76/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.2038\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.2849 - val_loss: 8.4504e-04 - val_coeff_determination: -0.0138 - lr: 0.0025\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2273 - val_loss: 8.4549e-04 - val_coeff_determination: -0.0143 - lr: 0.0012\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2063 - val_loss: 8.4650e-04 - val_coeff_determination: -0.0155 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1775 - val_loss: 8.4644e-04 - val_coeff_determination: -0.0155 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1752 - val_loss: 8.4705e-04 - val_coeff_determination: -0.0163 - lr: 0.0012\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2136 - val_loss: 8.4534e-04 - val_coeff_determination: -0.0142 - lr: 0.0012\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2006 - val_loss: 8.4560e-04 - val_coeff_determination: -0.0146 - lr: 0.0012\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2141 - val_loss: 8.4689e-04 - val_coeff_determination: -0.0161 - lr: 0.0012\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1811 - val_loss: 8.4614e-04 - val_coeff_determination: -0.0152 - lr: 0.0012\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1926 - val_loss: 8.4881e-04 - val_coeff_determination: -0.0184 - lr: 0.0012\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2223 - val_loss: 8.4791e-04 - val_coeff_determination: -0.0174 - lr: 0.0012\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1647 - val_loss: 8.4284e-04 - val_coeff_determination: -0.0114 - lr: 0.0012\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2173 - val_loss: 8.4468e-04 - val_coeff_determination: -0.0136 - lr: 0.0012\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.1688 - val_loss: 8.4347e-04 - val_coeff_determination: -0.0122 - lr: 0.0012\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1504 - val_loss: 8.4444e-04 - val_coeff_determination: -0.0134 - lr: 0.0012\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2163 - val_loss: 8.4364e-04 - val_coeff_determination: -0.0124 - lr: 0.0012\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1659 - val_loss: 8.4540e-04 - val_coeff_determination: -0.0145 - lr: 0.0012\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1555 - val_loss: 8.4528e-04 - val_coeff_determination: -0.0144 - lr: 0.0012\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2314 - val_loss: 8.4563e-04 - val_coeff_determination: -0.0148 - lr: 0.0012\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2008 - val_loss: 8.4563e-04 - val_coeff_determination: -0.0148 - lr: 0.0012\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1753 - val_loss: 8.4658e-04 - val_coeff_determination: -0.0160 - lr: 0.0012\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1601 - val_loss: 8.4551e-04 - val_coeff_determination: -0.0147 - lr: 0.0012\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1674 - val_loss: 8.4635e-04 - val_coeff_determination: -0.0157 - lr: 0.0012\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1486 - val_loss: 8.4532e-04 - val_coeff_determination: -0.0145 - lr: 0.0012\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1808 - val_loss: 8.4530e-04 - val_coeff_determination: -0.0145 - lr: 0.0012\n",
            "Epoch 101/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.1454\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1896 - val_loss: 8.4251e-04 - val_coeff_determination: -0.0112 - lr: 0.0012\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.2208 - val_loss: 8.4427e-04 - val_coeff_determination: -0.0133 - lr: 6.2500e-04\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1549 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0120 - lr: 6.2500e-04\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1378 - val_loss: 8.4391e-04 - val_coeff_determination: -0.0129 - lr: 6.2500e-04\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2006 - val_loss: 8.4347e-04 - val_coeff_determination: -0.0124 - lr: 6.2500e-04\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2349 - val_loss: 8.4456e-04 - val_coeff_determination: -0.0137 - lr: 6.2500e-04\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1648 - val_loss: 8.4445e-04 - val_coeff_determination: -0.0136 - lr: 6.2500e-04\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1730 - val_loss: 8.4521e-04 - val_coeff_determination: -0.0145 - lr: 6.2500e-04\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1769 - val_loss: 8.4726e-04 - val_coeff_determination: -0.0170 - lr: 6.2500e-04\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1301 - val_loss: 8.4650e-04 - val_coeff_determination: -0.0161 - lr: 6.2500e-04\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1762 - val_loss: 8.4560e-04 - val_coeff_determination: -0.0150 - lr: 6.2500e-04\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1878 - val_loss: 8.4396e-04 - val_coeff_determination: -0.0130 - lr: 6.2500e-04\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1969 - val_loss: 8.4383e-04 - val_coeff_determination: -0.0129 - lr: 6.2500e-04\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1054 - val_loss: 8.4203e-04 - val_coeff_determination: -0.0107 - lr: 6.2500e-04\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1463 - val_loss: 8.4234e-04 - val_coeff_determination: -0.0111 - lr: 6.2500e-04\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - coeff_determination: -0.1325 - val_loss: 8.4205e-04 - val_coeff_determination: -0.0108 - lr: 6.2500e-04\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1553 - val_loss: 8.4237e-04 - val_coeff_determination: -0.0112 - lr: 6.2500e-04\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1911 - val_loss: 8.4384e-04 - val_coeff_determination: -0.0129 - lr: 6.2500e-04\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1523 - val_loss: 8.4393e-04 - val_coeff_determination: -0.0131 - lr: 6.2500e-04\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1578 - val_loss: 8.4386e-04 - val_coeff_determination: -0.0130 - lr: 6.2500e-04\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1676 - val_loss: 8.4302e-04 - val_coeff_determination: -0.0120 - lr: 6.2500e-04\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1465 - val_loss: 8.4441e-04 - val_coeff_determination: -0.0137 - lr: 6.2500e-04\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2062 - val_loss: 8.4541e-04 - val_coeff_determination: -0.0149 - lr: 6.2500e-04\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1412 - val_loss: 8.4487e-04 - val_coeff_determination: -0.0143 - lr: 6.2500e-04\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1208 - val_loss: 8.4548e-04 - val_coeff_determination: -0.0150 - lr: 6.2500e-04\n",
            "Epoch 126/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: 0.0700\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1473 - val_loss: 8.4419e-04 - val_coeff_determination: -0.0135 - lr: 6.2500e-04\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1415 - val_loss: 8.4362e-04 - val_coeff_determination: -0.0128 - lr: 3.1250e-04\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1381 - val_loss: 8.4348e-04 - val_coeff_determination: -0.0126 - lr: 3.1250e-04\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1574 - val_loss: 8.4373e-04 - val_coeff_determination: -0.0129 - lr: 3.1250e-04\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1429 - val_loss: 8.4424e-04 - val_coeff_determination: -0.0136 - lr: 3.1250e-04\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1277 - val_loss: 8.4419e-04 - val_coeff_determination: -0.0135 - lr: 3.1250e-04\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1557 - val_loss: 8.4404e-04 - val_coeff_determination: -0.0133 - lr: 3.1250e-04\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1189 - val_loss: 8.4376e-04 - val_coeff_determination: -0.0130 - lr: 3.1250e-04\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1425 - val_loss: 8.4341e-04 - val_coeff_determination: -0.0126 - lr: 3.1250e-04\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1521 - val_loss: 8.4360e-04 - val_coeff_determination: -0.0128 - lr: 3.1250e-04\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1584 - val_loss: 8.4266e-04 - val_coeff_determination: -0.0117 - lr: 3.1250e-04\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1725 - val_loss: 8.4238e-04 - val_coeff_determination: -0.0114 - lr: 3.1250e-04\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1187 - val_loss: 8.4336e-04 - val_coeff_determination: -0.0125 - lr: 3.1250e-04\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1692 - val_loss: 8.4400e-04 - val_coeff_determination: -0.0133 - lr: 3.1250e-04\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1109 - val_loss: 8.4338e-04 - val_coeff_determination: -0.0126 - lr: 3.1250e-04\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1466 - val_loss: 8.4288e-04 - val_coeff_determination: -0.0120 - lr: 3.1250e-04\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1786 - val_loss: 8.4309e-04 - val_coeff_determination: -0.0122 - lr: 3.1250e-04\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1964 - val_loss: 8.4320e-04 - val_coeff_determination: -0.0124 - lr: 3.1250e-04\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1963 - val_loss: 8.4339e-04 - val_coeff_determination: -0.0126 - lr: 3.1250e-04\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1684 - val_loss: 8.4320e-04 - val_coeff_determination: -0.0124 - lr: 3.1250e-04\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1563 - val_loss: 8.4338e-04 - val_coeff_determination: -0.0126 - lr: 3.1250e-04\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1101 - val_loss: 8.4268e-04 - val_coeff_determination: -0.0118 - lr: 3.1250e-04\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1648 - val_loss: 8.4378e-04 - val_coeff_determination: -0.0131 - lr: 3.1250e-04\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1207 - val_loss: 8.4302e-04 - val_coeff_determination: -0.0122 - lr: 3.1250e-04\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1128 - val_loss: 8.4249e-04 - val_coeff_determination: -0.0116 - lr: 3.1250e-04\n",
            "Epoch 151/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.2405\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1697 - val_loss: 8.4281e-04 - val_coeff_determination: -0.0119 - lr: 3.1250e-04\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1282 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0126 - lr: 1.5625e-04\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - coeff_determination: -0.1356 - val_loss: 8.4359e-04 - val_coeff_determination: -0.0129 - lr: 1.5625e-04\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1818 - val_loss: 8.4359e-04 - val_coeff_determination: -0.0129 - lr: 1.5625e-04\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0754 - val_loss: 8.4289e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1467 - val_loss: 8.4293e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1278 - val_loss: 8.4338e-04 - val_coeff_determination: -0.0127 - lr: 1.5625e-04\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1517 - val_loss: 8.4366e-04 - val_coeff_determination: -0.0130 - lr: 1.5625e-04\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1611 - val_loss: 8.4356e-04 - val_coeff_determination: -0.0129 - lr: 1.5625e-04\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1543 - val_loss: 8.4360e-04 - val_coeff_determination: -0.0129 - lr: 1.5625e-04\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1566 - val_loss: 8.4293e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1207 - val_loss: 8.4286e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1264 - val_loss: 8.4291e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1413 - val_loss: 8.4275e-04 - val_coeff_determination: -0.0119 - lr: 1.5625e-04\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1247 - val_loss: 8.4252e-04 - val_coeff_determination: -0.0116 - lr: 1.5625e-04\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1368 - val_loss: 8.4257e-04 - val_coeff_determination: -0.0117 - lr: 1.5625e-04\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.2032 - val_loss: 8.4254e-04 - val_coeff_determination: -0.0117 - lr: 1.5625e-04\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1289 - val_loss: 8.4231e-04 - val_coeff_determination: -0.0114 - lr: 1.5625e-04\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1521 - val_loss: 8.4293e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1310 - val_loss: 8.4279e-04 - val_coeff_determination: -0.0120 - lr: 1.5625e-04\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1356 - val_loss: 8.4274e-04 - val_coeff_determination: -0.0119 - lr: 1.5625e-04\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1420 - val_loss: 8.4286e-04 - val_coeff_determination: -0.0121 - lr: 1.5625e-04\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1108 - val_loss: 8.4274e-04 - val_coeff_determination: -0.0119 - lr: 1.5625e-04\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1270 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0125 - lr: 1.5625e-04\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1106 - val_loss: 8.4322e-04 - val_coeff_determination: -0.0125 - lr: 1.5625e-04\n",
            "Epoch 176/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0982\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.0950 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0125 - lr: 1.5625e-04\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1687 - val_loss: 8.4376e-04 - val_coeff_determination: -0.0132 - lr: 7.8125e-05\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1438 - val_loss: 8.4359e-04 - val_coeff_determination: -0.0130 - lr: 7.8125e-05\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1408 - val_loss: 8.4300e-04 - val_coeff_determination: -0.0123 - lr: 7.8125e-05\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1124 - val_loss: 8.4293e-04 - val_coeff_determination: -0.0122 - lr: 7.8125e-05\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1659 - val_loss: 8.4242e-04 - val_coeff_determination: -0.0116 - lr: 7.8125e-05\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1379 - val_loss: 8.4257e-04 - val_coeff_determination: -0.0117 - lr: 7.8125e-05\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1447 - val_loss: 8.4267e-04 - val_coeff_determination: -0.0119 - lr: 7.8125e-05\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0011 - coeff_determination: -0.1084 - val_loss: 8.4290e-04 - val_coeff_determination: -0.0121 - lr: 7.8125e-05\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1779 - val_loss: 8.4298e-04 - val_coeff_determination: -0.0122 - lr: 7.8125e-05\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1573 - val_loss: 8.4312e-04 - val_coeff_determination: -0.0124 - lr: 7.8125e-05\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1530 - val_loss: 8.4325e-04 - val_coeff_determination: -0.0126 - lr: 7.8125e-05\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1512 - val_loss: 8.4352e-04 - val_coeff_determination: -0.0129 - lr: 7.8125e-05\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1396 - val_loss: 8.4343e-04 - val_coeff_determination: -0.0128 - lr: 7.8125e-05\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1382 - val_loss: 8.4342e-04 - val_coeff_determination: -0.0128 - lr: 7.8125e-05\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1387 - val_loss: 8.4323e-04 - val_coeff_determination: -0.0126 - lr: 7.8125e-05\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1173 - val_loss: 8.4352e-04 - val_coeff_determination: -0.0129 - lr: 7.8125e-05\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1891 - val_loss: 8.4349e-04 - val_coeff_determination: -0.0129 - lr: 7.8125e-05\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1579 - val_loss: 8.4381e-04 - val_coeff_determination: -0.0133 - lr: 7.8125e-05\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1482 - val_loss: 8.4386e-04 - val_coeff_determination: -0.0134 - lr: 7.8125e-05\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1208 - val_loss: 8.4374e-04 - val_coeff_determination: -0.0132 - lr: 7.8125e-05\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1527 - val_loss: 8.4383e-04 - val_coeff_determination: -0.0133 - lr: 7.8125e-05\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1483 - val_loss: 8.4378e-04 - val_coeff_determination: -0.0133 - lr: 7.8125e-05\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1464 - val_loss: 8.4342e-04 - val_coeff_determination: -0.0128 - lr: 7.8125e-05\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1121 - val_loss: 8.4300e-04 - val_coeff_determination: -0.0123 - lr: 7.8125e-05\n",
            "Epoch 201/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.1311\n",
            "Epoch 00201: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1257 - val_loss: 8.4292e-04 - val_coeff_determination: -0.0122 - lr: 7.8125e-05\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1240 - val_loss: 8.4308e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0954 - val_loss: 8.4299e-04 - val_coeff_determination: -0.0123 - lr: 3.9062e-05\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1336 - val_loss: 8.4290e-04 - val_coeff_determination: -0.0122 - lr: 3.9062e-05\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1285 - val_loss: 8.4308e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1030 - val_loss: 8.4289e-04 - val_coeff_determination: -0.0122 - lr: 3.9062e-05\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1022 - val_loss: 8.4305e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0999 - val_loss: 8.4298e-04 - val_coeff_determination: -0.0123 - lr: 3.9062e-05\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1588 - val_loss: 8.4297e-04 - val_coeff_determination: -0.0123 - lr: 3.9062e-05\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1265 - val_loss: 8.4290e-04 - val_coeff_determination: -0.0122 - lr: 3.9062e-05\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1320 - val_loss: 8.4288e-04 - val_coeff_determination: -0.0122 - lr: 3.9062e-05\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1225 - val_loss: 8.4292e-04 - val_coeff_determination: -0.0122 - lr: 3.9062e-05\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1376 - val_loss: 8.4303e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1358 - val_loss: 8.4307e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1684 - val_loss: 8.4306e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1536 - val_loss: 8.4293e-04 - val_coeff_determination: -0.0123 - lr: 3.9062e-05\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1466 - val_loss: 8.4309e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1265 - val_loss: 8.4315e-04 - val_coeff_determination: -0.0125 - lr: 3.9062e-05\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1295 - val_loss: 8.4301e-04 - val_coeff_determination: -0.0124 - lr: 3.9062e-05\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1555 - val_loss: 8.4321e-04 - val_coeff_determination: -0.0126 - lr: 3.9062e-05\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1313 - val_loss: 8.4311e-04 - val_coeff_determination: -0.0125 - lr: 3.9062e-05\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0012 - coeff_determination: -0.1696 - val_loss: 8.4338e-04 - val_coeff_determination: -0.0128 - lr: 3.9062e-05\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1328 - val_loss: 8.4339e-04 - val_coeff_determination: -0.0128 - lr: 3.9062e-05\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1606 - val_loss: 8.4329e-04 - val_coeff_determination: -0.0127 - lr: 3.9062e-05\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1299 - val_loss: 8.4330e-04 - val_coeff_determination: -0.0127 - lr: 3.9062e-05\n",
            "Epoch 226/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.2013\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0860 - val_loss: 8.4311e-04 - val_coeff_determination: -0.0125 - lr: 3.9062e-05\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1364 - val_loss: 8.4300e-04 - val_coeff_determination: -0.0124 - lr: 1.9531e-05\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1238 - val_loss: 8.4307e-04 - val_coeff_determination: -0.0124 - lr: 1.9531e-05\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1284 - val_loss: 8.4313e-04 - val_coeff_determination: -0.0125 - lr: 1.9531e-05\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1438 - val_loss: 8.4324e-04 - val_coeff_determination: -0.0127 - lr: 1.9531e-05\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1356 - val_loss: 8.4321e-04 - val_coeff_determination: -0.0126 - lr: 1.9531e-05\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1204 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0128 - lr: 1.9531e-05\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1153 - val_loss: 8.4319e-04 - val_coeff_determination: -0.0126 - lr: 1.9531e-05\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1654 - val_loss: 8.4320e-04 - val_coeff_determination: -0.0126 - lr: 1.9531e-05\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1296 - val_loss: 8.4323e-04 - val_coeff_determination: -0.0126 - lr: 1.9531e-05\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1175 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0126 - lr: 1.9531e-05\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1506 - val_loss: 8.4313e-04 - val_coeff_determination: -0.0125 - lr: 1.9531e-05\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1831 - val_loss: 8.4318e-04 - val_coeff_determination: -0.0126 - lr: 1.9531e-05\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1454 - val_loss: 8.4333e-04 - val_coeff_determination: -0.0128 - lr: 1.9531e-05\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1736 - val_loss: 8.4338e-04 - val_coeff_determination: -0.0128 - lr: 1.9531e-05\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1123 - val_loss: 8.4329e-04 - val_coeff_determination: -0.0127 - lr: 1.9531e-05\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1535 - val_loss: 8.4331e-04 - val_coeff_determination: -0.0127 - lr: 1.9531e-05\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1134 - val_loss: 8.4340e-04 - val_coeff_determination: -0.0129 - lr: 1.9531e-05\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1334 - val_loss: 8.4343e-04 - val_coeff_determination: -0.0129 - lr: 1.9531e-05\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1015 - val_loss: 8.4357e-04 - val_coeff_determination: -0.0131 - lr: 1.9531e-05\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1235 - val_loss: 8.4354e-04 - val_coeff_determination: -0.0130 - lr: 1.9531e-05\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1471 - val_loss: 8.4356e-04 - val_coeff_determination: -0.0131 - lr: 1.9531e-05\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1462 - val_loss: 8.4353e-04 - val_coeff_determination: -0.0130 - lr: 1.9531e-05\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1407 - val_loss: 8.4351e-04 - val_coeff_determination: -0.0130 - lr: 1.9531e-05\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1203 - val_loss: 8.4342e-04 - val_coeff_determination: -0.0129 - lr: 1.9531e-05\n",
            "Epoch 251/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.8790e-04 - coeff_determination: -0.3233\n",
            "Epoch 00251: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1161 - val_loss: 8.4335e-04 - val_coeff_determination: -0.0128 - lr: 1.9531e-05\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1287 - val_loss: 8.4334e-04 - val_coeff_determination: -0.0128 - lr: 9.7656e-06\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1796 - val_loss: 8.4326e-04 - val_coeff_determination: -0.0127 - lr: 9.7656e-06\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1106 - val_loss: 8.4329e-04 - val_coeff_determination: -0.0127 - lr: 9.7656e-06\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.1486 - val_loss: 8.4320e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1583 - val_loss: 8.4320e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1827 - val_loss: 8.4321e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1159 - val_loss: 8.4318e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1196 - val_loss: 8.4319e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1655 - val_loss: 8.4323e-04 - val_coeff_determination: -0.0127 - lr: 9.7656e-06\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1692 - val_loss: 8.4318e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1613 - val_loss: 8.4315e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1514 - val_loss: 8.4326e-04 - val_coeff_determination: -0.0127 - lr: 9.7656e-06\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1149 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1177 - val_loss: 8.4318e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1255 - val_loss: 8.4316e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1670 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1154 - val_loss: 8.4314e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1297 - val_loss: 8.4326e-04 - val_coeff_determination: -0.0127 - lr: 9.7656e-06\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1294 - val_loss: 8.4318e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1717 - val_loss: 8.4311e-04 - val_coeff_determination: -0.0125 - lr: 9.7656e-06\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1380 - val_loss: 8.4306e-04 - val_coeff_determination: -0.0125 - lr: 9.7656e-06\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1232 - val_loss: 8.4310e-04 - val_coeff_determination: -0.0125 - lr: 9.7656e-06\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0999 - val_loss: 8.4313e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1332 - val_loss: 8.4316e-04 - val_coeff_determination: -0.0126 - lr: 9.7656e-06\n",
            "Epoch 276/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.6914e-04 - coeff_determination: -0.0918\n",
            "Epoch 00276: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.1270 - val_loss: 8.4312e-04 - val_coeff_determination: -0.0125 - lr: 9.7656e-06\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0929 - val_loss: 8.4313e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1257 - val_loss: 8.4311e-04 - val_coeff_determination: -0.0125 - lr: 4.8828e-06\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1749 - val_loss: 8.4313e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1201 - val_loss: 8.4316e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1326 - val_loss: 8.4313e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1572 - val_loss: 8.4316e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1164 - val_loss: 8.4311e-04 - val_coeff_determination: -0.0125 - lr: 4.8828e-06\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1374 - val_loss: 8.4312e-04 - val_coeff_determination: -0.0125 - lr: 4.8828e-06\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1331 - val_loss: 8.4308e-04 - val_coeff_determination: -0.0125 - lr: 4.8828e-06\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0011 - coeff_determination: -0.1531 - val_loss: 8.4309e-04 - val_coeff_determination: -0.0125 - lr: 4.8828e-06\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1147 - val_loss: 8.4314e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1511 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1358 - val_loss: 8.4311e-04 - val_coeff_determination: -0.0125 - lr: 4.8828e-06\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1323 - val_loss: 8.4314e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1188 - val_loss: 8.4321e-04 - val_coeff_determination: -0.0127 - lr: 4.8828e-06\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1080 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1171 - val_loss: 8.4317e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1327 - val_loss: 8.4319e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1625 - val_loss: 8.4324e-04 - val_coeff_determination: -0.0127 - lr: 4.8828e-06\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.1490 - val_loss: 8.4326e-04 - val_coeff_determination: -0.0127 - lr: 4.8828e-06\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1045 - val_loss: 8.4329e-04 - val_coeff_determination: -0.0128 - lr: 4.8828e-06\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1083 - val_loss: 8.4324e-04 - val_coeff_determination: -0.0127 - lr: 4.8828e-06\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1247 - val_loss: 8.4319e-04 - val_coeff_determination: -0.0126 - lr: 4.8828e-06\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1191 - val_loss: 8.4323e-04 - val_coeff_determination: -0.0127 - lr: 4.8828e-06\n",
            "Epoch 301/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0206\n",
            "Epoch 00301: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1147 - val_loss: 8.4329e-04 - val_coeff_determination: -0.0128 - lr: 4.8828e-06\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1549 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1379 - val_loss: 8.4331e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1321 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.1644 - val_loss: 8.4335e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.1410 - val_loss: 8.4335e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1326 - val_loss: 8.4334e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1263 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1205 - val_loss: 8.4331e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1506 - val_loss: 8.4331e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.0703 - val_loss: 8.4331e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1381 - val_loss: 8.4330e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1436 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.1815 - val_loss: 8.4332e-04 - val_coeff_determination: -0.0128 - lr: 2.4414e-06\n",
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6421 - coeff_determination: -669.1234 - val_loss: 0.0031 - val_coeff_determination: -6.7077 - lr: 0.0100\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0510 - coeff_determination: -54.6259 - val_loss: 0.0207 - val_coeff_determination: -58.2066 - lr: 0.0100\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0257 - coeff_determination: -26.7201 - val_loss: 0.0014 - val_coeff_determination: -2.6956 - lr: 0.0100\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0183 - coeff_determination: -19.0880 - val_loss: 0.0010 - val_coeff_determination: -1.6260 - lr: 0.0100\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0147 - coeff_determination: -15.4858 - val_loss: 6.3864e-04 - val_coeff_determination: -0.2580 - lr: 0.0100\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0131 - coeff_determination: -13.3639 - val_loss: 5.7945e-04 - val_coeff_determination: -0.1913 - lr: 0.0100\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0114 - coeff_determination: -11.6195 - val_loss: 5.8183e-04 - val_coeff_determination: -0.3060 - lr: 0.0100\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0100 - coeff_determination: -9.6856 - val_loss: 5.5404e-04 - val_coeff_determination: -0.1725 - lr: 0.0100\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0088 - coeff_determination: -8.7045 - val_loss: 5.4477e-04 - val_coeff_determination: -0.1360 - lr: 0.0100\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0086 - coeff_determination: -8.2709 - val_loss: 5.3989e-04 - val_coeff_determination: -0.1254 - lr: 0.0100\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0069 - coeff_determination: -6.6653 - val_loss: 5.4281e-04 - val_coeff_determination: -0.1987 - lr: 0.0100\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0067 - coeff_determination: -6.2908 - val_loss: 5.3304e-04 - val_coeff_determination: -0.1546 - lr: 0.0100\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0059 - coeff_determination: -5.5199 - val_loss: 5.5457e-04 - val_coeff_determination: -0.1316 - lr: 0.0100\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0057 - coeff_determination: -5.1871 - val_loss: 5.3108e-04 - val_coeff_determination: -0.1104 - lr: 0.0100\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0053 - coeff_determination: -4.6486 - val_loss: 5.6616e-04 - val_coeff_determination: -0.1460 - lr: 0.0100\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - coeff_determination: -4.4675 - val_loss: 5.4534e-04 - val_coeff_determination: -0.1137 - lr: 0.0100\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0048 - coeff_determination: -4.1828 - val_loss: 5.2567e-04 - val_coeff_determination: -0.0954 - lr: 0.0100\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0043 - coeff_determination: -3.6415 - val_loss: 5.2502e-04 - val_coeff_determination: -0.0924 - lr: 0.0100\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0041 - coeff_determination: -3.3553 - val_loss: 5.2496e-04 - val_coeff_determination: -0.0892 - lr: 0.0100\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0038 - coeff_determination: -3.0874 - val_loss: 5.3222e-04 - val_coeff_determination: -0.0936 - lr: 0.0100\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - coeff_determination: -3.1630 - val_loss: 5.3044e-04 - val_coeff_determination: -0.0909 - lr: 0.0100\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - coeff_determination: -3.0820 - val_loss: 5.2099e-04 - val_coeff_determination: -0.0804 - lr: 0.0100\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0038 - coeff_determination: -3.1726 - val_loss: 5.1144e-04 - val_coeff_determination: -0.0830 - lr: 0.0100\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - coeff_determination: -2.6380 - val_loss: 5.2327e-04 - val_coeff_determination: -0.0796 - lr: 0.0100\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0033 - coeff_determination: -2.5471 - val_loss: 5.3261e-04 - val_coeff_determination: -0.0893 - lr: 0.0100\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -2.1945 - val_loss: 5.1036e-04 - val_coeff_determination: -0.0759 - lr: 0.0100\n",
            "Epoch 27/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0035 - coeff_determination: -2.8187\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -2.2773 - val_loss: 5.1755e-04 - val_coeff_determination: -0.0737 - lr: 0.0100\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0034 - coeff_determination: -2.7042 - val_loss: 5.2049e-04 - val_coeff_determination: -0.0760 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0030 - coeff_determination: -2.2284 - val_loss: 5.2550e-04 - val_coeff_determination: -0.0806 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0028 - coeff_determination: -2.0928 - val_loss: 5.2005e-04 - val_coeff_determination: -0.0756 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0031 - coeff_determination: -2.3186 - val_loss: 5.1456e-04 - val_coeff_determination: -0.0722 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0028 - coeff_determination: -1.9341 - val_loss: 5.1176e-04 - val_coeff_determination: -0.0706 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0029 - coeff_determination: -2.1529 - val_loss: 5.2239e-04 - val_coeff_determination: -0.0765 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - coeff_determination: -1.9889 - val_loss: 5.1218e-04 - val_coeff_determination: -0.0688 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - coeff_determination: -1.9397 - val_loss: 5.0533e-04 - val_coeff_determination: -0.0754 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0025 - coeff_determination: -1.6466 - val_loss: 5.0667e-04 - val_coeff_determination: -0.0722 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0026 - coeff_determination: -1.7482 - val_loss: 5.0698e-04 - val_coeff_determination: -0.0718 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - coeff_determination: -1.8979 - val_loss: 5.0790e-04 - val_coeff_determination: -0.0707 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0027 - coeff_determination: -1.9637 - val_loss: 5.1718e-04 - val_coeff_determination: -0.0730 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0026 - coeff_determination: -1.7480 - val_loss: 5.1526e-04 - val_coeff_determination: -0.0710 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.6322 - val_loss: 5.0748e-04 - val_coeff_determination: -0.0706 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.6134 - val_loss: 5.0552e-04 - val_coeff_determination: -0.0728 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.5760 - val_loss: 5.0864e-04 - val_coeff_determination: -0.0685 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.3274 - val_loss: 5.0342e-04 - val_coeff_determination: -0.0786 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0023 - coeff_determination: -1.4671 - val_loss: 5.0254e-04 - val_coeff_determination: -0.0924 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - coeff_determination: -1.4131 - val_loss: 5.0305e-04 - val_coeff_determination: -0.0784 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.3469 - val_loss: 5.0421e-04 - val_coeff_determination: -0.0723 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - coeff_determination: -1.4389 - val_loss: 5.0710e-04 - val_coeff_determination: -0.0669 - lr: 0.0050\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.2613 - val_loss: 5.0743e-04 - val_coeff_determination: -0.0654 - lr: 0.0050\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0021 - coeff_determination: -1.2736 - val_loss: 5.0301e-04 - val_coeff_determination: -0.0693 - lr: 0.0050\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0022 - coeff_determination: -1.3701 - val_loss: 5.0412e-04 - val_coeff_determination: -0.0649 - lr: 0.0050\n",
            "Epoch 52/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0028 - coeff_determination: -1.3780\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.2133 - val_loss: 5.0612e-04 - val_coeff_determination: -0.0619 - lr: 0.0050\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0021 - coeff_determination: -1.2242 - val_loss: 5.0250e-04 - val_coeff_determination: -0.0671 - lr: 0.0025\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.1632 - val_loss: 5.0284e-04 - val_coeff_determination: -0.0660 - lr: 0.0025\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.1546 - val_loss: 5.0211e-04 - val_coeff_determination: -0.0686 - lr: 0.0025\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.1729 - val_loss: 5.0231e-04 - val_coeff_determination: -0.0676 - lr: 0.0025\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.1681 - val_loss: 5.0105e-04 - val_coeff_determination: -0.0758 - lr: 0.0025\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.1186 - val_loss: 5.0129e-04 - val_coeff_determination: -0.0710 - lr: 0.0025\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -1.0329 - val_loss: 5.0230e-04 - val_coeff_determination: -0.0654 - lr: 0.0025\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0019 - coeff_determination: -1.0233 - val_loss: 5.0199e-04 - val_coeff_determination: -0.0660 - lr: 0.0025\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0020 - coeff_determination: -1.0821 - val_loss: 5.0251e-04 - val_coeff_determination: -0.0643 - lr: 0.0025\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -1.0236 - val_loss: 5.0126e-04 - val_coeff_determination: -0.0697 - lr: 0.0025\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -1.0336 - val_loss: 5.0060e-04 - val_coeff_determination: -0.0819 - lr: 0.0025\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -1.0715 - val_loss: 5.0134e-04 - val_coeff_determination: -0.0666 - lr: 0.0025\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -1.1277 - val_loss: 5.0166e-04 - val_coeff_determination: -0.0638 - lr: 0.0025\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.9418 - val_loss: 5.0342e-04 - val_coeff_determination: -0.0594 - lr: 0.0025\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -0.9501 - val_loss: 5.0122e-04 - val_coeff_determination: -0.0653 - lr: 0.0025\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.9619 - val_loss: 5.0112e-04 - val_coeff_determination: -0.0648 - lr: 0.0025\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.9272 - val_loss: 5.0187e-04 - val_coeff_determination: -0.0614 - lr: 0.0025\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - coeff_determination: -0.9234 - val_loss: 5.0119e-04 - val_coeff_determination: -0.0635 - lr: 0.0025\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0019 - coeff_determination: -1.0642 - val_loss: 5.0054e-04 - val_coeff_determination: -0.0679 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.9444 - val_loss: 5.0019e-04 - val_coeff_determination: -0.0780 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8695 - val_loss: 5.0027e-04 - val_coeff_determination: -0.0797 - lr: 0.0025\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.9819 - val_loss: 5.0140e-04 - val_coeff_determination: -0.0956 - lr: 0.0025\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7432 - val_loss: 5.0019e-04 - val_coeff_determination: -0.0724 - lr: 0.0025\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8079 - val_loss: 5.0027e-04 - val_coeff_determination: -0.0809 - lr: 0.0025\n",
            "Epoch 77/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0027 - coeff_determination: -1.2452\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8235 - val_loss: 5.0021e-04 - val_coeff_determination: -0.0799 - lr: 0.0025\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7695 - val_loss: 5.0014e-04 - val_coeff_determination: -0.0765 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8450 - val_loss: 5.0027e-04 - val_coeff_determination: -0.0791 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0018 - coeff_determination: -0.9314 - val_loss: 5.0026e-04 - val_coeff_determination: -0.0688 - lr: 0.0012\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8607 - val_loss: 5.0055e-04 - val_coeff_determination: -0.0643 - lr: 0.0012\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.9642 - val_loss: 5.0024e-04 - val_coeff_determination: -0.0679 - lr: 0.0012\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.9258 - val_loss: 5.0020e-04 - val_coeff_determination: -0.0687 - lr: 0.0012\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8269 - val_loss: 5.0020e-04 - val_coeff_determination: -0.0684 - lr: 0.0012\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.8348 - val_loss: 5.0021e-04 - val_coeff_determination: -0.0690 - lr: 0.0012\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.8390 - val_loss: 5.0025e-04 - val_coeff_determination: -0.0766 - lr: 0.0012\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7190 - val_loss: 5.0088e-04 - val_coeff_determination: -0.0865 - lr: 0.0012\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8128 - val_loss: 5.0062e-04 - val_coeff_determination: -0.0825 - lr: 0.0012\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6989 - val_loss: 5.0064e-04 - val_coeff_determination: -0.0830 - lr: 0.0012\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - coeff_determination: -0.7779 - val_loss: 5.0027e-04 - val_coeff_determination: -0.0762 - lr: 0.0012\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.8988 - val_loss: 5.0036e-04 - val_coeff_determination: -0.0777 - lr: 0.0012\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.8003 - val_loss: 5.0020e-04 - val_coeff_determination: -0.0718 - lr: 0.0012\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7909 - val_loss: 5.0021e-04 - val_coeff_determination: -0.0674 - lr: 0.0012\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7416 - val_loss: 5.0052e-04 - val_coeff_determination: -0.0618 - lr: 0.0012\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0018 - coeff_determination: -0.8842 - val_loss: 5.0096e-04 - val_coeff_determination: -0.0586 - lr: 0.0012\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6399 - val_loss: 5.0029e-04 - val_coeff_determination: -0.0635 - lr: 0.0012\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6940 - val_loss: 5.0025e-04 - val_coeff_determination: -0.0761 - lr: 0.0012\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7539 - val_loss: 5.0008e-04 - val_coeff_determination: -0.0727 - lr: 0.0012\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0016 - coeff_determination: -0.6844 - val_loss: 5.0009e-04 - val_coeff_determination: -0.0649 - lr: 0.0012\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6978 - val_loss: 5.0021e-04 - val_coeff_determination: -0.0629 - lr: 0.0012\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7753 - val_loss: 5.0007e-04 - val_coeff_determination: -0.0654 - lr: 0.0012\n",
            "Epoch 102/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.5319\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0017 - coeff_determination: -0.7818 - val_loss: 5.0009e-04 - val_coeff_determination: -0.0640 - lr: 0.0012\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6625 - val_loss: 5.0011e-04 - val_coeff_determination: -0.0636 - lr: 6.2500e-04\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7411 - val_loss: 5.0009e-04 - val_coeff_determination: -0.0639 - lr: 6.2500e-04\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7611 - val_loss: 5.0018e-04 - val_coeff_determination: -0.0622 - lr: 6.2500e-04\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5628 - val_loss: 5.0011e-04 - val_coeff_determination: -0.0633 - lr: 6.2500e-04\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7172 - val_loss: 5.0014e-04 - val_coeff_determination: -0.0626 - lr: 6.2500e-04\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.6421 - val_loss: 5.0000e-04 - val_coeff_determination: -0.0665 - lr: 6.2500e-04\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5451 - val_loss: 4.9998e-04 - val_coeff_determination: -0.0679 - lr: 6.2500e-04\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7268 - val_loss: 4.9995e-04 - val_coeff_determination: -0.0670 - lr: 6.2500e-04\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7371 - val_loss: 4.9997e-04 - val_coeff_determination: -0.0693 - lr: 6.2500e-04\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6074 - val_loss: 4.9997e-04 - val_coeff_determination: -0.0643 - lr: 6.2500e-04\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6322 - val_loss: 4.9992e-04 - val_coeff_determination: -0.0664 - lr: 6.2500e-04\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6849 - val_loss: 4.9992e-04 - val_coeff_determination: -0.0686 - lr: 6.2500e-04\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6685 - val_loss: 4.9988e-04 - val_coeff_determination: -0.0674 - lr: 6.2500e-04\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6948 - val_loss: 4.9986e-04 - val_coeff_determination: -0.0673 - lr: 6.2500e-04\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6148 - val_loss: 4.9987e-04 - val_coeff_determination: -0.0644 - lr: 6.2500e-04\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5951 - val_loss: 4.9983e-04 - val_coeff_determination: -0.0666 - lr: 6.2500e-04\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6872 - val_loss: 4.9981e-04 - val_coeff_determination: -0.0668 - lr: 6.2500e-04\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6216 - val_loss: 4.9986e-04 - val_coeff_determination: -0.0701 - lr: 6.2500e-04\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4920 - val_loss: 4.9985e-04 - val_coeff_determination: -0.0700 - lr: 6.2500e-04\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7092 - val_loss: 4.9990e-04 - val_coeff_determination: -0.0718 - lr: 6.2500e-04\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6563 - val_loss: 4.9975e-04 - val_coeff_determination: -0.0677 - lr: 6.2500e-04\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5651 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0698 - lr: 6.2500e-04\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5085 - val_loss: 5.0034e-04 - val_coeff_determination: -0.0789 - lr: 6.2500e-04\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5829 - val_loss: 5.0030e-04 - val_coeff_determination: -0.0784 - lr: 6.2500e-04\n",
            "Epoch 127/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - coeff_determination: -0.7434\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.6573 - val_loss: 4.9990e-04 - val_coeff_determination: -0.0723 - lr: 6.2500e-04\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5878 - val_loss: 4.9977e-04 - val_coeff_determination: -0.0695 - lr: 3.1250e-04\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5911 - val_loss: 4.9974e-04 - val_coeff_determination: -0.0689 - lr: 3.1250e-04\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5856 - val_loss: 4.9970e-04 - val_coeff_determination: -0.0676 - lr: 3.1250e-04\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6846 - val_loss: 4.9968e-04 - val_coeff_determination: -0.0664 - lr: 3.1250e-04\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5428 - val_loss: 4.9972e-04 - val_coeff_determination: -0.0680 - lr: 3.1250e-04\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5447 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0703 - lr: 3.1250e-04\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5907 - val_loss: 4.9973e-04 - val_coeff_determination: -0.0692 - lr: 3.1250e-04\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6880 - val_loss: 4.9966e-04 - val_coeff_determination: -0.0676 - lr: 3.1250e-04\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.6020 - val_loss: 4.9963e-04 - val_coeff_determination: -0.0668 - lr: 3.1250e-04\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5496 - val_loss: 4.9961e-04 - val_coeff_determination: -0.0658 - lr: 3.1250e-04\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.7384 - val_loss: 4.9964e-04 - val_coeff_determination: -0.0679 - lr: 3.1250e-04\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5424 - val_loss: 4.9965e-04 - val_coeff_determination: -0.0685 - lr: 3.1250e-04\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5045 - val_loss: 4.9969e-04 - val_coeff_determination: -0.0695 - lr: 3.1250e-04\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5349 - val_loss: 4.9971e-04 - val_coeff_determination: -0.0703 - lr: 3.1250e-04\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6107 - val_loss: 4.9972e-04 - val_coeff_determination: -0.0710 - lr: 3.1250e-04\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5625 - val_loss: 4.9961e-04 - val_coeff_determination: -0.0690 - lr: 3.1250e-04\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5926 - val_loss: 4.9961e-04 - val_coeff_determination: -0.0691 - lr: 3.1250e-04\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5711 - val_loss: 4.9962e-04 - val_coeff_determination: -0.0693 - lr: 3.1250e-04\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5429 - val_loss: 4.9959e-04 - val_coeff_determination: -0.0693 - lr: 3.1250e-04\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.7696 - val_loss: 4.9969e-04 - val_coeff_determination: -0.0717 - lr: 3.1250e-04\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5202 - val_loss: 4.9967e-04 - val_coeff_determination: -0.0714 - lr: 3.1250e-04\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4856 - val_loss: 4.9967e-04 - val_coeff_determination: -0.0714 - lr: 3.1250e-04\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5498 - val_loss: 4.9977e-04 - val_coeff_determination: -0.0732 - lr: 3.1250e-04\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4078 - val_loss: 4.9982e-04 - val_coeff_determination: -0.0741 - lr: 3.1250e-04\n",
            "Epoch 152/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 9.6272e-04 - coeff_determination: -0.1128\n",
            "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5387 - val_loss: 4.9969e-04 - val_coeff_determination: -0.0724 - lr: 3.1250e-04\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6386 - val_loss: 4.9966e-04 - val_coeff_determination: -0.0720 - lr: 1.5625e-04\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5907 - val_loss: 4.9956e-04 - val_coeff_determination: -0.0703 - lr: 1.5625e-04\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5794 - val_loss: 4.9965e-04 - val_coeff_determination: -0.0721 - lr: 1.5625e-04\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5601 - val_loss: 4.9957e-04 - val_coeff_determination: -0.0707 - lr: 1.5625e-04\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6024 - val_loss: 4.9952e-04 - val_coeff_determination: -0.0697 - lr: 1.5625e-04\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6255 - val_loss: 4.9954e-04 - val_coeff_determination: -0.0702 - lr: 1.5625e-04\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5596 - val_loss: 4.9961e-04 - val_coeff_determination: -0.0716 - lr: 1.5625e-04\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5492 - val_loss: 4.9970e-04 - val_coeff_determination: -0.0731 - lr: 1.5625e-04\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5823 - val_loss: 4.9970e-04 - val_coeff_determination: -0.0731 - lr: 1.5625e-04\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5728 - val_loss: 4.9969e-04 - val_coeff_determination: -0.0731 - lr: 1.5625e-04\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.6384 - val_loss: 4.9967e-04 - val_coeff_determination: -0.0728 - lr: 1.5625e-04\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4292 - val_loss: 4.9966e-04 - val_coeff_determination: -0.0726 - lr: 1.5625e-04\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5671 - val_loss: 4.9957e-04 - val_coeff_determination: -0.0712 - lr: 1.5625e-04\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5557 - val_loss: 4.9954e-04 - val_coeff_determination: -0.0704 - lr: 1.5625e-04\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5228 - val_loss: 4.9959e-04 - val_coeff_determination: -0.0715 - lr: 1.5625e-04\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5781 - val_loss: 4.9966e-04 - val_coeff_determination: -0.0725 - lr: 1.5625e-04\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5559 - val_loss: 4.9948e-04 - val_coeff_determination: -0.0696 - lr: 1.5625e-04\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5982 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0680 - lr: 1.5625e-04\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5704 - val_loss: 4.9945e-04 - val_coeff_determination: -0.0694 - lr: 1.5625e-04\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5304 - val_loss: 4.9955e-04 - val_coeff_determination: -0.0711 - lr: 1.5625e-04\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6815 - val_loss: 4.9967e-04 - val_coeff_determination: -0.0731 - lr: 1.5625e-04\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5687 - val_loss: 4.9981e-04 - val_coeff_determination: -0.0749 - lr: 1.5625e-04\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5107 - val_loss: 4.9971e-04 - val_coeff_determination: -0.0735 - lr: 1.5625e-04\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5279 - val_loss: 4.9962e-04 - val_coeff_determination: -0.0722 - lr: 1.5625e-04\n",
            "Epoch 177/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.8814\n",
            "Epoch 00177: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6289 - val_loss: 4.9947e-04 - val_coeff_determination: -0.0701 - lr: 1.5625e-04\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4766 - val_loss: 4.9947e-04 - val_coeff_determination: -0.0702 - lr: 7.8125e-05\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5517 - val_loss: 4.9948e-04 - val_coeff_determination: -0.0704 - lr: 7.8125e-05\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4318 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0709 - lr: 7.8125e-05\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5418 - val_loss: 4.9959e-04 - val_coeff_determination: -0.0722 - lr: 7.8125e-05\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4609 - val_loss: 4.9963e-04 - val_coeff_determination: -0.0729 - lr: 7.8125e-05\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5292 - val_loss: 4.9963e-04 - val_coeff_determination: -0.0731 - lr: 7.8125e-05\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5102 - val_loss: 4.9956e-04 - val_coeff_determination: -0.0720 - lr: 7.8125e-05\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5031 - val_loss: 4.9948e-04 - val_coeff_determination: -0.0709 - lr: 7.8125e-05\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6431 - val_loss: 4.9949e-04 - val_coeff_determination: -0.0710 - lr: 7.8125e-05\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5317 - val_loss: 4.9954e-04 - val_coeff_determination: -0.0718 - lr: 7.8125e-05\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5655 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0713 - lr: 7.8125e-05\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4736 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0712 - lr: 7.8125e-05\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5055 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0714 - lr: 7.8125e-05\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.7002 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0714 - lr: 7.8125e-05\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5521 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0714 - lr: 7.8125e-05\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5704 - val_loss: 4.9952e-04 - val_coeff_determination: -0.0718 - lr: 7.8125e-05\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5037 - val_loss: 4.9947e-04 - val_coeff_determination: -0.0711 - lr: 7.8125e-05\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - coeff_determination: -0.5105 - val_loss: 4.9948e-04 - val_coeff_determination: -0.0713 - lr: 7.8125e-05\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4459 - val_loss: 4.9956e-04 - val_coeff_determination: -0.0725 - lr: 7.8125e-05\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5332 - val_loss: 4.9962e-04 - val_coeff_determination: -0.0734 - lr: 7.8125e-05\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4377 - val_loss: 4.9968e-04 - val_coeff_determination: -0.0743 - lr: 7.8125e-05\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - coeff_determination: -0.4979 - val_loss: 4.9975e-04 - val_coeff_determination: -0.0751 - lr: 7.8125e-05\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4344 - val_loss: 4.9980e-04 - val_coeff_determination: -0.0757 - lr: 7.8125e-05\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5193 - val_loss: 4.9980e-04 - val_coeff_determination: -0.0757 - lr: 7.8125e-05\n",
            "Epoch 202/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.7969\n",
            "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5685 - val_loss: 4.9975e-04 - val_coeff_determination: -0.0751 - lr: 7.8125e-05\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5766 - val_loss: 4.9981e-04 - val_coeff_determination: -0.0758 - lr: 3.9062e-05\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - coeff_determination: -0.4617 - val_loss: 4.9982e-04 - val_coeff_determination: -0.0759 - lr: 3.9062e-05\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4983 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0755 - lr: 3.9062e-05\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5270 - val_loss: 4.9977e-04 - val_coeff_determination: -0.0753 - lr: 3.9062e-05\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5245 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0756 - lr: 3.9062e-05\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4646 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0756 - lr: 3.9062e-05\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4614 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0757 - lr: 3.9062e-05\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4846 - val_loss: 4.9978e-04 - val_coeff_determination: -0.0756 - lr: 3.9062e-05\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4976 - val_loss: 4.9980e-04 - val_coeff_determination: -0.0758 - lr: 3.9062e-05\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5406 - val_loss: 4.9979e-04 - val_coeff_determination: -0.0757 - lr: 3.9062e-05\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5036 - val_loss: 4.9976e-04 - val_coeff_determination: -0.0754 - lr: 3.9062e-05\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5741 - val_loss: 4.9973e-04 - val_coeff_determination: -0.0751 - lr: 3.9062e-05\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4890 - val_loss: 4.9977e-04 - val_coeff_determination: -0.0755 - lr: 3.9062e-05\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4744 - val_loss: 4.9984e-04 - val_coeff_determination: -0.0763 - lr: 3.9062e-05\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5004 - val_loss: 4.9987e-04 - val_coeff_determination: -0.0767 - lr: 3.9062e-05\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4823 - val_loss: 4.9984e-04 - val_coeff_determination: -0.0764 - lr: 3.9062e-05\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.7389 - val_loss: 4.9982e-04 - val_coeff_determination: -0.0762 - lr: 3.9062e-05\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4506 - val_loss: 4.9981e-04 - val_coeff_determination: -0.0760 - lr: 3.9062e-05\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - coeff_determination: -0.5673 - val_loss: 4.9978e-04 - val_coeff_determination: -0.0756 - lr: 3.9062e-05\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5258 - val_loss: 4.9976e-04 - val_coeff_determination: -0.0754 - lr: 3.9062e-05\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5413 - val_loss: 4.9972e-04 - val_coeff_determination: -0.0749 - lr: 3.9062e-05\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5441 - val_loss: 4.9964e-04 - val_coeff_determination: -0.0740 - lr: 3.9062e-05\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4815 - val_loss: 4.9959e-04 - val_coeff_determination: -0.0733 - lr: 3.9062e-05\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5561 - val_loss: 4.9957e-04 - val_coeff_determination: -0.0731 - lr: 3.9062e-05\n",
            "Epoch 227/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - coeff_determination: -0.9806\n",
            "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5227 - val_loss: 4.9948e-04 - val_coeff_determination: -0.0719 - lr: 3.9062e-05\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5471 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0722 - lr: 1.9531e-05\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6121 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0722 - lr: 1.9531e-05\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4856 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0722 - lr: 1.9531e-05\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4706 - val_loss: 4.9954e-04 - val_coeff_determination: -0.0727 - lr: 1.9531e-05\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4386 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0722 - lr: 1.9531e-05\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4920 - val_loss: 4.9947e-04 - val_coeff_determination: -0.0717 - lr: 1.9531e-05\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4501 - val_loss: 4.9947e-04 - val_coeff_determination: -0.0717 - lr: 1.9531e-05\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5622 - val_loss: 4.9946e-04 - val_coeff_determination: -0.0716 - lr: 1.9531e-05\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5532 - val_loss: 4.9943e-04 - val_coeff_determination: -0.0713 - lr: 1.9531e-05\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4616 - val_loss: 4.9946e-04 - val_coeff_determination: -0.0717 - lr: 1.9531e-05\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4912 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0722 - lr: 1.9531e-05\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4210 - val_loss: 4.9952e-04 - val_coeff_determination: -0.0726 - lr: 1.9531e-05\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5990 - val_loss: 4.9955e-04 - val_coeff_determination: -0.0730 - lr: 1.9531e-05\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4352 - val_loss: 4.9952e-04 - val_coeff_determination: -0.0726 - lr: 1.9531e-05\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6039 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0725 - lr: 1.9531e-05\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5187 - val_loss: 4.9949e-04 - val_coeff_determination: -0.0722 - lr: 1.9531e-05\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.6574 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0724 - lr: 1.9531e-05\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5668 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0725 - lr: 1.9531e-05\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4822 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0726 - lr: 1.9531e-05\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5193 - val_loss: 4.9955e-04 - val_coeff_determination: -0.0730 - lr: 1.9531e-05\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4669 - val_loss: 4.9957e-04 - val_coeff_determination: -0.0733 - lr: 1.9531e-05\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5856 - val_loss: 4.9953e-04 - val_coeff_determination: -0.0728 - lr: 1.9531e-05\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4996 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0725 - lr: 1.9531e-05\n",
            "Epoch 251/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4286 - val_loss: 4.9953e-04 - val_coeff_determination: -0.0729 - lr: 1.9531e-05\n",
            "Epoch 252/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.4124\n",
            "Epoch 00252: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5333 - val_loss: 4.9952e-04 - val_coeff_determination: -0.0728 - lr: 1.9531e-05\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5153 - val_loss: 4.9949e-04 - val_coeff_determination: -0.0725 - lr: 9.7656e-06\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4218 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0726 - lr: 9.7656e-06\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4860 - val_loss: 4.9951e-04 - val_coeff_determination: -0.0727 - lr: 9.7656e-06\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5922 - val_loss: 4.9950e-04 - val_coeff_determination: -0.0725 - lr: 9.7656e-06\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4692 - val_loss: 4.9949e-04 - val_coeff_determination: -0.0724 - lr: 9.7656e-06\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.7098 - val_loss: 4.9947e-04 - val_coeff_determination: -0.0721 - lr: 9.7656e-06\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5285 - val_loss: 4.9944e-04 - val_coeff_determination: -0.0717 - lr: 9.7656e-06\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5745 - val_loss: 4.9942e-04 - val_coeff_determination: -0.0714 - lr: 9.7656e-06\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4569 - val_loss: 4.9941e-04 - val_coeff_determination: -0.0713 - lr: 9.7656e-06\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5669 - val_loss: 4.9940e-04 - val_coeff_determination: -0.0712 - lr: 9.7656e-06\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5641 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0710 - lr: 9.7656e-06\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5490 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0710 - lr: 9.7656e-06\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4743 - val_loss: 4.9940e-04 - val_coeff_determination: -0.0712 - lr: 9.7656e-06\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5997 - val_loss: 4.9940e-04 - val_coeff_determination: -0.0711 - lr: 9.7656e-06\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5031 - val_loss: 4.9941e-04 - val_coeff_determination: -0.0713 - lr: 9.7656e-06\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4987 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0711 - lr: 9.7656e-06\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4804 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0709 - lr: 9.7656e-06\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5412 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0710 - lr: 9.7656e-06\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.5005 - val_loss: 4.9938e-04 - val_coeff_determination: -0.0708 - lr: 9.7656e-06\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5299 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0707 - lr: 9.7656e-06\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5925 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0707 - lr: 9.7656e-06\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4446 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0705 - lr: 9.7656e-06\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4542 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0705 - lr: 9.7656e-06\n",
            "Epoch 276/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5215 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0704 - lr: 9.7656e-06\n",
            "Epoch 277/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.6672\n",
            "Epoch 00277: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4955 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0705 - lr: 9.7656e-06\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4860 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0704 - lr: 4.8828e-06\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4449 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0705 - lr: 4.8828e-06\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4409 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0705 - lr: 4.8828e-06\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4812 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0708 - lr: 4.8828e-06\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - coeff_determination: -0.4341 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0708 - lr: 4.8828e-06\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0015 - coeff_determination: -0.5776 - val_loss: 4.9938e-04 - val_coeff_determination: -0.0709 - lr: 4.8828e-06\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6474 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0708 - lr: 4.8828e-06\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6613 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0708 - lr: 4.8828e-06\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6954 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0707 - lr: 4.8828e-06\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5470 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0706 - lr: 4.8828e-06\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4572 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0706 - lr: 4.8828e-06\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5090 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0708 - lr: 4.8828e-06\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4831 - val_loss: 4.9938e-04 - val_coeff_determination: -0.0710 - lr: 4.8828e-06\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4756 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0711 - lr: 4.8828e-06\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4938 - val_loss: 4.9941e-04 - val_coeff_determination: -0.0714 - lr: 4.8828e-06\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5235 - val_loss: 4.9941e-04 - val_coeff_determination: -0.0715 - lr: 4.8828e-06\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4925 - val_loss: 4.9941e-04 - val_coeff_determination: -0.0714 - lr: 4.8828e-06\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5457 - val_loss: 4.9940e-04 - val_coeff_determination: -0.0713 - lr: 4.8828e-06\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5627 - val_loss: 4.9940e-04 - val_coeff_determination: -0.0713 - lr: 4.8828e-06\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4311 - val_loss: 4.9940e-04 - val_coeff_determination: -0.0713 - lr: 4.8828e-06\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - coeff_determination: -0.6046 - val_loss: 4.9939e-04 - val_coeff_determination: -0.0712 - lr: 4.8828e-06\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5114 - val_loss: 4.9938e-04 - val_coeff_determination: -0.0710 - lr: 4.8828e-06\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5889 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0707 - lr: 4.8828e-06\n",
            "Epoch 301/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4565 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0707 - lr: 4.8828e-06\n",
            "Epoch 302/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0017 - coeff_determination: -0.4216\n",
            "Epoch 00302: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5116 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0707 - lr: 4.8828e-06\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4494 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0707 - lr: 2.4414e-06\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4443 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0707 - lr: 2.4414e-06\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4760 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0013 - coeff_determination: -0.4321 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - coeff_determination: -0.4933 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5633 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0710 - lr: 2.4414e-06\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5111 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4790 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4501 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6333 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4513 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5840 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5685 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5372 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4752 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 318/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4562 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 319/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4729 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 320/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4668 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0710 - lr: 2.4414e-06\n",
            "Epoch 321/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5531 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 322/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4683 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 323/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - coeff_determination: -0.4811 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0710 - lr: 2.4414e-06\n",
            "Epoch 324/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5311 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 2.4414e-06\n",
            "Epoch 325/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5629 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 326/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4892 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 327/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.4883\n",
            "Epoch 00327: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4554 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 2.4414e-06\n",
            "Epoch 328/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5609 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0708 - lr: 1.2207e-06\n",
            "Epoch 329/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3953 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 1.2207e-06\n",
            "Epoch 330/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4919 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 1.2207e-06\n",
            "Epoch 331/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.3486 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 1.2207e-06\n",
            "Epoch 332/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4636 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 1.2207e-06\n",
            "Epoch 333/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5311 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 1.2207e-06\n",
            "Epoch 334/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4767 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 1.2207e-06\n",
            "Epoch 335/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4770 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 336/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4154 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 337/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4699 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 338/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4765 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 339/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4301 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 340/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4870 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 341/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4312 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 342/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5309 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 343/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4550 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 344/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4743 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 1.2207e-06\n",
            "Epoch 345/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5311 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 1.2207e-06\n",
            "Epoch 346/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5104 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 1.2207e-06\n",
            "Epoch 347/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4450 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 1.2207e-06\n",
            "Epoch 348/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5014 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 349/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6060 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 350/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5751 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 351/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4590 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 352/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.2425\n",
            "Epoch 00352: ReduceLROnPlateau reducing learning rate to 6.103515488575795e-07.\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4671 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 1.2207e-06\n",
            "Epoch 353/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4393 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 6.1035e-07\n",
            "Epoch 354/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5143 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 6.1035e-07\n",
            "Epoch 355/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6553 - val_loss: 4.9937e-04 - val_coeff_determination: -0.0711 - lr: 6.1035e-07\n",
            "Epoch 356/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6424 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 357/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4714 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 358/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4599 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 359/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4350 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 360/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4913 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 361/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4325 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 362/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4595 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 363/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4832 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 364/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5039 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 365/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4214 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 366/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5898 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 367/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4990 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 368/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5203 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 369/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.7856 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 370/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5034 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 371/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4327 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0710 - lr: 6.1035e-07\n",
            "Epoch 372/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6083 - val_loss: 4.9936e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 373/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5468 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 374/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4864 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 375/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5030 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0709 - lr: 6.1035e-07\n",
            "Epoch 376/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5283 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 6.1035e-07\n",
            "Epoch 377/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.3747\n",
            "Epoch 00377: ReduceLROnPlateau reducing learning rate to 3.0517577442878974e-07.\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - coeff_determination: -0.5591 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0708 - lr: 6.1035e-07\n",
            "Epoch 378/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5818 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 379/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5138 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 380/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.5286 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 381/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4919 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 382/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4014 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 383/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5735 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 384/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0013 - coeff_determination: -0.3939 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 385/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5142 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 386/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4058 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 387/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4945 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 388/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5659 - val_loss: 4.9935e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 389/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5273 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 390/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6248 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 391/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4770 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 392/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5144 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 393/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4923 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 394/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5942 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 395/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5193 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 396/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5505 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 397/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5599 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 398/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5010 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 399/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5399 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 400/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0015 - coeff_determination: -0.6331 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 401/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4942 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 3.0518e-07\n",
            "Epoch 402/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - coeff_determination: -0.7435\n",
            "Epoch 00402: ReduceLROnPlateau reducing learning rate to 1.5258788721439487e-07.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5230 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0707 - lr: 3.0518e-07\n",
            "Epoch 403/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5305 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 404/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5412 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 405/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5251 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 406/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4490 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 407/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4567 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 408/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5488 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 409/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5387 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 410/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5614 - val_loss: 4.9934e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 411/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5860 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 412/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5176 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 413/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4465 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 414/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5934 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 415/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5100 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 416/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4576 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 417/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4600 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 418/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5625 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 419/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5530 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 420/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5372 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 421/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4893 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 422/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4520 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 423/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4525 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 424/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5711 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0706 - lr: 1.5259e-07\n",
            "Epoch 425/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4865 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 426/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4780 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 427/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.1881\n",
            "Epoch 00427: ReduceLROnPlateau reducing learning rate to 7.629394360719743e-08.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5246 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 1.5259e-07\n",
            "Epoch 428/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5180 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 429/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5256 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 430/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6686 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 431/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4145 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 432/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5694 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 433/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4558 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 434/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4360 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 435/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5312 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 436/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4144 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 437/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5423 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 438/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4519 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 439/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4916 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 440/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - coeff_determination: -0.5013 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 441/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5548 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 442/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4508 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 443/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5422 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 444/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4584 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 445/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4537 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 446/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4328 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 447/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4242 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 448/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4581 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 449/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6144 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 450/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4247 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 451/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4890 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 452/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0016 - coeff_determination: -0.3354\n",
            "Epoch 00452: ReduceLROnPlateau reducing learning rate to 3.814697180359872e-08.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5155 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 7.6294e-08\n",
            "Epoch 453/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4679 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 454/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5326 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 455/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4428 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 456/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0014 - coeff_determination: -0.4523 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 457/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4980 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 458/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5014 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 459/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4613 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 460/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5296 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 461/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4461 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 462/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5847 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 463/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5312 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 464/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4968 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 465/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5529 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 466/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5266 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 467/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.6168 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 468/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4750 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 469/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4831 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 470/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4820 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 471/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4598 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 472/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.4541 - val_loss: 4.9933e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 473/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5719 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 474/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5829 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 475/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.6544 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 3.8147e-08\n",
            "Epoch 476/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4836 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 3.8147e-08\n",
            "Epoch 477/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.7156\n",
            "Epoch 00477: ReduceLROnPlateau reducing learning rate to 1.907348590179936e-08.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5831 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 3.8147e-08\n",
            "Epoch 478/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5655 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 479/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.6068 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 480/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0014 - coeff_determination: -0.5317 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 481/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4512 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 482/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4689 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 483/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5240 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 484/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5036 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 485/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5390 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 486/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5045 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 487/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5332 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 488/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4627 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 489/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4529 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 490/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4665 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 491/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5305 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 492/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4869 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 493/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0015 - coeff_determination: -0.5653 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 494/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4803 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0704 - lr: 1.9073e-08\n",
            "Epoch 495/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5568 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 1.9073e-08\n",
            "Epoch 496/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5753 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 1.9073e-08\n",
            "Epoch 497/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0015 - coeff_determination: -0.5589 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 1.9073e-08\n",
            "Epoch 498/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.5384 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 1.9073e-08\n",
            "Epoch 499/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0014 - coeff_determination: -0.4959 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 1.9073e-08\n",
            "Epoch 500/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0014 - coeff_determination: -0.5838 - val_loss: 4.9932e-04 - val_coeff_determination: -0.0705 - lr: 1.9073e-08\n",
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - coeff_determination: -12.1594 - val_loss: 0.0030 - val_coeff_determination: -0.0432 - lr: 0.0100\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0024 - coeff_determination: -1.6716 - val_loss: 0.0029 - val_coeff_determination: -0.0818 - lr: 0.0100\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0016 - coeff_determination: -0.8262 - val_loss: 0.0029 - val_coeff_determination: -0.1112 - lr: 0.0100\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0013 - coeff_determination: -0.4827 - val_loss: 0.0029 - val_coeff_determination: -0.1296 - lr: 0.0100\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0012 - coeff_determination: -0.3606 - val_loss: 0.0030 - val_coeff_determination: -0.1713 - lr: 0.0100\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.2721 - val_loss: 0.0029 - val_coeff_determination: -0.0861 - lr: 0.0100\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0011 - coeff_determination: -0.2631 - val_loss: 0.0029 - val_coeff_determination: -0.0486 - lr: 0.0100\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.2112 - val_loss: 0.0029 - val_coeff_determination: -0.0640 - lr: 0.0100\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0011 - coeff_determination: -0.2117 - val_loss: 0.0029 - val_coeff_determination: -0.1099 - lr: 0.0100\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0010 - coeff_determination: -0.1351 - val_loss: 0.0029 - val_coeff_determination: -0.0682 - lr: 0.0100\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.0010 - coeff_determination: -0.1377 - val_loss: 0.0029 - val_coeff_determination: -0.0659 - lr: 0.0100\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.9153e-04 - coeff_determination: -0.1015 - val_loss: 0.0029 - val_coeff_determination: -0.1052 - lr: 0.0100\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.6950e-04 - coeff_determination: -0.0977 - val_loss: 0.0029 - val_coeff_determination: -0.0517 - lr: 0.0100\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 9.7810e-04 - coeff_determination: -0.0993 - val_loss: 0.0029 - val_coeff_determination: -0.1443 - lr: 0.0100\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.6966e-04 - coeff_determination: -0.0755 - val_loss: 0.0029 - val_coeff_determination: -0.1134 - lr: 0.0100\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.4458e-04 - coeff_determination: -0.0509 - val_loss: 0.0029 - val_coeff_determination: -0.0682 - lr: 0.0100\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.6291e-04 - coeff_determination: -0.0982 - val_loss: 0.0029 - val_coeff_determination: -0.0341 - lr: 0.0100\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.6451e-04 - coeff_determination: -0.0808 - val_loss: 0.0029 - val_coeff_determination: -0.1268 - lr: 0.0100\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2265e-04 - coeff_determination: -0.0306 - val_loss: 0.0029 - val_coeff_determination: -0.0423 - lr: 0.0100\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2500e-04 - coeff_determination: -0.0352 - val_loss: 0.0029 - val_coeff_determination: -0.0598 - lr: 0.0100\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 9.3197e-04 - coeff_determination: -0.0582 - val_loss: 0.0029 - val_coeff_determination: -0.0641 - lr: 0.0100\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.9294e-04 - coeff_determination: -0.1019 - val_loss: 0.0029 - val_coeff_determination: -0.1546 - lr: 0.0100\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.4619e-04 - coeff_determination: -0.0568 - val_loss: 0.0029 - val_coeff_determination: -0.0324 - lr: 0.0100\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2242e-04 - coeff_determination: -0.0359 - val_loss: 0.0029 - val_coeff_determination: -0.0843 - lr: 0.0100\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2556e-04 - coeff_determination: -0.0310 - val_loss: 0.0029 - val_coeff_determination: -0.1002 - lr: 0.0100\n",
            "Epoch 26/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.4514e-04 - coeff_determination: -0.0758\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2433e-04 - coeff_determination: -0.0363 - val_loss: 0.0029 - val_coeff_determination: -0.0572 - lr: 0.0100\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1811e-04 - coeff_determination: -0.0251 - val_loss: 0.0029 - val_coeff_determination: -0.0508 - lr: 0.0050\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1538e-04 - coeff_determination: -0.0168 - val_loss: 0.0029 - val_coeff_determination: -0.0900 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0485e-04 - coeff_determination: -0.0109 - val_loss: 0.0029 - val_coeff_determination: -0.0652 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2713e-04 - coeff_determination: -0.0309 - val_loss: 0.0029 - val_coeff_determination: -0.0616 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1527e-04 - coeff_determination: -0.0344 - val_loss: 0.0029 - val_coeff_determination: -0.0553 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.3259e-04 - coeff_determination: -0.0422 - val_loss: 0.0029 - val_coeff_determination: -0.0832 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2948e-04 - coeff_determination: -0.0443 - val_loss: 0.0029 - val_coeff_determination: -0.0590 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1947e-04 - coeff_determination: -0.0395 - val_loss: 0.0029 - val_coeff_determination: -0.0805 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.1500e-04 - coeff_determination: -0.0374 - val_loss: 0.0029 - val_coeff_determination: -0.0667 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1060e-04 - coeff_determination: -0.0196 - val_loss: 0.0029 - val_coeff_determination: -0.0527 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1113e-04 - coeff_determination: -0.0233 - val_loss: 0.0029 - val_coeff_determination: -0.0564 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1983e-04 - coeff_determination: -0.0325 - val_loss: 0.0029 - val_coeff_determination: -0.0314 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2380e-04 - coeff_determination: -0.0479 - val_loss: 0.0029 - val_coeff_determination: -0.0952 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1681e-04 - coeff_determination: -0.0290 - val_loss: 0.0029 - val_coeff_determination: -0.0570 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0198e-04 - coeff_determination: -0.0097 - val_loss: 0.0029 - val_coeff_determination: -0.0746 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0835e-04 - coeff_determination: -0.0155 - val_loss: 0.0029 - val_coeff_determination: -0.0749 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0217e-04 - coeff_determination: -0.0047 - val_loss: 0.0029 - val_coeff_determination: -0.0426 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1142e-04 - coeff_determination: -0.0260 - val_loss: 0.0029 - val_coeff_determination: -0.0537 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0536e-04 - coeff_determination: -0.0149 - val_loss: 0.0029 - val_coeff_determination: -0.0501 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1778e-04 - coeff_determination: -0.0293 - val_loss: 0.0029 - val_coeff_determination: -0.0695 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.3044e-04 - coeff_determination: -0.0386 - val_loss: 0.0029 - val_coeff_determination: -0.0734 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.2386e-04 - coeff_determination: -0.0335 - val_loss: 0.0029 - val_coeff_determination: -0.0809 - lr: 0.0050\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.1505e-04 - coeff_determination: -0.0169 - val_loss: 0.0029 - val_coeff_determination: -0.0711 - lr: 0.0050\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0598e-04 - coeff_determination: -0.0245 - val_loss: 0.0029 - val_coeff_determination: -0.0717 - lr: 0.0050\n",
            "Epoch 51/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.0002e-04 - coeff_determination: 0.0344\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0049e-04 - coeff_determination: -0.0180 - val_loss: 0.0029 - val_coeff_determination: -0.0919 - lr: 0.0050\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0186e-04 - coeff_determination: -0.0148 - val_loss: 0.0029 - val_coeff_determination: -0.0672 - lr: 0.0025\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9212e-04 - coeff_determination: 0.0069 - val_loss: 0.0029 - val_coeff_determination: -0.0828 - lr: 0.0025\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9150e-04 - coeff_determination: -0.0064 - val_loss: 0.0029 - val_coeff_determination: -0.0481 - lr: 0.0025\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1252e-04 - coeff_determination: -0.0261 - val_loss: 0.0029 - val_coeff_determination: -0.0671 - lr: 0.0025\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0426e-04 - coeff_determination: -0.0160 - val_loss: 0.0029 - val_coeff_determination: -0.0922 - lr: 0.0025\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1033e-04 - coeff_determination: -0.0203 - val_loss: 0.0029 - val_coeff_determination: -0.0435 - lr: 0.0025\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0933e-04 - coeff_determination: -0.0209 - val_loss: 0.0029 - val_coeff_determination: -0.0615 - lr: 0.0025\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1486e-04 - coeff_determination: -0.0381 - val_loss: 0.0029 - val_coeff_determination: -0.1089 - lr: 0.0025\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0216e-04 - coeff_determination: -0.0089 - val_loss: 0.0029 - val_coeff_determination: -0.0612 - lr: 0.0025\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9992e-04 - coeff_determination: -0.0079 - val_loss: 0.0029 - val_coeff_determination: -0.0786 - lr: 0.0025\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9379e-04 - coeff_determination: -0.0074 - val_loss: 0.0029 - val_coeff_determination: -0.0642 - lr: 0.0025\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 9.0592e-04 - coeff_determination: -0.0162 - val_loss: 0.0029 - val_coeff_determination: -0.0465 - lr: 0.0025\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0491e-04 - coeff_determination: -0.0174 - val_loss: 0.0029 - val_coeff_determination: -0.1150 - lr: 0.0025\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1199e-04 - coeff_determination: -0.0144 - val_loss: 0.0029 - val_coeff_determination: -0.0964 - lr: 0.0025\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1231e-04 - coeff_determination: -0.0123 - val_loss: 0.0029 - val_coeff_determination: -0.0599 - lr: 0.0025\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.1174e-04 - coeff_determination: -0.0174 - val_loss: 0.0029 - val_coeff_determination: -0.0696 - lr: 0.0025\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9933e-04 - coeff_determination: -0.0074 - val_loss: 0.0029 - val_coeff_determination: -0.0749 - lr: 0.0025\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9700e-04 - coeff_determination: -0.0127 - val_loss: 0.0029 - val_coeff_determination: -0.0655 - lr: 0.0025\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0135e-04 - coeff_determination: -0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0440 - lr: 0.0025\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9199e-04 - coeff_determination: 0.0044 - val_loss: 0.0029 - val_coeff_determination: -0.0949 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9826e-04 - coeff_determination: -0.0059 - val_loss: 0.0029 - val_coeff_determination: -0.0424 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9753e-04 - coeff_determination: -0.0110 - val_loss: 0.0029 - val_coeff_determination: -0.0721 - lr: 0.0025\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0315e-04 - coeff_determination: -0.0087 - val_loss: 0.0029 - val_coeff_determination: -0.0856 - lr: 0.0025\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0623e-04 - coeff_determination: -0.0118 - val_loss: 0.0029 - val_coeff_determination: -0.0608 - lr: 0.0025\n",
            "Epoch 76/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.1240e-04 - coeff_determination: 0.0271\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8816e-04 - coeff_determination: 4.2908e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0706 - lr: 0.0025\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8986e-04 - coeff_determination: 3.8261e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0666 - lr: 0.0012\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0271e-04 - coeff_determination: -0.0069 - val_loss: 0.0029 - val_coeff_determination: -0.0878 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0280e-04 - coeff_determination: -0.0074 - val_loss: 0.0029 - val_coeff_determination: -0.0644 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0717e-04 - coeff_determination: -0.0096 - val_loss: 0.0029 - val_coeff_determination: -0.0825 - lr: 0.0012\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9762e-04 - coeff_determination: -0.0087 - val_loss: 0.0029 - val_coeff_determination: -0.0757 - lr: 0.0012\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9778e-04 - coeff_determination: -0.0097 - val_loss: 0.0029 - val_coeff_determination: -0.0741 - lr: 0.0012\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0571e-04 - coeff_determination: -0.0100 - val_loss: 0.0029 - val_coeff_determination: -0.0736 - lr: 0.0012\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9087e-04 - coeff_determination: -3.3766e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0642 - lr: 0.0012\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9759e-04 - coeff_determination: -0.0094 - val_loss: 0.0029 - val_coeff_determination: -0.0814 - lr: 0.0012\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9522e-04 - coeff_determination: -0.0020 - val_loss: 0.0029 - val_coeff_determination: -0.0821 - lr: 0.0012\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9708e-04 - coeff_determination: 7.7146e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0659 - lr: 0.0012\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9575e-04 - coeff_determination: 0.0016 - val_loss: 0.0029 - val_coeff_determination: -0.0896 - lr: 0.0012\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0042e-04 - coeff_determination: -0.0118 - val_loss: 0.0029 - val_coeff_determination: -0.0709 - lr: 0.0012\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9276e-04 - coeff_determination: -4.8763e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0753 - lr: 0.0012\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9705e-04 - coeff_determination: -0.0063 - val_loss: 0.0029 - val_coeff_determination: -0.0655 - lr: 0.0012\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8544e-04 - coeff_determination: 0.0095 - val_loss: 0.0029 - val_coeff_determination: -0.0790 - lr: 0.0012\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8423e-04 - coeff_determination: 0.0139 - val_loss: 0.0029 - val_coeff_determination: -0.0836 - lr: 0.0012\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8609e-04 - coeff_determination: 0.0168 - val_loss: 0.0029 - val_coeff_determination: -0.0646 - lr: 0.0012\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8571e-04 - coeff_determination: 0.0176 - val_loss: 0.0029 - val_coeff_determination: -0.0801 - lr: 0.0012\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9740e-04 - coeff_determination: -0.0090 - val_loss: 0.0029 - val_coeff_determination: -0.0845 - lr: 0.0012\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9608e-04 - coeff_determination: -0.0032 - val_loss: 0.0029 - val_coeff_determination: -0.0695 - lr: 0.0012\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8252e-04 - coeff_determination: 0.0084 - val_loss: 0.0029 - val_coeff_determination: -0.0914 - lr: 0.0012\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9741e-04 - coeff_determination: -0.0021 - val_loss: 0.0029 - val_coeff_determination: -0.0663 - lr: 0.0012\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9861e-04 - coeff_determination: -0.0031 - val_loss: 0.0029 - val_coeff_determination: -0.0992 - lr: 0.0012\n",
            "Epoch 101/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0013 - coeff_determination: -0.0332\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9282e-04 - coeff_determination: 0.0026 - val_loss: 0.0029 - val_coeff_determination: -0.0707 - lr: 0.0012\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0684e-04 - coeff_determination: -0.0112 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 6.2500e-04\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0023e-04 - coeff_determination: -0.0160 - val_loss: 0.0029 - val_coeff_determination: -0.0807 - lr: 6.2500e-04\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9943e-04 - coeff_determination: -0.0042 - val_loss: 0.0029 - val_coeff_determination: -0.0837 - lr: 6.2500e-04\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0068e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0713 - lr: 6.2500e-04\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9215e-04 - coeff_determination: 0.0028 - val_loss: 0.0029 - val_coeff_determination: -0.0815 - lr: 6.2500e-04\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9372e-04 - coeff_determination: -6.3175e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0746 - lr: 6.2500e-04\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0207e-04 - coeff_determination: -5.6665e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0738 - lr: 6.2500e-04\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8926e-04 - coeff_determination: 0.0070 - val_loss: 0.0029 - val_coeff_determination: -0.0770 - lr: 6.2500e-04\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9053e-04 - coeff_determination: 0.0017 - val_loss: 0.0029 - val_coeff_determination: -0.0750 - lr: 6.2500e-04\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9693e-04 - coeff_determination: 0.0035 - val_loss: 0.0029 - val_coeff_determination: -0.0703 - lr: 6.2500e-04\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8047e-04 - coeff_determination: 0.0164 - val_loss: 0.0029 - val_coeff_determination: -0.0780 - lr: 6.2500e-04\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9520e-04 - coeff_determination: -7.3525e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0770 - lr: 6.2500e-04\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0187e-04 - coeff_determination: -0.0039 - val_loss: 0.0029 - val_coeff_determination: -0.0856 - lr: 6.2500e-04\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8203e-04 - coeff_determination: 0.0042 - val_loss: 0.0029 - val_coeff_determination: -0.0719 - lr: 6.2500e-04\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9117e-04 - coeff_determination: 8.1676e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0833 - lr: 6.2500e-04\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8905e-04 - coeff_determination: 0.0119 - val_loss: 0.0029 - val_coeff_determination: -0.0687 - lr: 6.2500e-04\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9413e-04 - coeff_determination: -0.0023 - val_loss: 0.0029 - val_coeff_determination: -0.0768 - lr: 6.2500e-04\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9914e-04 - coeff_determination: -0.0060 - val_loss: 0.0029 - val_coeff_determination: -0.0801 - lr: 6.2500e-04\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8213e-04 - coeff_determination: 0.0100 - val_loss: 0.0029 - val_coeff_determination: -0.0794 - lr: 6.2500e-04\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8996e-04 - coeff_determination: 0.0071 - val_loss: 0.0029 - val_coeff_determination: -0.0670 - lr: 6.2500e-04\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9279e-04 - coeff_determination: 0.0052 - val_loss: 0.0029 - val_coeff_determination: -0.0734 - lr: 6.2500e-04\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8761e-04 - coeff_determination: 0.0056 - val_loss: 0.0029 - val_coeff_determination: -0.0837 - lr: 6.2500e-04\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7630e-04 - coeff_determination: 0.0090 - val_loss: 0.0029 - val_coeff_determination: -0.0759 - lr: 6.2500e-04\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0002e-04 - coeff_determination: -0.0029 - val_loss: 0.0029 - val_coeff_determination: -0.0675 - lr: 6.2500e-04\n",
            "Epoch 126/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.7459e-04 - coeff_determination: -0.0188\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9742e-04 - coeff_determination: -0.0173 - val_loss: 0.0029 - val_coeff_determination: -0.0868 - lr: 6.2500e-04\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8536e-04 - coeff_determination: 0.0058 - val_loss: 0.0029 - val_coeff_determination: -0.0728 - lr: 3.1250e-04\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8827e-04 - coeff_determination: 0.0078 - val_loss: 0.0029 - val_coeff_determination: -0.0669 - lr: 3.1250e-04\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7639e-04 - coeff_determination: 0.0216 - val_loss: 0.0029 - val_coeff_determination: -0.0774 - lr: 3.1250e-04\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9109e-04 - coeff_determination: 0.0078 - val_loss: 0.0029 - val_coeff_determination: -0.0831 - lr: 3.1250e-04\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8762e-04 - coeff_determination: 0.0068 - val_loss: 0.0029 - val_coeff_determination: -0.0736 - lr: 3.1250e-04\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9706e-04 - coeff_determination: -0.0108 - val_loss: 0.0029 - val_coeff_determination: -0.0698 - lr: 3.1250e-04\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9735e-04 - coeff_determination: -0.0016 - val_loss: 0.0029 - val_coeff_determination: -0.0719 - lr: 3.1250e-04\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8846e-04 - coeff_determination: 0.0077 - val_loss: 0.0029 - val_coeff_determination: -0.0746 - lr: 3.1250e-04\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9207e-04 - coeff_determination: 0.0049 - val_loss: 0.0029 - val_coeff_determination: -0.0737 - lr: 3.1250e-04\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8704e-04 - coeff_determination: 0.0099 - val_loss: 0.0029 - val_coeff_determination: -0.0827 - lr: 3.1250e-04\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8261e-04 - coeff_determination: -0.0021 - val_loss: 0.0029 - val_coeff_determination: -0.0711 - lr: 3.1250e-04\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8957e-04 - coeff_determination: -0.0094 - val_loss: 0.0029 - val_coeff_determination: -0.0843 - lr: 3.1250e-04\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8847e-04 - coeff_determination: 0.0134 - val_loss: 0.0029 - val_coeff_determination: -0.0700 - lr: 3.1250e-04\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9316e-04 - coeff_determination: -0.0042 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 3.1250e-04\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9884e-04 - coeff_determination: -0.0025 - val_loss: 0.0029 - val_coeff_determination: -0.0746 - lr: 3.1250e-04\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9207e-04 - coeff_determination: -0.0024 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 3.1250e-04\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8270e-04 - coeff_determination: 0.0125 - val_loss: 0.0029 - val_coeff_determination: -0.0722 - lr: 3.1250e-04\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9536e-04 - coeff_determination: -0.0095 - val_loss: 0.0029 - val_coeff_determination: -0.0852 - lr: 3.1250e-04\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8978e-04 - coeff_determination: -0.0017 - val_loss: 0.0029 - val_coeff_determination: -0.0718 - lr: 3.1250e-04\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8438e-04 - coeff_determination: 0.0181 - val_loss: 0.0029 - val_coeff_determination: -0.0766 - lr: 3.1250e-04\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9039e-04 - coeff_determination: 0.0029 - val_loss: 0.0029 - val_coeff_determination: -0.0732 - lr: 3.1250e-04\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9163e-04 - coeff_determination: 0.0064 - val_loss: 0.0029 - val_coeff_determination: -0.0697 - lr: 3.1250e-04\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8177e-04 - coeff_determination: 0.0108 - val_loss: 0.0029 - val_coeff_determination: -0.0757 - lr: 3.1250e-04\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9281e-04 - coeff_determination: -0.0039 - val_loss: 0.0029 - val_coeff_determination: -0.0738 - lr: 3.1250e-04\n",
            "Epoch 151/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 7.9401e-04 - coeff_determination: 0.0074\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9512e-04 - coeff_determination: -0.0031 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 3.1250e-04\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7220e-04 - coeff_determination: 0.0212 - val_loss: 0.0029 - val_coeff_determination: -0.0737 - lr: 1.5625e-04\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8774e-04 - coeff_determination: 0.0104 - val_loss: 0.0029 - val_coeff_determination: -0.0735 - lr: 1.5625e-04\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8459e-04 - coeff_determination: 0.0149 - val_loss: 0.0029 - val_coeff_determination: -0.0733 - lr: 1.5625e-04\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8612e-04 - coeff_determination: 0.0159 - val_loss: 0.0029 - val_coeff_determination: -0.0779 - lr: 1.5625e-04\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9747e-04 - coeff_determination: -0.0033 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 1.5625e-04\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9175e-04 - coeff_determination: 1.0952e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0714 - lr: 1.5625e-04\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8736e-04 - coeff_determination: 0.0085 - val_loss: 0.0029 - val_coeff_determination: -0.0753 - lr: 1.5625e-04\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9739e-04 - coeff_determination: 0.0041 - val_loss: 0.0029 - val_coeff_determination: -0.0742 - lr: 1.5625e-04\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7536e-04 - coeff_determination: 0.0234 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 1.5625e-04\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8992e-04 - coeff_determination: 4.8999e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0820 - lr: 1.5625e-04\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9013e-04 - coeff_determination: 0.0073 - val_loss: 0.0029 - val_coeff_determination: -0.0767 - lr: 1.5625e-04\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8449e-04 - coeff_determination: 0.0087 - val_loss: 0.0029 - val_coeff_determination: -0.0769 - lr: 1.5625e-04\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8050e-04 - coeff_determination: 4.3923e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0788 - lr: 1.5625e-04\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8590e-04 - coeff_determination: 0.0030 - val_loss: 0.0029 - val_coeff_determination: -0.0812 - lr: 1.5625e-04\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8469e-04 - coeff_determination: 0.0076 - val_loss: 0.0029 - val_coeff_determination: -0.0725 - lr: 1.5625e-04\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0045e-04 - coeff_determination: -0.0142 - val_loss: 0.0029 - val_coeff_determination: -0.0757 - lr: 1.5625e-04\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9566e-04 - coeff_determination: -0.0053 - val_loss: 0.0029 - val_coeff_determination: -0.0788 - lr: 1.5625e-04\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8609e-04 - coeff_determination: 0.0133 - val_loss: 0.0029 - val_coeff_determination: -0.0749 - lr: 1.5625e-04\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7536e-04 - coeff_determination: 0.0214 - val_loss: 0.0029 - val_coeff_determination: -0.0752 - lr: 1.5625e-04\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8420e-04 - coeff_determination: 0.0104 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 1.5625e-04\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8961e-04 - coeff_determination: -0.0023 - val_loss: 0.0029 - val_coeff_determination: -0.0737 - lr: 1.5625e-04\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8989e-04 - coeff_determination: 0.0071 - val_loss: 0.0029 - val_coeff_determination: -0.0747 - lr: 1.5625e-04\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9412e-04 - coeff_determination: 0.0093 - val_loss: 0.0029 - val_coeff_determination: -0.0752 - lr: 1.5625e-04\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9788e-04 - coeff_determination: -0.0050 - val_loss: 0.0029 - val_coeff_determination: -0.0779 - lr: 1.5625e-04\n",
            "Epoch 176/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.5319e-04 - coeff_determination: 0.0787\n",
            "Epoch 00176: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9717e-04 - coeff_determination: 0.0012 - val_loss: 0.0029 - val_coeff_determination: -0.0788 - lr: 1.5625e-04\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8923e-04 - coeff_determination: 6.5691e-05 - val_loss: 0.0029 - val_coeff_determination: -0.0772 - lr: 7.8125e-05\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7608e-04 - coeff_determination: 0.0149 - val_loss: 0.0029 - val_coeff_determination: -0.0767 - lr: 7.8125e-05\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8181e-04 - coeff_determination: 0.0162 - val_loss: 0.0029 - val_coeff_determination: -0.0756 - lr: 7.8125e-05\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8788e-04 - coeff_determination: 0.0058 - val_loss: 0.0029 - val_coeff_determination: -0.0729 - lr: 7.8125e-05\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.8154e-04 - coeff_determination: 0.0134 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 7.8125e-05\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7968e-04 - coeff_determination: 0.0160 - val_loss: 0.0029 - val_coeff_determination: -0.0796 - lr: 7.8125e-05\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9065e-04 - coeff_determination: 0.0013 - val_loss: 0.0029 - val_coeff_determination: -0.0768 - lr: 7.8125e-05\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9323e-04 - coeff_determination: 0.0031 - val_loss: 0.0029 - val_coeff_determination: -0.0783 - lr: 7.8125e-05\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9149e-04 - coeff_determination: -0.0017 - val_loss: 0.0029 - val_coeff_determination: -0.0746 - lr: 7.8125e-05\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7956e-04 - coeff_determination: 0.0288 - val_loss: 0.0029 - val_coeff_determination: -0.0769 - lr: 7.8125e-05\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8567e-04 - coeff_determination: 0.0069 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 7.8125e-05\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9664e-04 - coeff_determination: -0.0098 - val_loss: 0.0029 - val_coeff_determination: -0.0740 - lr: 7.8125e-05\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8671e-04 - coeff_determination: 0.0104 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 7.8125e-05\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8116e-04 - coeff_determination: 0.0138 - val_loss: 0.0029 - val_coeff_determination: -0.0767 - lr: 7.8125e-05\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9233e-04 - coeff_determination: -0.0026 - val_loss: 0.0029 - val_coeff_determination: -0.0797 - lr: 7.8125e-05\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8569e-04 - coeff_determination: 0.0054 - val_loss: 0.0029 - val_coeff_determination: -0.0768 - lr: 7.8125e-05\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9102e-04 - coeff_determination: 6.1404e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0747 - lr: 7.8125e-05\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8164e-04 - coeff_determination: 0.0095 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 7.8125e-05\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8392e-04 - coeff_determination: 0.0083 - val_loss: 0.0029 - val_coeff_determination: -0.0798 - lr: 7.8125e-05\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8303e-04 - coeff_determination: 0.0139 - val_loss: 0.0029 - val_coeff_determination: -0.0766 - lr: 7.8125e-05\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8978e-04 - coeff_determination: 0.0020 - val_loss: 0.0029 - val_coeff_determination: -0.0772 - lr: 7.8125e-05\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7860e-04 - coeff_determination: 0.0117 - val_loss: 0.0029 - val_coeff_determination: -0.0753 - lr: 7.8125e-05\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9806e-04 - coeff_determination: -7.6296e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0757 - lr: 7.8125e-05\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7966e-04 - coeff_determination: 0.0135 - val_loss: 0.0029 - val_coeff_determination: -0.0739 - lr: 7.8125e-05\n",
            "Epoch 201/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 8.3522e-04 - coeff_determination: 0.0500\n",
            "Epoch 00201: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8440e-04 - coeff_determination: 0.0078 - val_loss: 0.0029 - val_coeff_determination: -0.0772 - lr: 7.8125e-05\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8775e-04 - coeff_determination: 0.0023 - val_loss: 0.0029 - val_coeff_determination: -0.0767 - lr: 3.9062e-05\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9822e-04 - coeff_determination: -0.0061 - val_loss: 0.0029 - val_coeff_determination: -0.0790 - lr: 3.9062e-05\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8934e-04 - coeff_determination: 0.0064 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 3.9062e-05\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8693e-04 - coeff_determination: 0.0093 - val_loss: 0.0029 - val_coeff_determination: -0.0763 - lr: 3.9062e-05\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8317e-04 - coeff_determination: 0.0164 - val_loss: 0.0029 - val_coeff_determination: -0.0762 - lr: 3.9062e-05\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8877e-04 - coeff_determination: 0.0057 - val_loss: 0.0029 - val_coeff_determination: -0.0770 - lr: 3.9062e-05\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9602e-04 - coeff_determination: -7.1235e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 3.9062e-05\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8094e-04 - coeff_determination: 0.0104 - val_loss: 0.0029 - val_coeff_determination: -0.0793 - lr: 3.9062e-05\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8116e-04 - coeff_determination: 0.0221 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 3.9062e-05\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8885e-04 - coeff_determination: 0.0012 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 3.9062e-05\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9055e-04 - coeff_determination: 0.0058 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 3.9062e-05\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9314e-04 - coeff_determination: -0.0071 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 3.9062e-05\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8626e-04 - coeff_determination: 0.0161 - val_loss: 0.0029 - val_coeff_determination: -0.0756 - lr: 3.9062e-05\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8649e-04 - coeff_determination: 0.0086 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 3.9062e-05\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9757e-04 - coeff_determination: 0.0012 - val_loss: 0.0029 - val_coeff_determination: -0.0770 - lr: 3.9062e-05\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8961e-04 - coeff_determination: 0.0015 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 3.9062e-05\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8116e-04 - coeff_determination: 0.0133 - val_loss: 0.0029 - val_coeff_determination: -0.0771 - lr: 3.9062e-05\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9328e-04 - coeff_determination: -0.0029 - val_loss: 0.0029 - val_coeff_determination: -0.0782 - lr: 3.9062e-05\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8714e-04 - coeff_determination: -3.3312e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0756 - lr: 3.9062e-05\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8650e-04 - coeff_determination: 0.0207 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 3.9062e-05\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9121e-04 - coeff_determination: 0.0033 - val_loss: 0.0029 - val_coeff_determination: -0.0772 - lr: 3.9062e-05\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8340e-04 - coeff_determination: 0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0774 - lr: 3.9062e-05\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9229e-04 - coeff_determination: -0.0018 - val_loss: 0.0029 - val_coeff_determination: -0.0765 - lr: 3.9062e-05\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9191e-04 - coeff_determination: -0.0011 - val_loss: 0.0029 - val_coeff_determination: -0.0783 - lr: 3.9062e-05\n",
            "Epoch 226/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 7.5871e-04 - coeff_determination: 0.0473\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9894e-04 - coeff_determination: -0.0064 - val_loss: 0.0029 - val_coeff_determination: -0.0795 - lr: 3.9062e-05\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8248e-04 - coeff_determination: 0.0120 - val_loss: 0.0029 - val_coeff_determination: -0.0793 - lr: 1.9531e-05\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9155e-04 - coeff_determination: 0.0038 - val_loss: 0.0029 - val_coeff_determination: -0.0781 - lr: 1.9531e-05\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7515e-04 - coeff_determination: 0.0190 - val_loss: 0.0029 - val_coeff_determination: -0.0781 - lr: 1.9531e-05\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8986e-04 - coeff_determination: 0.0052 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 1.9531e-05\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.8647e-04 - coeff_determination: 0.0128 - val_loss: 0.0029 - val_coeff_determination: -0.0791 - lr: 1.9531e-05\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8210e-04 - coeff_determination: 0.0120 - val_loss: 0.0029 - val_coeff_determination: -0.0803 - lr: 1.9531e-05\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8536e-04 - coeff_determination: -0.0081 - val_loss: 0.0029 - val_coeff_determination: -0.0797 - lr: 1.9531e-05\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8936e-04 - coeff_determination: 0.0014 - val_loss: 0.0029 - val_coeff_determination: -0.0799 - lr: 1.9531e-05\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9821e-04 - coeff_determination: -0.0054 - val_loss: 0.0029 - val_coeff_determination: -0.0794 - lr: 1.9531e-05\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8156e-04 - coeff_determination: 0.0174 - val_loss: 0.0029 - val_coeff_determination: -0.0792 - lr: 1.9531e-05\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8820e-04 - coeff_determination: 0.0022 - val_loss: 0.0029 - val_coeff_determination: -0.0792 - lr: 1.9531e-05\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8102e-04 - coeff_determination: 0.0093 - val_loss: 0.0029 - val_coeff_determination: -0.0791 - lr: 1.9531e-05\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8577e-04 - coeff_determination: 0.0100 - val_loss: 0.0029 - val_coeff_determination: -0.0788 - lr: 1.9531e-05\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9106e-04 - coeff_determination: 0.0018 - val_loss: 0.0029 - val_coeff_determination: -0.0786 - lr: 1.9531e-05\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.8878e-04 - coeff_determination: 0.0010 - val_loss: 0.0029 - val_coeff_determination: -0.0780 - lr: 1.9531e-05\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9146e-04 - coeff_determination: -0.0020 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 1.9531e-05\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8366e-04 - coeff_determination: 0.0120 - val_loss: 0.0029 - val_coeff_determination: -0.0792 - lr: 1.9531e-05\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8275e-04 - coeff_determination: 0.0063 - val_loss: 0.0029 - val_coeff_determination: -0.0792 - lr: 1.9531e-05\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8413e-04 - coeff_determination: 0.0130 - val_loss: 0.0029 - val_coeff_determination: -0.0788 - lr: 1.9531e-05\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9216e-04 - coeff_determination: -0.0012 - val_loss: 0.0029 - val_coeff_determination: -0.0797 - lr: 1.9531e-05\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1090e-04 - coeff_determination: -0.0317 - val_loss: 0.0029 - val_coeff_determination: -0.0798 - lr: 1.9531e-05\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7894e-04 - coeff_determination: 0.0107 - val_loss: 0.0029 - val_coeff_determination: -0.0790 - lr: 1.9531e-05\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8813e-04 - coeff_determination: -0.0037 - val_loss: 0.0029 - val_coeff_determination: -0.0770 - lr: 1.9531e-05\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8805e-04 - coeff_determination: 0.0029 - val_loss: 0.0029 - val_coeff_determination: -0.0758 - lr: 1.9531e-05\n",
            "Epoch 251/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 6.9487e-04 - coeff_determination: 0.0027\n",
            "Epoch 00251: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8922e-04 - coeff_determination: -0.0017 - val_loss: 0.0029 - val_coeff_determination: -0.0752 - lr: 1.9531e-05\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8073e-04 - coeff_determination: 0.0130 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 9.7656e-06\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8174e-04 - coeff_determination: 0.0110 - val_loss: 0.0029 - val_coeff_determination: -0.0756 - lr: 9.7656e-06\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9699e-04 - coeff_determination: -0.0051 - val_loss: 0.0029 - val_coeff_determination: -0.0759 - lr: 9.7656e-06\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9013e-04 - coeff_determination: -8.8169e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0759 - lr: 9.7656e-06\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.9377e-04 - coeff_determination: -0.0055 - val_loss: 0.0029 - val_coeff_determination: -0.0765 - lr: 9.7656e-06\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9141e-04 - coeff_determination: 5.0202e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 9.7656e-06\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8774e-04 - coeff_determination: 0.0023 - val_loss: 0.0029 - val_coeff_determination: -0.0758 - lr: 9.7656e-06\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9694e-04 - coeff_determination: -0.0039 - val_loss: 0.0029 - val_coeff_determination: -0.0760 - lr: 9.7656e-06\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9015e-04 - coeff_determination: 0.0059 - val_loss: 0.0029 - val_coeff_determination: -0.0759 - lr: 9.7656e-06\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8595e-04 - coeff_determination: 0.0029 - val_loss: 0.0029 - val_coeff_determination: -0.0763 - lr: 9.7656e-06\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9278e-04 - coeff_determination: -0.0024 - val_loss: 0.0029 - val_coeff_determination: -0.0764 - lr: 9.7656e-06\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8833e-04 - coeff_determination: 0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0761 - lr: 9.7656e-06\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9002e-04 - coeff_determination: 0.0033 - val_loss: 0.0029 - val_coeff_determination: -0.0758 - lr: 9.7656e-06\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7916e-04 - coeff_determination: 0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0758 - lr: 9.7656e-06\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8543e-04 - coeff_determination: 0.0114 - val_loss: 0.0029 - val_coeff_determination: -0.0756 - lr: 9.7656e-06\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9059e-04 - coeff_determination: -0.0016 - val_loss: 0.0029 - val_coeff_determination: -0.0758 - lr: 9.7656e-06\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8168e-04 - coeff_determination: 0.0115 - val_loss: 0.0029 - val_coeff_determination: -0.0767 - lr: 9.7656e-06\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.8029e-04 - coeff_determination: 0.0146 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 9.7656e-06\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9440e-04 - coeff_determination: -0.0077 - val_loss: 0.0029 - val_coeff_determination: -0.0781 - lr: 9.7656e-06\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8583e-04 - coeff_determination: 0.0146 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 9.7656e-06\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8640e-04 - coeff_determination: -9.9312e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 9.7656e-06\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9504e-04 - coeff_determination: 4.7549e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0780 - lr: 9.7656e-06\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.7447e-04 - coeff_determination: 0.0229 - val_loss: 0.0029 - val_coeff_determination: -0.0785 - lr: 9.7656e-06\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7879e-04 - coeff_determination: 0.0248 - val_loss: 0.0029 - val_coeff_determination: -0.0785 - lr: 9.7656e-06\n",
            "Epoch 276/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0336\n",
            "Epoch 00276: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8144e-04 - coeff_determination: 0.0099 - val_loss: 0.0029 - val_coeff_determination: -0.0783 - lr: 9.7656e-06\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8087e-04 - coeff_determination: 0.0133 - val_loss: 0.0029 - val_coeff_determination: -0.0787 - lr: 4.8828e-06\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8580e-04 - coeff_determination: 0.0060 - val_loss: 0.0029 - val_coeff_determination: -0.0784 - lr: 4.8828e-06\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8466e-04 - coeff_determination: 0.0084 - val_loss: 0.0029 - val_coeff_determination: -0.0786 - lr: 4.8828e-06\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.8802e-04 - coeff_determination: 0.0033 - val_loss: 0.0029 - val_coeff_determination: -0.0786 - lr: 4.8828e-06\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9652e-04 - coeff_determination: -0.0076 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 4.8828e-06\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7852e-04 - coeff_determination: 0.0092 - val_loss: 0.0029 - val_coeff_determination: -0.0790 - lr: 4.8828e-06\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8923e-04 - coeff_determination: 0.0052 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 4.8828e-06\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8186e-04 - coeff_determination: 0.0110 - val_loss: 0.0029 - val_coeff_determination: -0.0791 - lr: 4.8828e-06\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 9.0083e-04 - coeff_determination: -0.0143 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 4.8828e-06\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9461e-04 - coeff_determination: -0.0098 - val_loss: 0.0029 - val_coeff_determination: -0.0792 - lr: 4.8828e-06\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8721e-04 - coeff_determination: 0.0080 - val_loss: 0.0029 - val_coeff_determination: -0.0789 - lr: 4.8828e-06\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9414e-04 - coeff_determination: 0.0022 - val_loss: 0.0029 - val_coeff_determination: -0.0787 - lr: 4.8828e-06\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9304e-04 - coeff_determination: 0.0044 - val_loss: 0.0029 - val_coeff_determination: -0.0785 - lr: 4.8828e-06\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9262e-04 - coeff_determination: 0.0027 - val_loss: 0.0029 - val_coeff_determination: -0.0784 - lr: 4.8828e-06\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9471e-04 - coeff_determination: -8.6327e-05 - val_loss: 0.0029 - val_coeff_determination: -0.0783 - lr: 4.8828e-06\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9090e-04 - coeff_determination: 0.0034 - val_loss: 0.0029 - val_coeff_determination: -0.0781 - lr: 4.8828e-06\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9204e-04 - coeff_determination: 0.0105 - val_loss: 0.0029 - val_coeff_determination: -0.0780 - lr: 4.8828e-06\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9206e-04 - coeff_determination: 0.0016 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 4.8828e-06\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8921e-04 - coeff_determination: 0.0042 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 4.8828e-06\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9058e-04 - coeff_determination: -6.8771e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 4.8828e-06\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9027e-04 - coeff_determination: 0.0037 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 4.8828e-06\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.9771e-04 - coeff_determination: -0.0113 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 4.8828e-06\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8465e-04 - coeff_determination: 0.0118 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 4.8828e-06\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8284e-04 - coeff_determination: 0.0178 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 4.8828e-06\n",
            "Epoch 301/500\n",
            " 1/18 [>.............................] - ETA: 0s - loss: 7.3296e-04 - coeff_determination: -0.0555\n",
            "Epoch 00301: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8754e-04 - coeff_determination: 6.6733e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 4.8828e-06\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8465e-04 - coeff_determination: 0.0099 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7004e-04 - coeff_determination: 0.0216 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 2.4414e-06\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 9.0329e-04 - coeff_determination: -0.0048 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8805e-04 - coeff_determination: 0.0103 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7734e-04 - coeff_determination: 0.0240 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8353e-04 - coeff_determination: 7.5916e-04 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7794e-04 - coeff_determination: 0.0115 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8442e-04 - coeff_determination: 0.0116 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 2.4414e-06\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.7408e-04 - coeff_determination: 0.0072 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8006e-04 - coeff_determination: 0.0167 - val_loss: 0.0029 - val_coeff_determination: -0.0779 - lr: 2.4414e-06\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8598e-04 - coeff_determination: 0.0047 - val_loss: 0.0029 - val_coeff_determination: -0.0775 - lr: 2.4414e-06\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.9066e-04 - coeff_determination: 0.0059 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 2.4414e-06\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8641e-04 - coeff_determination: 0.0140 - val_loss: 0.0029 - val_coeff_determination: -0.0777 - lr: 2.4414e-06\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 8.8722e-04 - coeff_determination: 0.0034 - val_loss: 0.0029 - val_coeff_determination: -0.0778 - lr: 2.4414e-06\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.9419e-04 - coeff_determination: 0.0012 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 2.4414e-06\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 8.8417e-04 - coeff_determination: 0.0154 - val_loss: 0.0029 - val_coeff_determination: -0.0776 - lr: 2.4414e-06\n"
          ]
        }
      ],
      "source": [
        "predictions_MLP = {}\n",
        "model = {}\n",
        "for i in range(2016,2022):\n",
        "\n",
        "  X_train = data.loc[(data.index.year >= i - 8) & (data.index.year < i - 1), allFeatures]\n",
        "  y_train = data.loc[(data.index.year >= i - 8) & (data.index.year < i - 1), 'BV_1w target']\n",
        "\n",
        "  X_valid = data.loc[data.index.year == i - 1, allFeatures]\n",
        "  y_valid = data.loc[data.index.year == i - 1, 'BV_1w target']\n",
        "\n",
        "  X_test = data.loc[data.index.year == i, allFeatures]\n",
        "  y_test = data.loc[data.index.year == i, 'BV_1w target']\n",
        "\n",
        "\n",
        "  model[i] = tf.keras.models.Sequential()\n",
        "  model[i].add(tf.keras.layers.Dense(units=X_train.shape[1], input_dim = X_train.shape[1], activation='sigmoid'))\n",
        "  model[i].add(tf.keras.layers.Dropout(0.1))\n",
        "  model[i].add(tf.keras.layers.Dense(units=12,  activation = 'sigmoid'))\n",
        "  model[i].add(tf.keras.layers.Dropout(0.1))\n",
        "  model[i].add(tf.keras.layers.Dense(units=6,  activation = 'sigmoid'))\n",
        "  model[i].add(tf.keras.layers.Dropout(0.1))\n",
        "  model[i].add(tf.keras.layers.Dense(1,  activation = 'linear'))\n",
        "\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, \n",
        "                                   verbose=1, mode='max', min_lr=0.000000001)\n",
        "  \n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200) \n",
        "\n",
        "  model[i].compile(tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse', metrics=coeff_determination)\n",
        "\n",
        "  model[i].fit(X_train, y_train,\n",
        "            validation_data=(X_valid, y_valid),\n",
        "            epochs=500,\n",
        "            batch_size=100,\n",
        "            shuffle=1,\n",
        "            callbacks = [reduce_lr, earlystop],\n",
        "            verbose=1)\n",
        "  predictions_MLP[i] = pd.DataFrame(model[i].predict(X_test), index=X_test.index, columns=['Predictions'])\n",
        "  predictions_MLP[i]['True'] = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  MLP R²: -0.05594158107159042\n",
            "  MLP MAE: 0.029505952615166343\n",
            "  MLP MSE: 0.0014465529307038406\n",
            "2017\n",
            "  MLP R²: -0.04511663854031478\n",
            "  MLP MAE: 0.01994083338940216\n",
            "  MLP MSE: 0.0006405594724980232\n",
            "2018\n",
            "  MLP R²: 0.0013363002613050456\n",
            "  MLP MAE: 0.02289047630432245\n",
            "  MLP MSE: 0.0008425551942570343\n",
            "2019\n",
            "  MLP R²: -0.02706835409136832\n",
            "  MLP MAE: 0.01864204758289544\n",
            "  MLP MSE: 0.0005157239636730135\n",
            "2020\n",
            "  MLP R²: 0.001261410590472467\n",
            "  MLP MAE: 0.03359681166046833\n",
            "  MLP MSE: 0.002896344788706889\n",
            "2021\n",
            "  MLP R²: -0.018414271148470274\n",
            "  MLP MAE: 0.01843628828703952\n",
            "  MLP MSE: 0.0005523052794139099\n"
          ]
        }
      ],
      "source": [
        "for i in predictions_MLP.keys():\n",
        "  print(i)\n",
        "  print('  MLP R²: {}'.format(r2_score(predictions_MLP[i]['True'],predictions_MLP[i]['Predictions'])))\n",
        "  print('  MLP MAE: {}'.format(mean_absolute_error(predictions_MLP[i]['True'],predictions_MLP[i]['Predictions'])))\n",
        "  print('  MLP MSE: {}'.format(mean_squared_error(predictions_MLP[i]['True'],predictions_MLP[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_MLP = {}\n",
        "for i in predictions_MLP.keys():\n",
        "  classification_MLP[i] = predictions_MLP[i].applymap(lambda x: 0 if x < 0 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  MLP F1: 0.4032921810699588\n",
            "  MLP Accu: 0.41767068273092367\n",
            "  MLP precision: 0.5444444444444444\n",
            "  MLP recall: 0.3202614379084967\n",
            "2017\n",
            "  MLP F1: 0.3033707865168539\n",
            "  MLP Accu: 0.4979757085020243\n",
            "  MLP precision: 0.8709677419354839\n",
            "  MLP recall: 0.1836734693877551\n",
            "2018\n",
            "  MLP F1: 0.5338345864661654\n",
            "  MLP Accu: 0.4918032786885246\n",
            "  MLP precision: 0.5461538461538461\n",
            "  MLP recall: 0.5220588235294118\n",
            "2019\n",
            "  MLP F1: 0.53125\n",
            "  MLP Accu: 0.5141700404858299\n",
            "  MLP precision: 0.7157894736842105\n",
            "  MLP recall: 0.422360248447205\n",
            "2020\n",
            "  MLP F1: 0.7461928934010152\n",
            "  MLP Accu: 0.5951417004048583\n",
            "  MLP precision: 0.5951417004048583\n",
            "  MLP recall: 1.0\n",
            "2021\n",
            "  MLP F1: 0.5333333333333333\n",
            "  MLP Accu: 0.5625\n",
            "  MLP precision: 0.5098039215686274\n",
            "  MLP recall: 0.5591397849462365\n"
          ]
        }
      ],
      "source": [
        "for i in classification_MLP.keys():\n",
        "  print(i)\n",
        "  print('  MLP F1: {}'.format(f1_score(classification_MLP[i]['True'],classification_MLP[i]['Predictions'])))\n",
        "  print('  MLP Accu: {}'.format(accuracy_score(classification_MLP[i]['True'],classification_MLP[i]['Predictions'])))\n",
        "  print('  MLP precision: {}'.format(precision_score(classification_MLP[i]['True'],classification_MLP[i]['Predictions'])))\n",
        "  print('  MLP recall: {}'.format(recall_score(classification_MLP[i]['True'],classification_MLP[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016: patrimonio final long-only: 88.77457115503086, long-short: 52.5774933931971\n",
            "2017: patrimonio final long-only: 112.68068226894087, long-short: 101.26024772048723\n",
            "2018: patrimonio final long-only: 113.40443492481492, long-short: 105.60372906605878\n",
            "2019: patrimonio final long-only: 129.4756982158322, long-short: 125.16972688176169\n",
            "2020: patrimonio final long-only: 106.78916627093129, long-short: 106.78916627093129\n",
            "2021: patrimonio final long-only: 101.16003327536838, long-short: 114.68713205358931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-f341c5515776>:2: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  classification_MLP[i]['week'] = classification_MLP[i].index.week\n"
          ]
        }
      ],
      "source": [
        "for i in classification_MLP.keys():\n",
        "  classification_MLP[i]['week'] = classification_MLP[i].index.week\n",
        "  classification_MLP[i]['True'] = predictions_MLP[i]['True'] + 1\n",
        "  result = classification_MLP[i].groupby('week', as_index=False).first()\n",
        "  patrimonio = 100\n",
        "  patrimonio2 = 100\n",
        "  for j in result.index:\n",
        "    if result.loc[j, 'Predictions'] == 1:\n",
        "      patrimonio *= result.loc[j, 'True']\n",
        "      patrimonio2 *= result.loc[j, 'True']\n",
        "    else:\n",
        "      patrimonio2 *= 2 - result.loc[j, 'True']\n",
        "  print('{}: patrimonio final long-only: {}, long-short: {}'.format(i, patrimonio, patrimonio2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "skuYOpmN0eo2"
      },
      "outputs": [],
      "source": [
        "lookback = 50\n",
        "data_lstm = pd.DataFrame(columns=allFeatures + ['BV_1w target'], dtype=object)\n",
        "for index in data.index[50:]:\n",
        "  for column in data[allFeatures + ['BV_1w target']].columns:\n",
        "    position = data.index.get_loc(index)\n",
        "    data_lstm.at[index, column] = data[column].iloc[position - 49: position + 1].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ityua6sosLrs",
        "outputId": "33315ea2-458b-4afb-a2f0-e56b7697ebdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 74ms/step - loss: 0.1157 - coeff_determination: -73.0774 - val_loss: 0.0056 - val_coeff_determination: -3.9664 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0060 - coeff_determination: -3.0137 - val_loss: 0.0019 - val_coeff_determination: -0.7488 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0036 - coeff_determination: -1.4033 - val_loss: 0.0014 - val_coeff_determination: -0.3146 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0024 - coeff_determination: -0.6460 - val_loss: 0.0012 - val_coeff_determination: -0.1223 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0019 - coeff_determination: -0.3176 - val_loss: 0.0012 - val_coeff_determination: -0.0657 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0017 - coeff_determination: -0.1665 - val_loss: 0.0011 - val_coeff_determination: -0.0551 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0016 - coeff_determination: -0.1045 - val_loss: 0.0011 - val_coeff_determination: -0.0342 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0016 - coeff_determination: -0.0694 - val_loss: 0.0011 - val_coeff_determination: -0.0324 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0517 - val_loss: 0.0011 - val_coeff_determination: -0.0234 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0427 - val_loss: 0.0011 - val_coeff_determination: -0.0193 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0329\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0329 - val_loss: 0.0011 - val_coeff_determination: -0.0208 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0291 - val_loss: 0.0011 - val_coeff_determination: -0.0172 - lr: 0.0500\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0255 - val_loss: 0.0011 - val_coeff_determination: -0.0185 - lr: 0.0500\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0229 - val_loss: 0.0011 - val_coeff_determination: -0.0161 - lr: 0.0500\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0219 - val_loss: 0.0011 - val_coeff_determination: -0.0164 - lr: 0.0500\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0199 - val_loss: 0.0011 - val_coeff_determination: -0.0159 - lr: 0.0500\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0175 - val_loss: 0.0011 - val_coeff_determination: -0.0146 - lr: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0192 - val_loss: 0.0011 - val_coeff_determination: -0.0134 - lr: 0.0500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0157 - val_loss: 0.0011 - val_coeff_determination: -0.0152 - lr: 0.0500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0174 - val_loss: 0.0011 - val_coeff_determination: -0.0120 - lr: 0.0500\n",
            "Epoch 21/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0161\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0161 - val_loss: 0.0011 - val_coeff_determination: -0.0165 - lr: 0.0500\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0151 - val_loss: 0.0011 - val_coeff_determination: -0.0128 - lr: 0.0250\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0151 - val_loss: 0.0011 - val_coeff_determination: -0.0123 - lr: 0.0250\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0146 - val_loss: 0.0011 - val_coeff_determination: -0.0127 - lr: 0.0250\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0015 - coeff_determination: -0.0128 - val_loss: 0.0011 - val_coeff_determination: -0.0124 - lr: 0.0250\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0015 - coeff_determination: -0.0123 - val_loss: 0.0011 - val_coeff_determination: -0.0120 - lr: 0.0250\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0129 - val_loss: 0.0011 - val_coeff_determination: -0.0122 - lr: 0.0250\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0117 - val_loss: 0.0011 - val_coeff_determination: -0.0115 - lr: 0.0250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0113 - val_loss: 0.0011 - val_coeff_determination: -0.0124 - lr: 0.0250\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0110 - val_loss: 0.0011 - val_coeff_determination: -0.0113 - lr: 0.0250\n",
            "Epoch 31/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0119\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0117 - val_loss: 0.0011 - val_coeff_determination: -0.0108 - lr: 0.0250\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0108 - val_loss: 0.0011 - val_coeff_determination: -0.0119 - lr: 0.0125\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.0114 - val_loss: 0.0011 - val_coeff_determination: -0.0103 - lr: 0.0125\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0105 - val_loss: 0.0011 - val_coeff_determination: -0.0117 - lr: 0.0125\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0108 - val_loss: 0.0011 - val_coeff_determination: -0.0111 - lr: 0.0125\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0015 - coeff_determination: -0.0085 - val_loss: 0.0011 - val_coeff_determination: -0.0106 - lr: 0.0125\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.0097 - val_loss: 0.0011 - val_coeff_determination: -0.0103 - lr: 0.0125\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0095 - val_loss: 0.0011 - val_coeff_determination: -0.0114 - lr: 0.0125\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0092 - val_loss: 0.0011 - val_coeff_determination: -0.0112 - lr: 0.0125\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0108 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0125\n",
            "Epoch 41/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.0102\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0093 - val_loss: 0.0011 - val_coeff_determination: -0.0109 - lr: 0.0125\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0089 - val_loss: 0.0011 - val_coeff_determination: -0.0109 - lr: 0.0063\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0102 - val_loss: 0.0011 - val_coeff_determination: -0.0101 - lr: 0.0063\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0097 - val_loss: 0.0011 - val_coeff_determination: -0.0104 - lr: 0.0063\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0103 - val_loss: 0.0011 - val_coeff_determination: -0.0107 - lr: 0.0063\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0095 - val_loss: 0.0011 - val_coeff_determination: -0.0104 - lr: 0.0063\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0101 - val_loss: 0.0011 - val_coeff_determination: -0.0105 - lr: 0.0063\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0088 - val_loss: 0.0011 - val_coeff_determination: -0.0103 - lr: 0.0063\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0088 - val_loss: 0.0011 - val_coeff_determination: -0.0108 - lr: 0.0063\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0089 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0063\n",
            "Epoch 51/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0081\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0085 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0063\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0081 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0031\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0088 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0031\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0089 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0031\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0095 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 0.0031\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0075 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0031\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0088 - val_loss: 0.0011 - val_coeff_determination: -0.0103 - lr: 0.0031\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0085 - val_loss: 0.0011 - val_coeff_determination: -0.0103 - lr: 0.0031\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0073 - val_loss: 0.0011 - val_coeff_determination: -0.0105 - lr: 0.0031\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0085 - val_loss: 0.0011 - val_coeff_determination: -0.0104 - lr: 0.0031\n",
            "Epoch 61/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.0085\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0085 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 0.0031\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0077 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 0.0016\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0077 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 0.0016\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0083 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 0.0016\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0089 - val_loss: 0.0011 - val_coeff_determination: -0.0101 - lr: 0.0016\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.0080 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0016\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0080 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 0.0016\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0082 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 0.0016\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0074 - val_loss: 0.0011 - val_coeff_determination: -0.0102 - lr: 0.0016\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0081 - val_loss: 0.0011 - val_coeff_determination: -0.0101 - lr: 0.0016\n",
            "Epoch 71/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0090\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0083 - val_loss: 0.0011 - val_coeff_determination: -0.0101 - lr: 0.0016\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0086 - val_loss: 0.0011 - val_coeff_determination: -0.0101 - lr: 7.8125e-04\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0091 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 7.8125e-04\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0082 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 7.8125e-04\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0074 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 7.8125e-04\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0063 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 7.8125e-04\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0094 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 7.8125e-04\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0073 - val_loss: 0.0011 - val_coeff_determination: -0.0098 - lr: 7.8125e-04\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0068 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 7.8125e-04\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0083 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 7.8125e-04\n",
            "Epoch 81/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0080\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0080 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 7.8125e-04\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0083 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 3.9063e-04\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0082 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 3.9063e-04\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0088 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 3.9063e-04\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0080 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 3.9063e-04\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0079 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 3.9063e-04\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0065 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 3.9063e-04\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0079 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 3.9063e-04\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0076 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 3.9063e-04\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.0093 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 3.9063e-04\n",
            "Epoch 91/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0081\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0084 - val_loss: 0.0011 - val_coeff_determination: -0.0100 - lr: 3.9063e-04\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0082 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0080 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0086 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0086 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0075 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0081 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.0078 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0078 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.0080 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 101/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0014 - coeff_determination: -0.0074\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 9.765625145519152e-05.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0071 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 1.9531e-04\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0069 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0100 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0015 - coeff_determination: -0.0072 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0070 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0097 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0074 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0073 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0015 - coeff_determination: -0.0074 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0015 - coeff_determination: -0.0077 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 111/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0015 - coeff_determination: -0.0080\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.882812572759576e-05.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.0074 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 9.7656e-05\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.0078 - val_loss: 0.0011 - val_coeff_determination: -0.0099 - lr: 4.8828e-05\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 75ms/step - loss: 0.2015 - coeff_determination: -177.2147 - val_loss: 0.0041 - val_coeff_determination: -3.3086 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0094 - coeff_determination: -7.5465 - val_loss: 0.0031 - val_coeff_determination: -1.6665 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0035 - coeff_determination: -2.2046 - val_loss: 0.0017 - val_coeff_determination: -0.4234 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0026 - coeff_determination: -1.3590 - val_loss: 0.0017 - val_coeff_determination: -0.3788 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0019 - coeff_determination: -0.7192 - val_loss: 0.0014 - val_coeff_determination: -0.0699 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.3754 - val_loss: 0.0015 - val_coeff_determination: -0.0959 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0014 - coeff_determination: -0.2591 - val_loss: 0.0014 - val_coeff_determination: -0.0595 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0013 - coeff_determination: -0.1693 - val_loss: 0.0014 - val_coeff_determination: -0.0532 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.1268 - val_loss: 0.0014 - val_coeff_determination: -0.0438 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.1017 - val_loss: 0.0014 - val_coeff_determination: -0.0443 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0012 - coeff_determination: -0.0827\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.0831 - val_loss: 0.0014 - val_coeff_determination: -0.0483 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.0744 - val_loss: 0.0014 - val_coeff_determination: -0.0430 - lr: 0.0500\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.0672 - val_loss: 0.0014 - val_coeff_determination: -0.0421 - lr: 0.0500\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.0685 - val_loss: 0.0014 - val_coeff_determination: -0.0374 - lr: 0.0500\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.0608 - val_loss: 0.0014 - val_coeff_determination: -0.0388 - lr: 0.0500\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0012 - coeff_determination: -0.0586 - val_loss: 0.0014 - val_coeff_determination: -0.0372 - lr: 0.0500\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0011 - coeff_determination: -0.0530 - val_loss: 0.0014 - val_coeff_determination: -0.0379 - lr: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0516 - val_loss: 0.0014 - val_coeff_determination: -0.0360 - lr: 0.0500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0478 - val_loss: 0.0014 - val_coeff_determination: -0.0333 - lr: 0.0500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0432 - val_loss: 0.0014 - val_coeff_determination: -0.0351 - lr: 0.0500\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0424\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0011 - coeff_determination: -0.0424 - val_loss: 0.0014 - val_coeff_determination: -0.0327 - lr: 0.0500\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0401 - val_loss: 0.0014 - val_coeff_determination: -0.0328 - lr: 0.0250\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0400 - val_loss: 0.0014 - val_coeff_determination: -0.0324 - lr: 0.0250\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0011 - coeff_determination: -0.0396 - val_loss: 0.0014 - val_coeff_determination: -0.0316 - lr: 0.0250\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0378 - val_loss: 0.0014 - val_coeff_determination: -0.0308 - lr: 0.0250\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0358 - val_loss: 0.0014 - val_coeff_determination: -0.0323 - lr: 0.0250\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0369 - val_loss: 0.0014 - val_coeff_determination: -0.0308 - lr: 0.0250\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0331 - val_loss: 0.0014 - val_coeff_determination: -0.0307 - lr: 0.0250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0329 - val_loss: 0.0014 - val_coeff_determination: -0.0316 - lr: 0.0250\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0344 - val_loss: 0.0014 - val_coeff_determination: -0.0295 - lr: 0.0250\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0319\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0319 - val_loss: 0.0014 - val_coeff_determination: -0.0297 - lr: 0.0250\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0311 - val_loss: 0.0014 - val_coeff_determination: -0.0305 - lr: 0.0125\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0305 - val_loss: 0.0014 - val_coeff_determination: -0.0304 - lr: 0.0125\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0301 - val_loss: 0.0014 - val_coeff_determination: -0.0274 - lr: 0.0125\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0298 - val_loss: 0.0014 - val_coeff_determination: -0.0302 - lr: 0.0125\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0289 - val_loss: 0.0014 - val_coeff_determination: -0.0296 - lr: 0.0125\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0011 - coeff_determination: -0.0276 - val_loss: 0.0014 - val_coeff_determination: -0.0278 - lr: 0.0125\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0307 - val_loss: 0.0014 - val_coeff_determination: -0.0280 - lr: 0.0125\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0270 - val_loss: 0.0014 - val_coeff_determination: -0.0295 - lr: 0.0125\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0265 - val_loss: 0.0014 - val_coeff_determination: -0.0278 - lr: 0.0125\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0264\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0264 - val_loss: 0.0014 - val_coeff_determination: -0.0282 - lr: 0.0125\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0253 - val_loss: 0.0014 - val_coeff_determination: -0.0285 - lr: 0.0063\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0280 - val_loss: 0.0014 - val_coeff_determination: -0.0283 - lr: 0.0063\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0250 - val_loss: 0.0014 - val_coeff_determination: -0.0275 - lr: 0.0063\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0269 - val_loss: 0.0014 - val_coeff_determination: -0.0272 - lr: 0.0063\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0262 - val_loss: 0.0014 - val_coeff_determination: -0.0282 - lr: 0.0063\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0259 - val_loss: 0.0014 - val_coeff_determination: -0.0281 - lr: 0.0063\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0253 - val_loss: 0.0014 - val_coeff_determination: -0.0276 - lr: 0.0063\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0249 - val_loss: 0.0014 - val_coeff_determination: -0.0272 - lr: 0.0063\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0258 - val_loss: 0.0014 - val_coeff_determination: -0.0265 - lr: 0.0063\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0250\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0250 - val_loss: 0.0014 - val_coeff_determination: -0.0284 - lr: 0.0063\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0251 - val_loss: 0.0014 - val_coeff_determination: -0.0286 - lr: 0.0031\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0247 - val_loss: 0.0014 - val_coeff_determination: -0.0276 - lr: 0.0031\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0265 - val_loss: 0.0014 - val_coeff_determination: -0.0273 - lr: 0.0031\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0255 - val_loss: 0.0014 - val_coeff_determination: -0.0267 - lr: 0.0031\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0253 - val_loss: 0.0014 - val_coeff_determination: -0.0271 - lr: 0.0031\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0247 - val_loss: 0.0014 - val_coeff_determination: -0.0273 - lr: 0.0031\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0255 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 0.0031\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0238 - val_loss: 0.0014 - val_coeff_determination: -0.0275 - lr: 0.0031\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0244 - val_loss: 0.0014 - val_coeff_determination: -0.0272 - lr: 0.0031\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0248\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0248 - val_loss: 0.0014 - val_coeff_determination: -0.0270 - lr: 0.0031\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0252 - val_loss: 0.0014 - val_coeff_determination: -0.0271 - lr: 0.0016\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0238 - val_loss: 0.0014 - val_coeff_determination: -0.0273 - lr: 0.0016\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0241 - val_loss: 0.0014 - val_coeff_determination: -0.0273 - lr: 0.0016\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0229 - val_loss: 0.0014 - val_coeff_determination: -0.0271 - lr: 0.0016\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0219 - val_loss: 0.0014 - val_coeff_determination: -0.0269 - lr: 0.0016\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0241 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 0.0016\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0242 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 0.0016\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0245 - val_loss: 0.0014 - val_coeff_determination: -0.0269 - lr: 0.0016\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0011 - coeff_determination: -0.0241 - val_loss: 0.0014 - val_coeff_determination: -0.0270 - lr: 0.0016\n",
            "Epoch 71/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0221\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0223 - val_loss: 0.0014 - val_coeff_determination: -0.0267 - lr: 0.0016\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0233 - val_loss: 0.0014 - val_coeff_determination: -0.0267 - lr: 7.8125e-04\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0242 - val_loss: 0.0014 - val_coeff_determination: -0.0267 - lr: 7.8125e-04\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0238 - val_loss: 0.0014 - val_coeff_determination: -0.0269 - lr: 7.8125e-04\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0011 - coeff_determination: -0.0228 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 7.8125e-04\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0245 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 7.8125e-04\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0231 - val_loss: 0.0014 - val_coeff_determination: -0.0269 - lr: 7.8125e-04\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0228 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 7.8125e-04\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0232 - val_loss: 0.0014 - val_coeff_determination: -0.0267 - lr: 7.8125e-04\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0228 - val_loss: 0.0014 - val_coeff_determination: -0.0267 - lr: 7.8125e-04\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0222\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0222 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 7.8125e-04\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0235 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 3.9063e-04\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0011 - coeff_determination: -0.0249 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 3.9063e-04\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0011 - coeff_determination: -0.0230 - val_loss: 0.0014 - val_coeff_determination: -0.0268 - lr: 3.9063e-04\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 75ms/step - loss: 0.1046 - coeff_determination: -102.7291 - val_loss: 0.0019 - val_coeff_determination: -2.4127 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0056 - coeff_determination: -4.4779 - val_loss: 9.5949e-04 - val_coeff_determination: -0.5852 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0032 - coeff_determination: -2.1287 - val_loss: 8.4639e-04 - val_coeff_determination: -0.4255 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0022 - coeff_determination: -1.2079 - val_loss: 7.7545e-04 - val_coeff_determination: -0.1836 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0018 - coeff_determination: -0.7275 - val_loss: 7.0493e-04 - val_coeff_determination: -0.1318 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0015 - coeff_determination: -0.4849 - val_loss: 7.0854e-04 - val_coeff_determination: -0.0968 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0013 - coeff_determination: -0.3272 - val_loss: 6.8976e-04 - val_coeff_determination: -0.0799 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0013 - coeff_determination: -0.2380 - val_loss: 6.8866e-04 - val_coeff_determination: -0.0683 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0012 - coeff_determination: -0.1765 - val_loss: 6.8929e-04 - val_coeff_determination: -0.0634 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0012 - coeff_determination: -0.1425 - val_loss: 6.7867e-04 - val_coeff_determination: -0.0525 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.1189\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.1176 - val_loss: 6.9007e-04 - val_coeff_determination: -0.0565 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0974 - val_loss: 6.7886e-04 - val_coeff_determination: -0.0458 - lr: 0.0500\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0011 - coeff_determination: -0.0896 - val_loss: 6.7905e-04 - val_coeff_determination: -0.0443 - lr: 0.0500\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0801 - val_loss: 6.8059e-04 - val_coeff_determination: -0.0440 - lr: 0.0500\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0778 - val_loss: 6.7686e-04 - val_coeff_determination: -0.0400 - lr: 0.0500\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0011 - coeff_determination: -0.0684 - val_loss: 6.8085e-04 - val_coeff_determination: -0.0419 - lr: 0.0500\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0637 - val_loss: 6.7710e-04 - val_coeff_determination: -0.0378 - lr: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.0577 - val_loss: 6.7819e-04 - val_coeff_determination: -0.0376 - lr: 0.0500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0011 - coeff_determination: -0.0547 - val_loss: 6.7708e-04 - val_coeff_determination: -0.0358 - lr: 0.0500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0511 - val_loss: 6.7916e-04 - val_coeff_determination: -0.0367 - lr: 0.0500\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0495\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0495 - val_loss: 6.7646e-04 - val_coeff_determination: -0.0337 - lr: 0.0500\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0428 - val_loss: 6.7809e-04 - val_coeff_determination: -0.0347 - lr: 0.0250\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0453 - val_loss: 6.7617e-04 - val_coeff_determination: -0.0327 - lr: 0.0250\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0419 - val_loss: 6.7526e-04 - val_coeff_determination: -0.0317 - lr: 0.0250\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0386 - val_loss: 6.7867e-04 - val_coeff_determination: -0.0342 - lr: 0.0250\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0387 - val_loss: 6.7552e-04 - val_coeff_determination: -0.0312 - lr: 0.0250\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0364 - val_loss: 6.7674e-04 - val_coeff_determination: -0.0319 - lr: 0.0250\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0381 - val_loss: 6.7594e-04 - val_coeff_determination: -0.0309 - lr: 0.0250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0375 - val_loss: 6.7727e-04 - val_coeff_determination: -0.0317 - lr: 0.0250\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0334 - val_loss: 6.7433e-04 - val_coeff_determination: -0.0290 - lr: 0.0250\n",
            "Epoch 31/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0328\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0317 - val_loss: 6.7692e-04 - val_coeff_determination: -0.0308 - lr: 0.0250\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.0350 - val_loss: 6.7630e-04 - val_coeff_determination: -0.0301 - lr: 0.0125\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0310 - val_loss: 6.7491e-04 - val_coeff_determination: -0.0289 - lr: 0.0125\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0321 - val_loss: 6.7541e-04 - val_coeff_determination: -0.0291 - lr: 0.0125\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0294 - val_loss: 6.7699e-04 - val_coeff_determination: -0.0303 - lr: 0.0125\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0313 - val_loss: 6.7586e-04 - val_coeff_determination: -0.0293 - lr: 0.0125\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0301 - val_loss: 6.7574e-04 - val_coeff_determination: -0.0290 - lr: 0.0125\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0300 - val_loss: 6.7562e-04 - val_coeff_determination: -0.0288 - lr: 0.0125\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0281 - val_loss: 6.7532e-04 - val_coeff_determination: -0.0284 - lr: 0.0125\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0299 - val_loss: 6.7637e-04 - val_coeff_determination: -0.0292 - lr: 0.0125\n",
            "Epoch 41/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0011 - coeff_determination: -0.0280\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0278 - val_loss: 6.7532e-04 - val_coeff_determination: -0.0282 - lr: 0.0125\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0283 - val_loss: 6.7526e-04 - val_coeff_determination: -0.0281 - lr: 0.0063\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0287 - val_loss: 6.7559e-04 - val_coeff_determination: -0.0283 - lr: 0.0063\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0279 - val_loss: 6.7582e-04 - val_coeff_determination: -0.0284 - lr: 0.0063\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0278 - val_loss: 6.7588e-04 - val_coeff_determination: -0.0284 - lr: 0.0063\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0271 - val_loss: 6.7588e-04 - val_coeff_determination: -0.0284 - lr: 0.0063\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0241 - val_loss: 6.7498e-04 - val_coeff_determination: -0.0276 - lr: 0.0063\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0254 - val_loss: 6.7578e-04 - val_coeff_determination: -0.0282 - lr: 0.0063\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0256 - val_loss: 6.7527e-04 - val_coeff_determination: -0.0277 - lr: 0.0063\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0251 - val_loss: 6.7517e-04 - val_coeff_determination: -0.0275 - lr: 0.0063\n",
            "Epoch 51/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0244\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0241 - val_loss: 6.7543e-04 - val_coeff_determination: -0.0277 - lr: 0.0063\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0264 - val_loss: 6.7604e-04 - val_coeff_determination: -0.0282 - lr: 0.0031\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0258 - val_loss: 6.7551e-04 - val_coeff_determination: -0.0277 - lr: 0.0031\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0259 - val_loss: 6.7548e-04 - val_coeff_determination: -0.0277 - lr: 0.0031\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0248 - val_loss: 6.7520e-04 - val_coeff_determination: -0.0274 - lr: 0.0031\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0010 - coeff_determination: -0.0243 - val_loss: 6.7496e-04 - val_coeff_determination: -0.0272 - lr: 0.0031\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0010 - coeff_determination: -0.0261 - val_loss: 6.7576e-04 - val_coeff_determination: -0.0278 - lr: 0.0031\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0245 - val_loss: 6.7538e-04 - val_coeff_determination: -0.0274 - lr: 0.0031\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0254 - val_loss: 6.7560e-04 - val_coeff_determination: -0.0276 - lr: 0.0031\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0259 - val_loss: 6.7485e-04 - val_coeff_determination: -0.0270 - lr: 0.0031\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0233\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0233 - val_loss: 6.7534e-04 - val_coeff_determination: -0.0273 - lr: 0.0031\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0246 - val_loss: 6.7524e-04 - val_coeff_determination: -0.0272 - lr: 0.0016\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0240 - val_loss: 6.7538e-04 - val_coeff_determination: -0.0273 - lr: 0.0016\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0229 - val_loss: 6.7548e-04 - val_coeff_determination: -0.0274 - lr: 0.0016\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0010 - coeff_determination: -0.0239 - val_loss: 6.7556e-04 - val_coeff_determination: -0.0275 - lr: 0.0016\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0271 - val_loss: 6.7571e-04 - val_coeff_determination: -0.0276 - lr: 0.0016\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0242 - val_loss: 6.7580e-04 - val_coeff_determination: -0.0276 - lr: 0.0016\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0247 - val_loss: 6.7567e-04 - val_coeff_determination: -0.0275 - lr: 0.0016\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0241 - val_loss: 6.7565e-04 - val_coeff_determination: -0.0275 - lr: 0.0016\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0254 - val_loss: 6.7561e-04 - val_coeff_determination: -0.0274 - lr: 0.0016\n",
            "Epoch 71/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0253\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0240 - val_loss: 6.7541e-04 - val_coeff_determination: -0.0272 - lr: 0.0016\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0258 - val_loss: 6.7524e-04 - val_coeff_determination: -0.0271 - lr: 7.8125e-04\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0229 - val_loss: 6.7521e-04 - val_coeff_determination: -0.0271 - lr: 7.8125e-04\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0233 - val_loss: 6.7542e-04 - val_coeff_determination: -0.0272 - lr: 7.8125e-04\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0228 - val_loss: 6.7542e-04 - val_coeff_determination: -0.0272 - lr: 7.8125e-04\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0217 - val_loss: 6.7541e-04 - val_coeff_determination: -0.0272 - lr: 7.8125e-04\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0243 - val_loss: 6.7531e-04 - val_coeff_determination: -0.0271 - lr: 7.8125e-04\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0229 - val_loss: 6.7536e-04 - val_coeff_determination: -0.0271 - lr: 7.8125e-04\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0230 - val_loss: 6.7533e-04 - val_coeff_determination: -0.0271 - lr: 7.8125e-04\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0236 - val_loss: 6.7523e-04 - val_coeff_determination: -0.0270 - lr: 7.8125e-04\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 3s 80ms/step - loss: 0.0404 - coeff_determination: -39.8526 - val_loss: 0.0016 - val_coeff_determination: -1.0465 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0033 - coeff_determination: -2.2719 - val_loss: 0.0010 - val_coeff_determination: -0.3222 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0016 - coeff_determination: -0.6326 - val_loss: 8.5414e-04 - val_coeff_determination: -0.1207 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0012 - coeff_determination: -0.1976 - val_loss: 8.3365e-04 - val_coeff_determination: -0.0963 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0953 - val_loss: 8.1294e-04 - val_coeff_determination: -0.0535 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.0562 - val_loss: 8.1754e-04 - val_coeff_determination: -0.0728 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0378 - val_loss: 8.1013e-04 - val_coeff_determination: -0.0555 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0301 - val_loss: 8.1249e-04 - val_coeff_determination: -0.0630 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0244 - val_loss: 8.1444e-04 - val_coeff_determination: -0.0683 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0225 - val_loss: 8.0749e-04 - val_coeff_determination: -0.0499 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0211\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0211 - val_loss: 8.1919e-04 - val_coeff_determination: -0.0800 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0190 - val_loss: 8.0757e-04 - val_coeff_determination: -0.0517 - lr: 0.0500\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0190 - val_loss: 8.1153e-04 - val_coeff_determination: -0.0630 - lr: 0.0500\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0165 - val_loss: 8.1166e-04 - val_coeff_determination: -0.0633 - lr: 0.0500\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0167 - val_loss: 8.0721e-04 - val_coeff_determination: -0.0508 - lr: 0.0500\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0138 - val_loss: 8.1010e-04 - val_coeff_determination: -0.0596 - lr: 0.0500\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0130 - val_loss: 8.1276e-04 - val_coeff_determination: -0.0663 - lr: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0134 - val_loss: 8.1031e-04 - val_coeff_determination: -0.0602 - lr: 0.0500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0138 - val_loss: 8.1509e-04 - val_coeff_determination: -0.0719 - lr: 0.0500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0116 - val_loss: 8.0662e-04 - val_coeff_determination: -0.0490 - lr: 0.0500\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0127\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0127 - val_loss: 8.1402e-04 - val_coeff_determination: -0.0696 - lr: 0.0500\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0107 - val_loss: 8.0845e-04 - val_coeff_determination: -0.0553 - lr: 0.0250\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0010 - coeff_determination: -0.0116 - val_loss: 8.1214e-04 - val_coeff_determination: -0.0652 - lr: 0.0250\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0110 - val_loss: 8.0945e-04 - val_coeff_determination: -0.0583 - lr: 0.0250\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0110 - val_loss: 8.0972e-04 - val_coeff_determination: -0.0592 - lr: 0.0250\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0095 - val_loss: 8.1079e-04 - val_coeff_determination: -0.0621 - lr: 0.0250\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0112 - val_loss: 8.0980e-04 - val_coeff_determination: -0.0595 - lr: 0.0250\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0104 - val_loss: 8.0972e-04 - val_coeff_determination: -0.0594 - lr: 0.0250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0105 - val_loss: 8.1156e-04 - val_coeff_determination: -0.0642 - lr: 0.0250\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0096 - val_loss: 8.0945e-04 - val_coeff_determination: -0.0587 - lr: 0.0250\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0093\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0093 - val_loss: 8.1009e-04 - val_coeff_determination: -0.0604 - lr: 0.0250\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0095 - val_loss: 8.1025e-04 - val_coeff_determination: -0.0609 - lr: 0.0125\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0095 - val_loss: 8.1044e-04 - val_coeff_determination: -0.0614 - lr: 0.0125\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0104 - val_loss: 8.1028e-04 - val_coeff_determination: -0.0610 - lr: 0.0125\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.0010 - coeff_determination: -0.0100 - val_loss: 8.0913e-04 - val_coeff_determination: -0.0579 - lr: 0.0125\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.0010 - coeff_determination: -0.0098 - val_loss: 8.0999e-04 - val_coeff_determination: -0.0603 - lr: 0.0125\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0010 - coeff_determination: -0.0092 - val_loss: 8.0923e-04 - val_coeff_determination: -0.0582 - lr: 0.0125\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.0010 - coeff_determination: -0.0089 - val_loss: 8.1089e-04 - val_coeff_determination: -0.0627 - lr: 0.0125\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0010 - coeff_determination: -0.0098 - val_loss: 8.0934e-04 - val_coeff_determination: -0.0586 - lr: 0.0125\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0092 - val_loss: 8.1041e-04 - val_coeff_determination: -0.0616 - lr: 0.0125\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0083    \n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.0010 - coeff_determination: -0.0083 - val_loss: 8.1025e-04 - val_coeff_determination: -0.0612 - lr: 0.0125\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0010 - coeff_determination: -0.0078 - val_loss: 8.1033e-04 - val_coeff_determination: -0.0614 - lr: 0.0063\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0079 - val_loss: 8.0908e-04 - val_coeff_determination: -0.0580 - lr: 0.0063\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0099 - val_loss: 8.0956e-04 - val_coeff_determination: -0.0593 - lr: 0.0063\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0085 - val_loss: 8.1117e-04 - val_coeff_determination: -0.0635 - lr: 0.0063\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0092 - val_loss: 8.0926e-04 - val_coeff_determination: -0.0585 - lr: 0.0063\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0071 - val_loss: 8.0920e-04 - val_coeff_determination: -0.0584 - lr: 0.0063\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0080 - val_loss: 8.1032e-04 - val_coeff_determination: -0.0614 - lr: 0.0063\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0010 - coeff_determination: -0.0082 - val_loss: 8.0957e-04 - val_coeff_determination: -0.0594 - lr: 0.0063\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0083 - val_loss: 8.0969e-04 - val_coeff_determination: -0.0597 - lr: 0.0063\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0080    \n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0080 - val_loss: 8.0944e-04 - val_coeff_determination: -0.0590 - lr: 0.0063\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0072 - val_loss: 8.0979e-04 - val_coeff_determination: -0.0600 - lr: 0.0031\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0081 - val_loss: 8.0995e-04 - val_coeff_determination: -0.0604 - lr: 0.0031\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0089 - val_loss: 8.0955e-04 - val_coeff_determination: -0.0593 - lr: 0.0031\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0010 - coeff_determination: -0.0072 - val_loss: 8.1031e-04 - val_coeff_determination: -0.0614 - lr: 0.0031\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.0010 - coeff_determination: -0.0086 - val_loss: 8.0980e-04 - val_coeff_determination: -0.0600 - lr: 0.0031\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0010 - coeff_determination: -0.0084 - val_loss: 8.0950e-04 - val_coeff_determination: -0.0592 - lr: 0.0031\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.0010 - coeff_determination: -0.0086 - val_loss: 8.0947e-04 - val_coeff_determination: -0.0592 - lr: 0.0031\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0010 - coeff_determination: -0.0075 - val_loss: 8.1001e-04 - val_coeff_determination: -0.0606 - lr: 0.0031\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0010 - coeff_determination: -0.0079 - val_loss: 8.0971e-04 - val_coeff_determination: -0.0598 - lr: 0.0031\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0010 - coeff_determination: -0.0078\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.0010 - coeff_determination: -0.0078 - val_loss: 8.1072e-04 - val_coeff_determination: -0.0625 - lr: 0.0031\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0010 - coeff_determination: -0.0081 - val_loss: 8.0978e-04 - val_coeff_determination: -0.0600 - lr: 0.0016\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0010 - coeff_determination: -0.0074 - val_loss: 8.0968e-04 - val_coeff_determination: -0.0598 - lr: 0.0016\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0010 - coeff_determination: -0.0085 - val_loss: 8.0957e-04 - val_coeff_determination: -0.0595 - lr: 0.0016\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.0010 - coeff_determination: -0.0091 - val_loss: 8.0962e-04 - val_coeff_determination: -0.0596 - lr: 0.0016\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0010 - coeff_determination: -0.0084 - val_loss: 8.0961e-04 - val_coeff_determination: -0.0596 - lr: 0.0016\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0071 - val_loss: 8.0990e-04 - val_coeff_determination: -0.0603 - lr: 0.0016\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0010 - coeff_determination: -0.0094 - val_loss: 8.1018e-04 - val_coeff_determination: -0.0611 - lr: 0.0016\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0010 - coeff_determination: -0.0085 - val_loss: 8.0964e-04 - val_coeff_determination: -0.0597 - lr: 0.0016\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0076 - val_loss: 8.0954e-04 - val_coeff_determination: -0.0594 - lr: 0.0016\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 3s 94ms/step - loss: 0.0662 - coeff_determination: -68.9783 - val_loss: 0.0058 - val_coeff_determination: -10.7551 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0061 - coeff_determination: -5.2504 - val_loss: 0.0018 - val_coeff_determination: -2.9242 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0025 - coeff_determination: -1.5750 - val_loss: 8.9402e-04 - val_coeff_determination: -0.6179 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0015 - coeff_determination: -0.6042 - val_loss: 6.3830e-04 - val_coeff_determination: -0.2230 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0012 - coeff_determination: -0.2491 - val_loss: 6.1105e-04 - val_coeff_determination: -0.1459 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0011 - coeff_determination: -0.1215 - val_loss: 5.8701e-04 - val_coeff_determination: -0.0351 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.0577 - val_loss: 6.1542e-04 - val_coeff_determination: -0.1600 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.8672e-04 - coeff_determination: -0.0394 - val_loss: 5.8266e-04 - val_coeff_determination: -0.0540 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.7116e-04 - coeff_determination: -0.0230 - val_loss: 5.7893e-04 - val_coeff_determination: -0.0392 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.6329e-04 - coeff_determination: -0.0141 - val_loss: 5.9133e-04 - val_coeff_determination: -0.0870 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.6055e-04 - coeff_determination: -0.0114\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.6055e-04 - coeff_determination: -0.0114 - val_loss: 5.8086e-04 - val_coeff_determination: -0.0502 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5889e-04 - coeff_determination: -0.0102 - val_loss: 5.8409e-04 - val_coeff_determination: -0.0627 - lr: 0.0500\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.5812e-04 - coeff_determination: -0.0086 - val_loss: 5.8070e-04 - val_coeff_determination: -0.0500 - lr: 0.0500\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.5778e-04 - coeff_determination: -0.0085 - val_loss: 5.8316e-04 - val_coeff_determination: -0.0594 - lr: 0.0500\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.5702e-04 - coeff_determination: -0.0078 - val_loss: 5.7940e-04 - val_coeff_determination: -0.0448 - lr: 0.0500\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.5764e-04 - coeff_determination: -0.0084 - val_loss: 5.8236e-04 - val_coeff_determination: -0.0565 - lr: 0.0500\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.5646e-04 - coeff_determination: -0.0071 - val_loss: 5.8374e-04 - val_coeff_determination: -0.0616 - lr: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5697e-04 - coeff_determination: -0.0083 - val_loss: 5.7939e-04 - val_coeff_determination: -0.0451 - lr: 0.0500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5646e-04 - coeff_determination: -0.0075 - val_loss: 5.7972e-04 - val_coeff_determination: -0.0464 - lr: 0.0500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5613e-04 - coeff_determination: -0.0068 - val_loss: 5.8312e-04 - val_coeff_determination: -0.0596 - lr: 0.0500\n",
            "Epoch 21/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.5901e-04 - coeff_determination: -0.0068\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5611e-04 - coeff_determination: -0.0076 - val_loss: 5.7880e-04 - val_coeff_determination: -0.0429 - lr: 0.0500\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5593e-04 - coeff_determination: -0.0064 - val_loss: 5.8120e-04 - val_coeff_determination: -0.0525 - lr: 0.0250\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5635e-04 - coeff_determination: -0.0071 - val_loss: 5.8236e-04 - val_coeff_determination: -0.0569 - lr: 0.0250\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5581e-04 - coeff_determination: -0.0073 - val_loss: 5.7896e-04 - val_coeff_determination: -0.0436 - lr: 0.0250\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5532e-04 - coeff_determination: -0.0056 - val_loss: 5.8169e-04 - val_coeff_determination: -0.0544 - lr: 0.0250\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5520e-04 - coeff_determination: -0.0058 - val_loss: 5.8066e-04 - val_coeff_determination: -0.0505 - lr: 0.0250\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5530e-04 - coeff_determination: -0.0059 - val_loss: 5.8077e-04 - val_coeff_determination: -0.0510 - lr: 0.0250\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.5515e-04 - coeff_determination: -0.0060 - val_loss: 5.8183e-04 - val_coeff_determination: -0.0550 - lr: 0.0250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5478e-04 - coeff_determination: -0.0057 - val_loss: 5.7911e-04 - val_coeff_determination: -0.0444 - lr: 0.0250\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5505e-04 - coeff_determination: -0.0056 - val_loss: 5.8117e-04 - val_coeff_determination: -0.0526 - lr: 0.0250\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.5483e-04 - coeff_determination: -0.0056\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.5483e-04 - coeff_determination: -0.0056 - val_loss: 5.8080e-04 - val_coeff_determination: -0.0512 - lr: 0.0250\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.5446e-04 - coeff_determination: -0.0051 - val_loss: 5.8064e-04 - val_coeff_determination: -0.0506 - lr: 0.0125\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5479e-04 - coeff_determination: -0.0051 - val_loss: 5.8053e-04 - val_coeff_determination: -0.0502 - lr: 0.0125\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5445e-04 - coeff_determination: -0.0050 - val_loss: 5.8091e-04 - val_coeff_determination: -0.0517 - lr: 0.0125\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 9.5398e-04 - coeff_determination: -0.0043 - val_loss: 5.8102e-04 - val_coeff_determination: -0.0522 - lr: 0.0125\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.5488e-04 - coeff_determination: -0.0052 - val_loss: 5.8059e-04 - val_coeff_determination: -0.0505 - lr: 0.0125\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5457e-04 - coeff_determination: -0.0052 - val_loss: 5.8042e-04 - val_coeff_determination: -0.0499 - lr: 0.0125\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.5478e-04 - coeff_determination: -0.0057 - val_loss: 5.8113e-04 - val_coeff_determination: -0.0526 - lr: 0.0125\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.5416e-04 - coeff_determination: -0.0049 - val_loss: 5.8113e-04 - val_coeff_determination: -0.0526 - lr: 0.0125\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.5399e-04 - coeff_determination: -0.0049 - val_loss: 5.7938e-04 - val_coeff_determination: -0.0458 - lr: 0.0125\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.5421e-04 - coeff_determination: -0.0048\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5421e-04 - coeff_determination: -0.0048 - val_loss: 5.8088e-04 - val_coeff_determination: -0.0517 - lr: 0.0125\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.5420e-04 - coeff_determination: -0.0047 - val_loss: 5.8019e-04 - val_coeff_determination: -0.0491 - lr: 0.0063\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.5432e-04 - coeff_determination: -0.0053 - val_loss: 5.8109e-04 - val_coeff_determination: -0.0525 - lr: 0.0063\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5456e-04 - coeff_determination: -0.0050 - val_loss: 5.8082e-04 - val_coeff_determination: -0.0515 - lr: 0.0063\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 9.5407e-04 - coeff_determination: -0.0051 - val_loss: 5.8075e-04 - val_coeff_determination: -0.0513 - lr: 0.0063\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 9.5384e-04 - coeff_determination: -0.0043 - val_loss: 5.8049e-04 - val_coeff_determination: -0.0503 - lr: 0.0063\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.5392e-04 - coeff_determination: -0.0043 - val_loss: 5.8059e-04 - val_coeff_determination: -0.0507 - lr: 0.0063\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.5412e-04 - coeff_determination: -0.0048 - val_loss: 5.8063e-04 - val_coeff_determination: -0.0508 - lr: 0.0063\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5382e-04 - coeff_determination: -0.0044 - val_loss: 5.8029e-04 - val_coeff_determination: -0.0495 - lr: 0.0063\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5407e-04 - coeff_determination: -0.0049 - val_loss: 5.8198e-04 - val_coeff_determination: -0.0559 - lr: 0.0063\n",
            "Epoch 51/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.5930e-04 - coeff_determination: -0.0048\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5428e-04 - coeff_determination: -0.0047 - val_loss: 5.7931e-04 - val_coeff_determination: -0.0456 - lr: 0.0063\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.5388e-04 - coeff_determination: -0.0045 - val_loss: 5.8022e-04 - val_coeff_determination: -0.0493 - lr: 0.0031\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5408e-04 - coeff_determination: -0.0050 - val_loss: 5.8040e-04 - val_coeff_determination: -0.0500 - lr: 0.0031\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5415e-04 - coeff_determination: -0.0044 - val_loss: 5.8089e-04 - val_coeff_determination: -0.0519 - lr: 0.0031\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5414e-04 - coeff_determination: -0.0049 - val_loss: 5.8150e-04 - val_coeff_determination: -0.0542 - lr: 0.0031\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.5392e-04 - coeff_determination: -0.0045 - val_loss: 5.8052e-04 - val_coeff_determination: -0.0504 - lr: 0.0031\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.5446e-04 - coeff_determination: -0.0048 - val_loss: 5.7980e-04 - val_coeff_determination: -0.0476 - lr: 0.0031\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5404e-04 - coeff_determination: -0.0050 - val_loss: 5.8070e-04 - val_coeff_determination: -0.0512 - lr: 0.0031\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5400e-04 - coeff_determination: -0.0046 - val_loss: 5.8031e-04 - val_coeff_determination: -0.0497 - lr: 0.0031\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5418e-04 - coeff_determination: -0.0046 - val_loss: 5.8047e-04 - val_coeff_determination: -0.0502 - lr: 0.0031\n",
            "Epoch 61/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.5342e-04 - coeff_determination: -0.0053\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.5400e-04 - coeff_determination: -0.0053 - val_loss: 5.7984e-04 - val_coeff_determination: -0.0478 - lr: 0.0031\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5412e-04 - coeff_determination: -0.0054 - val_loss: 5.8096e-04 - val_coeff_determination: -0.0521 - lr: 0.0016\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.5405e-04 - coeff_determination: -0.0042 - val_loss: 5.8087e-04 - val_coeff_determination: -0.0518 - lr: 0.0016\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5406e-04 - coeff_determination: -0.0049 - val_loss: 5.8068e-04 - val_coeff_determination: -0.0511 - lr: 0.0016\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.5424e-04 - coeff_determination: -0.0051 - val_loss: 5.8030e-04 - val_coeff_determination: -0.0496 - lr: 0.0016\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 9.5398e-04 - coeff_determination: -0.0047 - val_loss: 5.8024e-04 - val_coeff_determination: -0.0494 - lr: 0.0016\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.5389e-04 - coeff_determination: -0.0046 - val_loss: 5.8056e-04 - val_coeff_determination: -0.0506 - lr: 0.0016\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.5408e-04 - coeff_determination: -0.0045 - val_loss: 5.8063e-04 - val_coeff_determination: -0.0509 - lr: 0.0016\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.5401e-04 - coeff_determination: -0.0053 - val_loss: 5.8059e-04 - val_coeff_determination: -0.0507 - lr: 0.0016\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.5378e-04 - coeff_determination: -0.0045 - val_loss: 5.8093e-04 - val_coeff_determination: -0.0520 - lr: 0.0016\n",
            "Epoch 71/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.4719e-04 - coeff_determination: -0.0043\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5384e-04 - coeff_determination: -0.0042 - val_loss: 5.8051e-04 - val_coeff_determination: -0.0504 - lr: 0.0016\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 74ms/step - loss: 0.0896 - coeff_determination: -96.6773 - val_loss: 0.0085 - val_coeff_determination: -3.3046 - lr: 0.1000\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0075 - coeff_determination: -7.1874 - val_loss: 0.0047 - val_coeff_determination: -1.0741 - lr: 0.1000\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0047 - coeff_determination: -4.0984 - val_loss: 0.0031 - val_coeff_determination: -0.1955 - lr: 0.1000\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0028 - coeff_determination: -2.0675 - val_loss: 0.0030 - val_coeff_determination: -0.1363 - lr: 0.1000\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0020 - coeff_determination: -1.1643 - val_loss: 0.0030 - val_coeff_determination: -0.0597 - lr: 0.1000\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0015 - coeff_determination: -0.6369 - val_loss: 0.0029 - val_coeff_determination: -0.0517 - lr: 0.1000\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0012 - coeff_determination: -0.3703 - val_loss: 0.0029 - val_coeff_determination: -0.0603 - lr: 0.1000\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0011 - coeff_determination: -0.2354 - val_loss: 0.0029 - val_coeff_determination: -0.0411 - lr: 0.1000\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0011 - coeff_determination: -0.1589 - val_loss: 0.0029 - val_coeff_determination: -0.0463 - lr: 0.1000\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0010 - coeff_determination: -0.1092 - val_loss: 0.0029 - val_coeff_determination: -0.0439 - lr: 0.1000\n",
            "Epoch 11/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.9412e-04 - coeff_determination: -0.0878\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.8564e-04 - coeff_determination: -0.0868 - val_loss: 0.0029 - val_coeff_determination: -0.0344 - lr: 0.1000\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.7366e-04 - coeff_determination: -0.0740 - val_loss: 0.0029 - val_coeff_determination: -0.0409 - lr: 0.0500\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.6572e-04 - coeff_determination: -0.0650 - val_loss: 0.0029 - val_coeff_determination: -0.0355 - lr: 0.0500\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.6198e-04 - coeff_determination: -0.0608 - val_loss: 0.0029 - val_coeff_determination: -0.0375 - lr: 0.0500\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5616e-04 - coeff_determination: -0.0548 - val_loss: 0.0029 - val_coeff_determination: -0.0354 - lr: 0.0500\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.5373e-04 - coeff_determination: -0.0520 - val_loss: 0.0029 - val_coeff_determination: -0.0335 - lr: 0.0500\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.4756e-04 - coeff_determination: -0.0451 - val_loss: 0.0029 - val_coeff_determination: -0.0333 - lr: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.4501e-04 - coeff_determination: -0.0424 - val_loss: 0.0029 - val_coeff_determination: -0.0347 - lr: 0.0500\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.4290e-04 - coeff_determination: -0.0401 - val_loss: 0.0029 - val_coeff_determination: -0.0284 - lr: 0.0500\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.4057e-04 - coeff_determination: -0.0370 - val_loss: 0.0029 - val_coeff_determination: -0.0326 - lr: 0.0500\n",
            "Epoch 21/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.4464e-04 - coeff_determination: -0.0344\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.3719e-04 - coeff_determination: -0.0338 - val_loss: 0.0029 - val_coeff_determination: -0.0273 - lr: 0.0500\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.3425e-04 - coeff_determination: -0.0304 - val_loss: 0.0029 - val_coeff_determination: -0.0307 - lr: 0.0250\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.3634e-04 - coeff_determination: -0.0326 - val_loss: 0.0029 - val_coeff_determination: -0.0309 - lr: 0.0250\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.3301e-04 - coeff_determination: -0.0285 - val_loss: 0.0029 - val_coeff_determination: -0.0287 - lr: 0.0250\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.3591e-04 - coeff_determination: -0.0319 - val_loss: 0.0029 - val_coeff_determination: -0.0300 - lr: 0.0250\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.3329e-04 - coeff_determination: -0.0297 - val_loss: 0.0029 - val_coeff_determination: -0.0281 - lr: 0.0250\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.3409e-04 - coeff_determination: -0.0311 - val_loss: 0.0029 - val_coeff_determination: -0.0296 - lr: 0.0250\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.3403e-04 - coeff_determination: -0.0304 - val_loss: 0.0029 - val_coeff_determination: -0.0272 - lr: 0.0250\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.3002e-04 - coeff_determination: -0.0258 - val_loss: 0.0029 - val_coeff_determination: -0.0319 - lr: 0.0250\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.3087e-04 - coeff_determination: -0.0267 - val_loss: 0.0029 - val_coeff_determination: -0.0268 - lr: 0.0250\n",
            "Epoch 31/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.3314e-04 - coeff_determination: -0.0248\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2932e-04 - coeff_determination: -0.0252 - val_loss: 0.0029 - val_coeff_determination: -0.0294 - lr: 0.0250\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2788e-04 - coeff_determination: -0.0234 - val_loss: 0.0029 - val_coeff_determination: -0.0287 - lr: 0.0125\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2847e-04 - coeff_determination: -0.0243 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0125\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2975e-04 - coeff_determination: -0.0258 - val_loss: 0.0029 - val_coeff_determination: -0.0281 - lr: 0.0125\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2765e-04 - coeff_determination: -0.0232 - val_loss: 0.0029 - val_coeff_determination: -0.0277 - lr: 0.0125\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2784e-04 - coeff_determination: -0.0237 - val_loss: 0.0029 - val_coeff_determination: -0.0271 - lr: 0.0125\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2929e-04 - coeff_determination: -0.0252 - val_loss: 0.0029 - val_coeff_determination: -0.0289 - lr: 0.0125\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2602e-04 - coeff_determination: -0.0212 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0125\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2518e-04 - coeff_determination: -0.0207 - val_loss: 0.0029 - val_coeff_determination: -0.0270 - lr: 0.0125\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2700e-04 - coeff_determination: -0.0226 - val_loss: 0.0029 - val_coeff_determination: -0.0264 - lr: 0.0125\n",
            "Epoch 41/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.2772e-04 - coeff_determination: -0.0213\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2612e-04 - coeff_determination: -0.0214 - val_loss: 0.0029 - val_coeff_determination: -0.0287 - lr: 0.0125\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2564e-04 - coeff_determination: -0.0208 - val_loss: 0.0029 - val_coeff_determination: -0.0271 - lr: 0.0063\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 9.2717e-04 - coeff_determination: -0.0229 - val_loss: 0.0029 - val_coeff_determination: -0.0265 - lr: 0.0063\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2609e-04 - coeff_determination: -0.0217 - val_loss: 0.0029 - val_coeff_determination: -0.0266 - lr: 0.0063\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 9.2670e-04 - coeff_determination: -0.0225 - val_loss: 0.0029 - val_coeff_determination: -0.0269 - lr: 0.0063\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2600e-04 - coeff_determination: -0.0214 - val_loss: 0.0029 - val_coeff_determination: -0.0261 - lr: 0.0063\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.2655e-04 - coeff_determination: -0.0227 - val_loss: 0.0029 - val_coeff_determination: -0.0267 - lr: 0.0063\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2523e-04 - coeff_determination: -0.0211 - val_loss: 0.0029 - val_coeff_determination: -0.0272 - lr: 0.0063\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2537e-04 - coeff_determination: -0.0206 - val_loss: 0.0029 - val_coeff_determination: -0.0255 - lr: 0.0063\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 9.2712e-04 - coeff_determination: -0.0237 - val_loss: 0.0029 - val_coeff_determination: -0.0265 - lr: 0.0063\n",
            "Epoch 51/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.1561e-04 - coeff_determination: -0.0202\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2511e-04 - coeff_determination: -0.0205 - val_loss: 0.0029 - val_coeff_determination: -0.0269 - lr: 0.0063\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2559e-04 - coeff_determination: -0.0216 - val_loss: 0.0029 - val_coeff_determination: -0.0267 - lr: 0.0031\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2409e-04 - coeff_determination: -0.0197 - val_loss: 0.0029 - val_coeff_determination: -0.0264 - lr: 0.0031\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2636e-04 - coeff_determination: -0.0213 - val_loss: 0.0029 - val_coeff_determination: -0.0255 - lr: 0.0031\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2521e-04 - coeff_determination: -0.0205 - val_loss: 0.0029 - val_coeff_determination: -0.0255 - lr: 0.0031\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2362e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0267 - lr: 0.0031\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2405e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0265 - lr: 0.0031\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2302e-04 - coeff_determination: -0.0179 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0031\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 9.2381e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0265 - lr: 0.0031\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2350e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 0.0031\n",
            "Epoch 61/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.2374e-04 - coeff_determination: -0.0163\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2245e-04 - coeff_determination: -0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 0.0031\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2290e-04 - coeff_determination: -0.0177 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 0.0016\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2429e-04 - coeff_determination: -0.0197 - val_loss: 0.0029 - val_coeff_determination: -0.0263 - lr: 0.0016\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 9.2405e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0261 - lr: 0.0016\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.2504e-04 - coeff_determination: -0.0202 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0016\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2669e-04 - coeff_determination: -0.0220 - val_loss: 0.0029 - val_coeff_determination: -0.0265 - lr: 0.0016\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2613e-04 - coeff_determination: -0.0214 - val_loss: 0.0029 - val_coeff_determination: -0.0261 - lr: 0.0016\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2439e-04 - coeff_determination: -0.0202 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0016\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 9.2413e-04 - coeff_determination: -0.0192 - val_loss: 0.0029 - val_coeff_determination: -0.0264 - lr: 0.0016\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2484e-04 - coeff_determination: -0.0210 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0016\n",
            "Epoch 71/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.1759e-04 - coeff_determination: -0.0208\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2463e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 0.0016\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 9.2262e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0262 - lr: 7.8125e-04\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2390e-04 - coeff_determination: -0.0196 - val_loss: 0.0029 - val_coeff_determination: -0.0261 - lr: 7.8125e-04\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2333e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0261 - lr: 7.8125e-04\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2521e-04 - coeff_determination: -0.0207 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.8125e-04\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2464e-04 - coeff_determination: -0.0201 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.8125e-04\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2462e-04 - coeff_determination: -0.0197 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.8125e-04\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2329e-04 - coeff_determination: -0.0184 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.8125e-04\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 9.2477e-04 - coeff_determination: -0.0201 - val_loss: 0.0029 - val_coeff_determination: -0.0258 - lr: 7.8125e-04\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.2375e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.8125e-04\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2412e-04 - coeff_determination: -0.0192\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2412e-04 - coeff_determination: -0.0192 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.8125e-04\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2450e-04 - coeff_determination: -0.0205 - val_loss: 0.0029 - val_coeff_determination: -0.0258 - lr: 3.9063e-04\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2320e-04 - coeff_determination: -0.0185 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.9063e-04\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2454e-04 - coeff_determination: -0.0201 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 3.9063e-04\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2455e-04 - coeff_determination: -0.0200 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.9063e-04\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.2376e-04 - coeff_determination: -0.0193 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 3.9063e-04\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2377e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 3.9063e-04\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2348e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 3.9063e-04\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2246e-04 - coeff_determination: -0.0180 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.9063e-04\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2311e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.9063e-04\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2363e-04 - coeff_determination: -0.0185\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2363e-04 - coeff_determination: -0.0185 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.9063e-04\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2295e-04 - coeff_determination: -0.0179 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 1.9531e-04\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2441e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 1.9531e-04\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.2339e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2346e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2291e-04 - coeff_determination: -0.0179 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2448e-04 - coeff_determination: -0.0198 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2331e-04 - coeff_determination: -0.0187 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2250e-04 - coeff_determination: -0.0176 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2466e-04 - coeff_determination: -0.0202 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9531e-04\n",
            "Epoch 101/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.3240e-04 - coeff_determination: -0.0190\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 9.765625145519152e-05.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2421e-04 - coeff_determination: -0.0196 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 1.9531e-04\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2345e-04 - coeff_determination: -0.0192 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2440e-04 - coeff_determination: -0.0197 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 9.7656e-05\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2412e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 9.7656e-05\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 9.2324e-04 - coeff_determination: -0.0190 - val_loss: 0.0029 - val_coeff_determination: -0.0260 - lr: 9.7656e-05\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2332e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2488e-04 - coeff_determination: -0.0199 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2136e-04 - coeff_determination: -0.0163 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2353e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2332e-04 - coeff_determination: -0.0185 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 111/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 9.2280e-04 - coeff_determination: -0.0186\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.882812572759576e-05.\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2334e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.7656e-05\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2219e-04 - coeff_determination: -0.0173 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2344e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2301e-04 - coeff_determination: -0.0181 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2420e-04 - coeff_determination: -0.0193 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2230e-04 - coeff_determination: -0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2297e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2585e-04 - coeff_determination: -0.0210 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2373e-04 - coeff_determination: -0.0192 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2215e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 121/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 9.2118e-04 - coeff_determination: -0.0189\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 2.441406286379788e-05.\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2349e-04 - coeff_determination: -0.0187 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.8828e-05\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2217e-04 - coeff_determination: -0.0170 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2262e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2511e-04 - coeff_determination: -0.0205 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2174e-04 - coeff_determination: -0.0166 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2228e-04 - coeff_determination: -0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2293e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2304e-04 - coeff_determination: -0.0181 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2464e-04 - coeff_determination: -0.0200 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2281e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 131/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 9.2235e-04 - coeff_determination: -0.0190\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.220703143189894e-05.\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 9.2341e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.4414e-05\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 9.2157e-04 - coeff_determination: -0.0165 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2437e-04 - coeff_determination: -0.0205 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 9.2412e-04 - coeff_determination: -0.0193 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2299e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 9.2234e-04 - coeff_determination: -0.0176 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 9.2247e-04 - coeff_determination: -0.0178 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2160e-04 - coeff_determination: -0.0171 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2359e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2356e-04 - coeff_determination: -0.0187 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2287e-04 - coeff_determination: -0.0175\n",
            "Epoch 00141: ReduceLROnPlateau reducing learning rate to 6.10351571594947e-06.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2287e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.2207e-05\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 9.2398e-04 - coeff_determination: -0.0193 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2335e-04 - coeff_determination: -0.0192 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2446e-04 - coeff_determination: -0.0206 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2329e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 9.2200e-04 - coeff_determination: -0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 9.2478e-04 - coeff_determination: -0.0205 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2214e-04 - coeff_determination: -0.0172 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 9.2449e-04 - coeff_determination: -0.0202 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 9.2242e-04 - coeff_determination: -0.0171 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2356e-04 - coeff_determination: -0.0191\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 3.051757857974735e-06.\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2356e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 6.1035e-06\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2507e-04 - coeff_determination: -0.0206 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2150e-04 - coeff_determination: -0.0163 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2216e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2332e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2308e-04 - coeff_determination: -0.0184 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2337e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2303e-04 - coeff_determination: -0.0179 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2431e-04 - coeff_determination: -0.0196 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2469e-04 - coeff_determination: -0.0203 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 161/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.2244e-04 - coeff_determination: -0.0169\n",
            "Epoch 00161: ReduceLROnPlateau reducing learning rate to 1.5258789289873675e-06.\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2204e-04 - coeff_determination: -0.0173 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.0518e-06\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2273e-04 - coeff_determination: -0.0178 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2218e-04 - coeff_determination: -0.0174 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2407e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2153e-04 - coeff_determination: -0.0165 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 9.2269e-04 - coeff_determination: -0.0177 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 9.2253e-04 - coeff_determination: -0.0181 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2297e-04 - coeff_determination: -0.0187 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 9.2427e-04 - coeff_determination: -0.0197 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2289e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2462e-04 - coeff_determination: -0.0200\n",
            "Epoch 00171: ReduceLROnPlateau reducing learning rate to 7.629394644936838e-07.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2462e-04 - coeff_determination: -0.0200 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.5259e-06\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 9.2154e-04 - coeff_determination: -0.0167 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2368e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2213e-04 - coeff_determination: -0.0173 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2342e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 9.2405e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2297e-04 - coeff_determination: -0.0180 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2097e-04 - coeff_determination: -0.0160 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2409e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2579e-04 - coeff_determination: -0.0216 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 181/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 9.2305e-04 - coeff_determination: -0.0199\n",
            "Epoch 00181: ReduceLROnPlateau reducing learning rate to 3.814697322468419e-07.\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2466e-04 - coeff_determination: -0.0200 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 7.6294e-07\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2184e-04 - coeff_determination: -0.0174 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2263e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2291e-04 - coeff_determination: -0.0178 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2416e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2182e-04 - coeff_determination: -0.0168 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2294e-04 - coeff_determination: -0.0180 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2355e-04 - coeff_determination: -0.0185 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2343e-04 - coeff_determination: -0.0185 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2420e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2212e-04 - coeff_determination: -0.0171\n",
            "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1.9073486612342094e-07.\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2212e-04 - coeff_determination: -0.0171 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 3.8147e-07\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2223e-04 - coeff_determination: -0.0174 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2399e-04 - coeff_determination: -0.0190 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2237e-04 - coeff_determination: -0.0177 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 9.2356e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2266e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 9.2183e-04 - coeff_determination: -0.0168 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2362e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2412e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2370e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2470e-04 - coeff_determination: -0.0206\n",
            "Epoch 00201: ReduceLROnPlateau reducing learning rate to 9.536743306171047e-08.\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2470e-04 - coeff_determination: -0.0206 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.9073e-07\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2288e-04 - coeff_determination: -0.0184 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2171e-04 - coeff_determination: -0.0166 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2269e-04 - coeff_determination: -0.0177 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2356e-04 - coeff_determination: -0.0190 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2143e-04 - coeff_determination: -0.0162 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2262e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2329e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2316e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2358e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 211/300\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 9.2328e-04 - coeff_determination: -0.0188\n",
            "Epoch 00211: ReduceLROnPlateau reducing learning rate to 4.7683716530855236e-08.\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2342e-04 - coeff_determination: -0.0182 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 9.5367e-08\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2413e-04 - coeff_determination: -0.0193 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2315e-04 - coeff_determination: -0.0181 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2299e-04 - coeff_determination: -0.0179 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2343e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 9.2293e-04 - coeff_determination: -0.0180 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 9.2318e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2374e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2365e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2415e-04 - coeff_determination: -0.0193 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 221/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.1801e-04 - coeff_determination: -0.0177\n",
            "Epoch 00221: ReduceLROnPlateau reducing learning rate to 2.3841858265427618e-08.\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 9.2261e-04 - coeff_determination: -0.0177 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 4.7684e-08\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2375e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2178e-04 - coeff_determination: -0.0173 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 9.2472e-04 - coeff_determination: -0.0200 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2395e-04 - coeff_determination: -0.0194 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 9.2434e-04 - coeff_determination: -0.0198 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 9.2325e-04 - coeff_determination: -0.0183 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2180e-04 - coeff_determination: -0.0168 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 9.2313e-04 - coeff_determination: -0.0189 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 9.2334e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - ETA: 0s - loss: 9.2290e-04 - coeff_determination: -0.0178\n",
            "Epoch 00231: ReduceLROnPlateau reducing learning rate to 1.1920929132713809e-08.\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 9.2290e-04 - coeff_determination: -0.0178 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 2.3842e-08\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 9.2234e-04 - coeff_determination: -0.0175 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2365e-04 - coeff_determination: -0.0188 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 9.2379e-04 - coeff_determination: -0.0195 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2183e-04 - coeff_determination: -0.0170 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2523e-04 - coeff_determination: -0.0208 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2481e-04 - coeff_determination: -0.0202 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 9.2360e-04 - coeff_determination: -0.0191 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 9.2251e-04 - coeff_determination: -0.0181 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2325e-04 - coeff_determination: -0.0186 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 241/300\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 9.1481e-04 - coeff_determination: -0.0174\n",
            "Epoch 00241: ReduceLROnPlateau reducing learning rate to 5.9604645663569045e-09.\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 9.2205e-04 - coeff_determination: -0.0170 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 1.1921e-08\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 9.2352e-04 - coeff_determination: -0.0190 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 5.9605e-09\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 9.2213e-04 - coeff_determination: -0.0171 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 5.9605e-09\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 9.2266e-04 - coeff_determination: -0.0177 - val_loss: 0.0029 - val_coeff_determination: -0.0259 - lr: 5.9605e-09\n"
          ]
        }
      ],
      "source": [
        "predictions_LSTM = {}\n",
        "model = {}\n",
        "for i in range(2016,2022):\n",
        "\n",
        "  X_train = data_lstm.loc[(data_lstm.index.year >= i - 8) & (data_lstm.index.year < i - 1), allFeatures]\n",
        "  X_train = np.array([X_train[column].tolist() for column in X_train.columns])\n",
        "  X_train = X_train.reshape(X_train.shape[1], X_train.shape[2], X_train.shape[0])\n",
        "  y_train = data_lstm.loc[(data_lstm.index.year >= i - 8) & (data_lstm.index.year < i - 1), 'BV_1w target'].tolist()\n",
        "\n",
        "  X_valid = data_lstm.loc[data_lstm.index.year == i - 1, allFeatures]\n",
        "  X_valid = np.array([X_valid[column].tolist() for column in X_valid.columns])\n",
        "  X_valid = X_valid.reshape(X_valid.shape[1], X_valid.shape[2], X_valid.shape[0])\n",
        "  y_valid = data_lstm.loc[data_lstm.index.year == i - 1, 'BV_1w target'].tolist()\n",
        "\n",
        "  X_test = data_lstm.loc[data_lstm.index.year == i, allFeatures]\n",
        "  X_test = np.array([X_test[column].tolist() for column in X_test.columns])\n",
        "  X_test = X_test.reshape(X_test.shape[1], X_test.shape[2], X_test.shape[0])\n",
        "  y_test = data_lstm.loc[data_lstm.index.year == i, 'BV_1w target'].tolist()\n",
        "\n",
        "\n",
        "  model[i] = tf.keras.models.Sequential()\n",
        "  model[i].add(tf.keras.layers.LSTM(units=len(allFeatures), input_shape=(None, len(allFeatures)), return_sequences=True))\n",
        "  model[i].add(tf.keras.layers.Dropout(0.1))\n",
        "  model[i].add(tf.keras.layers.LSTM(units=6,  activation = 'sigmoid', return_sequences=True))\n",
        "  model[i].add(tf.keras.layers.Dropout(0.1))\n",
        "  model[i].add(tf.keras.layers.Dense(1,  activation = 'linear'))\n",
        "\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, \n",
        "                                   verbose=1, mode='max', min_lr=0.000000001)\n",
        "  \n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50) \n",
        "\n",
        "  model[i].compile(tf.keras.optimizers.Adam(learning_rate=0.1), loss='mse', metrics=coeff_determination)\n",
        "  model[i].fit(tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train),\n",
        "            validation_data=(tf.convert_to_tensor(X_valid), tf.convert_to_tensor(y_valid)),\n",
        "            epochs=300,\n",
        "            batch_size=200,\n",
        "            shuffle=1,\n",
        "            callbacks= [reduce_lr, earlystop],\n",
        "            verbose=1)\n",
        "  predictions_LSTM[i] = pd.DataFrame(model[i].predict(X_test)[:, -1], index=data.loc[data.index.year == i].index, columns=['Predictions'])\n",
        "  predictions_LSTM[i]['True'] = np.array(y_test)[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, None, 24)          4704      \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, None, 24)          0         \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, None, 6)           744       \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, None, 6)           0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, None, 1)           7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,455\n",
            "Trainable params: 5,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model[i].summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  LSTM R²: -0.05389705585893512\n",
            "  LSTM MAE: 0.02954297812209623\n",
            "  LSTM MSE: 0.0014437520996812918\n",
            "2017\n",
            "  LSTM R²: -0.02499148659784267\n",
            "  LSTM MAE: 0.01998075181741874\n",
            "  LSTM MSE: 0.0006282246227436288\n",
            "2018\n",
            "  LSTM R²: -0.0102736034810893\n",
            "  LSTM MAE: 0.022852470860363176\n",
            "  LSTM MSE: 0.0008523502681197752\n",
            "2019\n",
            "  LSTM R²: -0.03218922494721266\n",
            "  LSTM MAE: 0.018612061920348054\n",
            "  LSTM MSE: 0.0005182953171809989\n",
            "2020\n",
            "  LSTM R²: 0.002502425478075776\n",
            "  LSTM MAE: 0.03390932467943585\n",
            "  LSTM MSE: 0.002892745841954924\n",
            "2021\n",
            "  LSTM R²: -0.01885363466101886\n",
            "  LSTM MAE: 0.018261829915290042\n",
            "  LSTM MSE: 0.0005525435545387161\n"
          ]
        }
      ],
      "source": [
        "for i in predictions_LSTM.keys():\n",
        "  print(i)\n",
        "  print('  LSTM R²: {}'.format(r2_score(predictions_LSTM[i]['True'],predictions_LSTM[i]['Predictions'])))\n",
        "  print('  LSTM MAE: {}'.format(mean_absolute_error(predictions_LSTM[i]['True'],predictions_LSTM[i]['Predictions'])))\n",
        "  print('  LSTM MSE: {}'.format(mean_squared_error(predictions_LSTM[i]['True'],predictions_LSTM[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "classification_LSTM = {}\n",
        "for i in predictions_LSTM.keys():\n",
        "  classification_LSTM[i] = predictions_LSTM[i].applymap(lambda x: 0 if x < 0 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016\n",
            "  LSTM F1: 0.4827586206896552\n",
            "  LSTM Accu: 0.4578313253012048\n",
            "  LSTM precision: 0.5833333333333334\n",
            "  LSTM recall: 0.4117647058823529\n",
            "2017\n",
            "  LSTM F1: 0.6253869969040248\n",
            "  LSTM Accu: 0.5101214574898786\n",
            "  LSTM precision: 0.5738636363636364\n",
            "  LSTM recall: 0.6870748299319728\n",
            "2018\n",
            "  LSTM F1: 0.5918367346938775\n",
            "  LSTM Accu: 0.5081967213114754\n",
            "  LSTM precision: 0.5506329113924051\n",
            "  LSTM recall: 0.6397058823529411\n",
            "2019\n",
            "  LSTM F1: 0.7237569060773482\n",
            "  LSTM Accu: 0.5951417004048583\n",
            "  LSTM precision: 0.6517412935323383\n",
            "  LSTM recall: 0.8136645962732919\n",
            "2020\n",
            "  LSTM F1: 0.7461928934010152\n",
            "  LSTM Accu: 0.5951417004048583\n",
            "  LSTM precision: 0.5951417004048583\n",
            "  LSTM recall: 1.0\n",
            "2021\n",
            "  LSTM F1: 0.6344827586206896\n",
            "  LSTM Accu: 0.49038461538461536\n",
            "  LSTM precision: 0.467005076142132\n",
            "  LSTM recall: 0.989247311827957\n"
          ]
        }
      ],
      "source": [
        "for i in classification_LSTM.keys():\n",
        "  print(i)\n",
        "  print('  LSTM F1: {}'.format(f1_score(classification_LSTM[i]['True'],classification_LSTM[i]['Predictions'])))\n",
        "  print('  LSTM Accu: {}'.format(accuracy_score(classification_LSTM[i]['True'],classification_LSTM[i]['Predictions'])))\n",
        "  print('  LSTM precision: {}'.format(precision_score(classification_LSTM[i]['True'],classification_LSTM[i]['Predictions'])))\n",
        "  print('  LSTM recall: {}'.format(recall_score(classification_LSTM[i]['True'],classification_LSTM[i]['Predictions'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016: patrimonio final long-only: 104.86051276346278, long-short: 72.85018093188664\n",
            "2017: patrimonio final long-only: 117.21401658079725, long-short: 112.46126862901082\n",
            "2018: patrimonio final long-only: 103.42937218636773, long-short: 89.07993916195105\n",
            "2019: patrimonio final long-only: 118.17669674762003, long-short: 105.81944715572656\n",
            "2020: patrimonio final long-only: 106.78916627093129, long-short: 106.78916627093129\n",
            "2021: patrimonio final long-only: 93.25413190987409, long-short: 98.64242672326654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-118-a0ec28184311>:2: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
            "  classification_LSTM[i]['week'] = classification_LSTM[i].index.week\n"
          ]
        }
      ],
      "source": [
        "for i in classification_LSTM.keys():\n",
        "  classification_LSTM[i]['week'] = classification_LSTM[i].index.week\n",
        "  classification_LSTM[i]['True'] = predictions_LSTM[i]['True'] + 1\n",
        "  result = classification_LSTM[i].groupby('week', as_index=False).first()\n",
        "  patrimonio = 100\n",
        "  patrimonio2 = 100\n",
        "  for j in result.index:\n",
        "    if result.loc[j, 'Predictions'] == 1:\n",
        "      patrimonio *= result.loc[j, 'True']\n",
        "      patrimonio2 *= result.loc[j, 'True']\n",
        "    else:\n",
        "      patrimonio2 *= 2 - result.loc[j, 'True']\n",
        "  print('{}: patrimonio final long-only: {}, long-short: {}'.format(i, patrimonio, patrimonio2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BV_ano\n",
              "2006         NaN\n",
              "2007    0.436480\n",
              "2008   -0.412234\n",
              "2009    0.826578\n",
              "2010    0.010454\n",
              "2011   -0.181098\n",
              "2012    0.073968\n",
              "2013   -0.154958\n",
              "2014   -0.029122\n",
              "2015   -0.133121\n",
              "2016    0.389319\n",
              "2017    0.268567\n",
              "2018    0.150323\n",
              "2019    0.319467\n",
              "2020    0.028819\n",
              "Name: BV_Close, dtype: float64"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby('BV_ano').last()['BV_Close'].pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B1L2K7iaSPM"
      },
      "outputs": [],
      "source": [
        "realy = []\n",
        "for i in y_train:\n",
        "  realy.append(i[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xroJPwGGay26"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(np.array(realy).reshape(-1, 1))\n",
        "t = scaler.transform(np.array([ i for i in predictions_LSTM[2016]['Predictions'].values]).reshape(1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "wpW8lD30b0qX",
        "outputId": "adfa6679-73e9-4834-cb28-2d318b8a8030"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fba187d0c50>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.displot(t[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ssy4nG3cU61"
      },
      "outputs": [],
      "source": [
        "# Para 2016\n",
        "dfClassifier = pd.concat([data['1w target'][(data.index.year == 2016)].reset_index(drop=True).copy(),pd.Series(t[0])],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k1MnljLdAm1"
      },
      "outputs": [],
      "source": [
        "dfClassifier.columns = ['1w target', 'predict']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B3th6lwjdlza",
        "outputId": "3b3f219f-1082-4598-ee9e-df38ca67b08d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1w target</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.948008</td>\n",
              "      <td>0.455029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.931517</td>\n",
              "      <td>0.454685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.932277</td>\n",
              "      <td>0.454638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.970635</td>\n",
              "      <td>0.454705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.949695</td>\n",
              "      <td>0.455321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   1w target   predict\n",
              "0   0.948008  0.455029\n",
              "1   0.931517  0.454685\n",
              "2   0.932277  0.454638\n",
              "3   0.970635  0.454705\n",
              "4   0.949695  0.455321"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfClassifier.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0ZIoEaJdpkG"
      },
      "outputs": [],
      "source": [
        "dfClassifier['target'] = dfClassifier['1w target'].apply(lambda x: 1 if x > 1.0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "3P_OXNVucG8j",
        "outputId": "b8001d47-66cf-425c-c22c-9478ff600681"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1122.38x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = sns.displot(dfClassifier,x='predict',hue='target',aspect=3, multiple=\"stack\").set(title='Target x Predict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaZCFJu5eaAa",
        "outputId": "d08158ba-79ff-4b02-b4d2-d322bdf46e24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5813589324618736"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roc_auc_score(dfClassifier['target'],dfClassifier['predict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BImWRWFafKt9"
      },
      "outputs": [],
      "source": [
        "def limiar_escore(predictions,df_target):\n",
        "    #Imprimindo limiar de Escore\n",
        "    fpr, tpr, threshold = roc_curve(df_target, predictions)\n",
        "    i = np.arange(len(tpr)) \n",
        "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
        "    roc_t = roc.loc[(roc.tf-0).abs().argsort()[:1]]\n",
        "    print('Limiar que maxima especificidade e sensitividade:')\n",
        "    print(list(roc_t['threshold']))\n",
        "    #analisando modelo com novo limiar\n",
        "    tn, fp, fn, tp = confusion_matrix(df_target, [1 if item>=list(roc_t['threshold'])[0] else 0 for item in predictions]).ravel()\n",
        "    Precision = tp/(tp+fp)\n",
        "    Recall = tp/(tp+fn)\n",
        "    acuracia = (tp+tn)/(tn+fp+fn+tp)\n",
        "    F = (2*Precision*Recall)/(Precision+Recall)\n",
        "    print('Precision',np.round(Precision,4))\n",
        "    print('Recall',np.round(Recall,4))\n",
        "    print('Acuracia',np.round(acuracia,4))\n",
        "    print('F-Score',np.round(F,4))\n",
        "    print('Roc-Auc',np.round(roc_auc_score(df_target,predictions),4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpPd842efNUQ",
        "outputId": "6ec7257f-fa97-44e0-ce17-8910e64d93ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limiar que maxima especificidade e sensitividade:\n",
            "[0.4597029983997345]\n",
            "Precision 0.6641\n",
            "Recall 0.5556\n",
            "Acuracia 0.5542\n",
            "F-Score 0.605\n",
            "Roc-Auc 0.5814\n"
          ]
        }
      ],
      "source": [
        "limiar_escore(dfClassifier['predict'],dfClassifier['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHFWJN5VZ2sI"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "scaler.fit(np.array(realy).reshape(-1, 1))\n",
        "t = scaler.transform(np.array([ i for i in predictions_LSTM[2016]['Predictions'].values]).reshape(1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "BBfZFJ4zZmnI",
        "outputId": "b9a7f488-8a70-442c-ff31-38a5022a3c3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fba086683d0>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.displot(t[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TGII.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
